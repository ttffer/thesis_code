{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torchvision\n",
    "from torchvision import datasets\n",
    "from torchvision.transforms import ToTensor\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets\n",
    "from torchvision.transforms import ToTensor\n",
    "import numpy as np\n",
    "import torch.onnx\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_img_sz=11\n",
    "layer0_output_size =32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "# Download training data from open datasets.\n",
    "training_data = datasets.FashionMNIST(\n",
    "    root=\"../../data\",    \n",
    "    train=True,\n",
    "    download=True,\n",
    "    transform=torchvision.transforms.Compose(\n",
    "        [torchvision.transforms.Resize(input_img_sz), torchvision.transforms.ToTensor()]\n",
    "    ),\n",
    ")\n",
    "\n",
    "# Download test data from open datasets.\n",
    "test_data = datasets.FashionMNIST(\n",
    "    root=\"../../data\",\n",
    "    train=False,\n",
    "    download=True,\n",
    "    transform=torchvision.transforms.Compose(\n",
    "        [torchvision.transforms.Resize(input_img_sz), torchvision.transforms.ToTensor()]\n",
    "    ),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda device\n",
      "NeuralNetwork(\n",
      "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
      "  (liner0): Linear(in_features=121, out_features=32, bias=True)\n",
      "  (relu): ReLU(inplace=True)\n",
      "  (liner1): Linear(in_features=32, out_features=10, bias=True)\n",
      ")\n",
      "Shape of X [N, C, H, W]: torch.Size([64, 1, 11, 11])\n",
      "Shape of y: torch.Size([64]) torch.int64\n"
     ]
    }
   ],
   "source": [
    "# Get cpu or gpu device for training.\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(f\"Using {device} device\")\n",
    "\n",
    "# Define model\n",
    "class NeuralNetwork(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(NeuralNetwork, self).__init__()\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.liner0 = nn.Linear(input_img_sz*input_img_sz, layer0_output_size)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.liner1 =nn.Linear(layer0_output_size, 10)\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.flatten(x)\n",
    "        x = self.liner0(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.liner1(x)\n",
    "        return x\n",
    "\n",
    "model = NeuralNetwork().to(device)\n",
    "print(model)\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "\n",
    "# optimizer = torch.optim.SGD(model.parameters(), lr=1e-3)\n",
    "optimizer = torch.optim.Adam(model.parameters(),lr=1e-3)\n",
    "def train(dataloader, model, loss_fn, optimizer):\n",
    "    size = len(dataloader.dataset)\n",
    "    model.train()\n",
    "    for batch, (X, y) in enumerate(dataloader):\n",
    "        X, y = X.to(device), y.to(device)\n",
    "\n",
    "        # Compute prediction error\n",
    "        pred = model(X)\n",
    "        loss = loss_fn(pred, y)\n",
    "\n",
    "        # Backpropagation\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        if batch % 100 == 0:\n",
    "            loss, current = loss.item(), batch * len(X)\n",
    "            print(f\"loss: {loss:>7f}  [{current:>5d}/{size:>5d}]\")\n",
    "\n",
    "def test(dataloader, model, loss_fn):\n",
    "    size = len(dataloader.dataset)\n",
    "    num_batches = len(dataloader)\n",
    "    model.eval()\n",
    "    test_loss, correct = 0, 0\n",
    "    with torch.no_grad():\n",
    "        for X, y in dataloader:\n",
    "            X, y = X.to(device), y.to(device)\n",
    "            pred = model(X)\n",
    "            test_loss += loss_fn(pred, y).item()\n",
    "            correct += (pred.argmax(1) == y).type(torch.float).sum().item()\n",
    "    test_loss /= num_batches\n",
    "    correct /= size\n",
    "    print(f\"Test Error: \\n Accuracy: {(100*correct):>0.1f}%, Avg loss: {test_loss:>8f} \\n\")\n",
    "    return correct\n",
    "batch_size = 64\n",
    "\n",
    "# Create data loaders.\n",
    "train_dataloader = DataLoader(training_data, batch_size=batch_size)\n",
    "test_dataloader = DataLoader(test_data, batch_size=batch_size)\n",
    "\n",
    "for X, y in test_dataloader:\n",
    "    print(f\"Shape of X [N, C, H, W]: {X.shape}\")\n",
    "    print(f\"Shape of y: {y.shape} {y.dtype}\")\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "def myplot(x_data,ydata,name):\n",
    "    import matplotlib.pyplot as plt\n",
    "    plt.plot(x_data,ydata)\n",
    "    plt.title(\"Learning Curve \"+name,fontsize=18)\n",
    "    plt.xlabel(\"Epoch\",fontsize=30)\n",
    "    plt.xticks(fontsize=20)\n",
    "    plt.ylabel(\"Accuracy(%)\",fontsize=20)\n",
    "    plt.yticks(fontsize=20)\n",
    "    plt.grid()\n",
    "    fig = plt.gcf()\n",
    "    fig.set_size_inches(12,10)\n",
    "    fig.savefig('./fashion_MNIST/'+name, dpi=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model loaded\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "acc_line = []\n",
    "file_name =\"fashion_MNIST\"+str(input_img_sz)+\"x\"+str(input_img_sz)+\"_\"+str(layer0_output_size)+\"_10.pth\"\n",
    "if not (os.path.isfile(file_name)):\n",
    "    epochs = 50\n",
    "    for t in range(epochs):\n",
    "        print(f\"Epoch {t+1}\\n-------------------------------\")\n",
    "        train(train_dataloader, model, loss_fn, optimizer)\n",
    "        acc_result=test(test_dataloader, model, loss_fn)\n",
    "        acc_line.append(acc_result)\n",
    "        torch.save(model, file_name)\n",
    "    print(\"Done!\")\n",
    "\n",
    "else:\n",
    "    #model.load_state_dict(torch.load(\"model.pth\"))\n",
    "    model = torch.load( file_name)\n",
    "    print(\"Model loaded\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "myplot(np.arange(1,epochs+1),acc_line,\"net2 121x16x10\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Error: \n",
      " Accuracy: 85.8%, Avg loss: 3804.845027 \n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "OrderedDict([('liner0.weight',\n",
       "              tensor([[  32.,  -33.,   51.,  ...,  -25.,  -24., -111.],\n",
       "                      [  -6., -212.,  -64.,  ...,    0.,   -2., -125.],\n",
       "                      [  -4.,   -4.,   64.,  ...,   22.,   -3., -131.],\n",
       "                      ...,\n",
       "                      [-218., -211.,  -31.,  ...,   47.,  133., -137.],\n",
       "                      [  -9.,  152.,  -56.,  ...,  -71., -187.,   91.],\n",
       "                      [ -88., -135., -150.,  ...,   72.,  -58.,  -15.]], device='cuda:0')),\n",
       "             ('liner0.bias',\n",
       "              tensor([ 19.,  60., -69.,  87., -18., -83.,  83.,  74., -17.,   0.,  33., -11.,\n",
       "                       92., -19.,  39., -70.,  -7., -33.,  -2.,  92.,  35.,  26.,  -7.,  -9.,\n",
       "                       61., 100., -27., -11.,  22.,  41., 123.,  12.], device='cuda:0')),\n",
       "             ('liner1.weight',\n",
       "              tensor([[  22.,   70.,   84.,   91.,   62.,  -32.,  -71.,   16.,  -98.,  -92.,\n",
       "                          5.,  -10.,  -80.,   33.,  -54.,  -56.,   -3.,  -31.,   24.,  -49.,\n",
       "                         -8.,  -86.,    2.,  -10.,  -24.,   32.,   14.,   17., -132.,   -8.,\n",
       "                       -199.,   28.],\n",
       "                      [-214.,   10.,   34., -246.,  -21.,  119.,  114., -194.,  -13.,  -98.,\n",
       "                        -29.,   16., -173.,  -20., -165.,   33.,  -10.,  357.,  -89., -409.,\n",
       "                         23., -195.,  -11.,   17.,  193., -106.,   64.,   -7., -137.,   69.,\n",
       "                        125.,  -34.],\n",
       "                      [   2., -228.,  -93., -119.,   42., -159.,   16.,   22.,   85.,   -6.,\n",
       "                        103.,   -6.,  -55.,   33.,  -83.,   11.,   20.,  -13.,   11.,  -10.,\n",
       "                         42.,   41.,  -20.,   12.,   25.,  -53.,   29.,   17.,  -58.,   71.,\n",
       "                       -173.,    4.],\n",
       "                      [-184.,  -29., -125.,  -34.,  -29.,   94.,    8.,   29.,    0.,  -35.,\n",
       "                       -230.,    1.,   68.,   11.,  -13.,   54.,   -4., -111.,   33., -215.,\n",
       "                        152.,   85.,   19.,    0., -128., -142.,    1.,  -20.,  -95.,  -46.,\n",
       "                         34.,   60.],\n",
       "                      [   3., -166., -129., -191.,  -16.,   26.,  -17.,   51.,   18.,   18.,\n",
       "                        -45.,    2., -190.,   -6.,    6.,   49.,   -2.,    4.,   48.,  113.,\n",
       "                        -97.,   25.,  -13.,    3.,  -60., -149.,    8.,    6.,   14.,   18.,\n",
       "                         45.,    1.],\n",
       "                      [  59., -281.,   32.,    9., -190.,   16.,   41.,  134.,   10.,  -39.,\n",
       "                         23.,  -11.,   46., -184.,   12., -101.,  -17.,  227., -197.,    1.,\n",
       "                        291.,   -4.,  -11.,  -13.,  154.,  100., -212.,   -5.,   85., -244.,\n",
       "                        -61.,  301.],\n",
       "                      [  41.,   70.,  -41.,   99.,   15., -105.,  -78.,   34., -264.,   18.,\n",
       "                        -60.,  -11.,   36.,   28.,   17.,   26.,   -1., -102.,   32., -137.,\n",
       "                       -166.,  -96.,    2.,   13.,   34., -107.,  -14.,   15.,  146.,   18.,\n",
       "                       -215.,  -21.],\n",
       "                      [ -41., -445.,   34.,   44.,  -75.,   19.,  -43., -362.,   33.,   54.,\n",
       "                         14.,  -10.,   31.,   53.,   22., -152.,   -3.,  -64.,  -67.,   52.,\n",
       "                       -186.,   45.,   19.,   19., -200.,   93.,  -99.,   -8., -108.,  215.,\n",
       "                         76., -350.],\n",
       "                      [  38., -131.,   24.,   33.,   89.,  -66., -290.,  -12.,  359.,   36.,\n",
       "                        -85.,   -1.,    3., -133.,   66.,   27.,   -9.,   72.,   -9.,   77.,\n",
       "                         78.,   44.,    5.,  -14.,  -19.,  -54.,   53.,    3., -371., -151.,\n",
       "                        -32., -168.],\n",
       "                      [   3., -106.,   57., -137.,  -25.,   72., -248., -403., -233.,  -14.,\n",
       "                         87.,   -8.,   26.,   41.,   40.,  -29.,    3., -358., -249.,   68.,\n",
       "                       -115.,   46.,   -4.,   -7.,  -15.,  -77.,  -16.,   13.,   72., -244.,\n",
       "                        103.,  -73.]], device='cuda:0')),\n",
       "             ('liner1.bias',\n",
       "              tensor([ 57.,   9., -10.,  47., -74.,  22.,  -6.,  52.,  31., -52.],\n",
       "                     device='cuda:0'))])"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = torch.load( file_name)\n",
    "for ele in model.state_dict():#turn to numpy\n",
    "    model.state_dict()[ele]=model.state_dict()[ele].cpu().numpy()\n",
    "#turn float to int\n",
    "for layers in model.state_dict():\n",
    "    try:\n",
    "        model.state_dict()[layers].shape[1]## if parameter is 2D\n",
    "        row,col=model.state_dict()[layers].shape\n",
    "        for row in range(model.state_dict()[layers].shape[0]):\n",
    "            for col in range(model.state_dict()[layers].shape[1]):\n",
    "                num=int((model.state_dict()[layers][row][col]+1)/2*255-127)\n",
    "                model.state_dict()[layers][row][col]= num\n",
    "    except:\n",
    "        #model[layers].shape #1D\n",
    "        # print(model[layers].shape[0])\n",
    "        for i in range(model.state_dict()[layers].shape[0]):\n",
    "            num=int((model.state_dict()[layers][i]+1)/2*255-127)\n",
    "            model.state_dict()[layers][i]=num\n",
    "test(test_dataloader, model, loss_fn)\n",
    "model.state_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Error: \n",
      " Accuracy: 61.2%, Avg loss: 28132.917627 \n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "OrderedDict([('liner0.weight',\n",
       "              tensor([[  59.,  -59.,   59.,  ...,    0.,    0., -118.],\n",
       "                      [   0., -236.,  -59.,  ...,    0.,    0., -118.],\n",
       "                      [   0.,    0.,   59.,  ...,    0.,    0., -118.],\n",
       "                      ...,\n",
       "                      [-236., -236.,  -59.,  ...,   59.,  118., -118.],\n",
       "                      [   0.,  177.,  -59.,  ...,  -59., -177.,  118.],\n",
       "                      [ -59., -118., -177.,  ...,   59.,  -59.,    0.]], device='cuda:0')),\n",
       "             ('liner0.bias',\n",
       "              tensor([  0.,  59., -59.,  59.,   0., -59.,  59.,  59.,   0.,   0.,  59.,   0.,\n",
       "                      118.,   0.,  59., -59.,   0., -59.,   0., 118.,  59.,   0.,   0.,   0.,\n",
       "                       59., 118.,   0.,   0.,   0.,  59., 118.,   0.], device='cuda:0')),\n",
       "             ('liner1.weight',\n",
       "              tensor([[   0.,   59.,   59.,  118.,   59.,  -59.,  -59.,    0., -118., -118.,\n",
       "                          0.,    0.,  -59.,   59.,  -59.,  -59.,    0.,  -59.,    0.,  -59.,\n",
       "                          0.,  -59.,    0.,    0.,    0.,   59.,    0.,    0., -118.,    0.,\n",
       "                       -177.,    0.],\n",
       "                      [-236.,    0.,   59., -236.,    0.,  118.,  118., -177.,    0., -118.,\n",
       "                          0.,    0., -177.,    0., -177.,   59.,    0.,  354., -118., -413.,\n",
       "                          0., -177.,    0.,    0.,  177., -118.,   59.,    0., -118.,   59.,\n",
       "                        118.,  -59.],\n",
       "                      [   0., -236., -118., -118.,   59., -177.,    0.,    0.,   59.,    0.,\n",
       "                        118.,    0.,  -59.,   59.,  -59.,    0.,    0.,    0.,    0.,    0.,\n",
       "                         59.,   59.,    0.,    0.,    0.,  -59.,    0.,    0.,  -59.,   59.,\n",
       "                       -177.,    0.],\n",
       "                      [-177.,    0., -118.,  -59.,    0.,  118.,    0.,    0.,    0.,  -59.,\n",
       "                       -236.,    0.,   59.,    0.,    0.,   59.,    0., -118.,   59., -236.,\n",
       "                        177.,   59.,    0.,    0., -118., -118.,    0.,    0., -118.,  -59.,\n",
       "                         59.,   59.],\n",
       "                      [   0., -177., -118., -177.,    0.,    0.,    0.,   59.,    0.,    0.,\n",
       "                        -59.,    0., -177.,    0.,    0.,   59.,    0.,    0.,   59.,  118.,\n",
       "                       -118.,    0.,    0.,    0.,  -59., -177.,    0.,    0.,    0.,    0.,\n",
       "                         59.,    0.],\n",
       "                      [  59., -295.,   59.,    0., -177.,    0.,   59.,  118.,    0.,  -59.,\n",
       "                          0.,    0.,   59., -177.,    0., -118.,    0.,  236., -177.,    0.,\n",
       "                        295.,    0.,    0.,    0.,  177.,  118., -236.,    0.,   59., -236.,\n",
       "                        -59.,  295.],\n",
       "                      [  59.,   59.,  -59.,  118.,    0., -118.,  -59.,   59., -236.,    0.,\n",
       "                        -59.,    0.,   59.,    0.,    0.,    0.,    0., -118.,   59., -118.,\n",
       "                       -177., -118.,    0.,    0.,   59., -118.,    0.,    0.,  118.,    0.,\n",
       "                       -236.,    0.],\n",
       "                      [ -59., -472.,   59.,   59.,  -59.,    0.,  -59., -354.,   59.,   59.,\n",
       "                          0.,    0.,   59.,   59.,    0., -177.,    0.,  -59.,  -59.,   59.,\n",
       "                       -177.,   59.,    0.,    0., -177.,  118., -118.,    0., -118.,  236.,\n",
       "                         59., -354.],\n",
       "                      [  59., -118.,    0.,   59.,  118.,  -59., -295.,    0.,  354.,   59.,\n",
       "                        -59.,    0.,    0., -118.,   59.,    0.,    0.,   59.,    0.,   59.,\n",
       "                         59.,   59.,    0.,    0.,    0.,  -59.,   59.,    0., -354., -177.,\n",
       "                        -59., -177.],\n",
       "                      [   0., -118.,   59., -118.,    0.,   59., -236., -413., -236.,    0.,\n",
       "                         59.,    0.,    0.,   59.,   59.,    0.,    0., -354., -236.,   59.,\n",
       "                       -118.,   59.,    0.,    0.,    0.,  -59.,    0.,    0.,   59., -236.,\n",
       "                        118.,  -59.]], device='cuda:0')),\n",
       "             ('liner1.bias',\n",
       "              tensor([ 59.,   0.,   0.,  59., -59.,   0.,   0.,  59.,  59., -59.],\n",
       "                     device='cuda:0'))])"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = torch.load( file_name)\n",
    "A=59\n",
    "for ele in model.state_dict():#turn to numpy\n",
    "    model.state_dict()[ele]=model.state_dict()[ele].cpu().numpy()\n",
    "#turn float to int\n",
    "for layers in model.state_dict():\n",
    "    try:\n",
    "        model.state_dict()[layers].shape[1]## if parameter is 2D\n",
    "        row,col=model.state_dict()[layers].shape\n",
    "        for row in range(model.state_dict()[layers].shape[0]):\n",
    "            for col in range(model.state_dict()[layers].shape[1]):\n",
    "                num=int((model.state_dict()[layers][row][col]+1)/2*255-127)\n",
    "                model.state_dict()[layers][row][col]= round(num/A)*A\n",
    "    except:\n",
    "        #model[layers].shape #1D\n",
    "        # print(model[layers].shape[0])\n",
    "        for i in range(model.state_dict()[layers].shape[0]):\n",
    "            num=int((model.state_dict()[layers][i]+1)/2*255-127)\n",
    "            model.state_dict()[layers][i]=round(num/A)*A\n",
    "test(test_dataloader, model, loss_fn)\n",
    "model.state_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Error: \n",
      " Accuracy: 85.9%, Avg loss: 26223170.915605 \n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "OrderedDict([('liner0.weight',\n",
       "              tensor([[  2656.,  -2739.,   4233.,  ...,  -2075.,  -1992.,  -9213.],\n",
       "                      [  -498., -17596.,  -5312.,  ...,      0.,   -166., -10375.],\n",
       "                      [  -332.,   -332.,   5312.,  ...,   1826.,   -249., -10873.],\n",
       "                      ...,\n",
       "                      [-18094., -17513.,  -2573.,  ...,   3901.,  11039., -11371.],\n",
       "                      [  -747.,  12616.,  -4648.,  ...,  -5893., -15521.,   7553.],\n",
       "                      [ -7304., -11205., -12450.,  ...,   5976.,  -4814.,  -1245.]],\n",
       "                     device='cuda:0')),\n",
       "             ('liner0.bias',\n",
       "              tensor([ 1577.,  4980., -5727.,  7221., -1494., -6889.,  6889.,  6142., -1411.,\n",
       "                          0.,  2739.,  -913.,  7636., -1577.,  3237., -5810.,  -581., -2739.,\n",
       "                       -166.,  7636.,  2905.,  2158.,  -581.,  -747.,  5063.,  8300., -2241.,\n",
       "                       -913.,  1826.,  3403., 10209.,   996.], device='cuda:0')),\n",
       "             ('liner1.weight',\n",
       "              tensor([[  1826.,   5810.,   6972.,   7553.,   5146.,  -2656.,  -5893.,   1328.,\n",
       "                        -8134.,  -7636.,    415.,   -830.,  -6640.,   2739.,  -4482.,  -4648.,\n",
       "                         -249.,  -2573.,   1992.,  -4067.,   -664.,  -7138.,    166.,   -830.,\n",
       "                        -1992.,   2656.,   1162.,   1411., -10956.,   -664., -16517.,   2324.],\n",
       "                      [-17762.,    830.,   2822., -20418.,  -1743.,   9877.,   9462., -16102.,\n",
       "                        -1079.,  -8134.,  -2407.,   1328., -14359.,  -1660., -13695.,   2739.,\n",
       "                         -830.,  29631.,  -7387., -33947.,   1909., -16185.,   -913.,   1411.,\n",
       "                        16019.,  -8798.,   5312.,   -581., -11371.,   5727.,  10375.,  -2822.],\n",
       "                      [   166., -18924.,  -7719.,  -9877.,   3486., -13197.,   1328.,   1826.,\n",
       "                         7055.,   -498.,   8549.,   -498.,  -4565.,   2739.,  -6889.,    913.,\n",
       "                         1660.,  -1079.,    913.,   -830.,   3486.,   3403.,  -1660.,    996.,\n",
       "                         2075.,  -4399.,   2407.,   1411.,  -4814.,   5893., -14359.,    332.],\n",
       "                      [-15272.,  -2407., -10375.,  -2822.,  -2407.,   7802.,    664.,   2407.,\n",
       "                            0.,  -2905., -19090.,     83.,   5644.,    913.,  -1079.,   4482.,\n",
       "                         -332.,  -9213.,   2739., -17845.,  12616.,   7055.,   1577.,      0.,\n",
       "                       -10624., -11786.,     83.,  -1660.,  -7885.,  -3818.,   2822.,   4980.],\n",
       "                      [   249., -13778., -10707., -15853.,  -1328.,   2158.,  -1411.,   4233.,\n",
       "                         1494.,   1494.,  -3735.,    166., -15770.,   -498.,    498.,   4067.,\n",
       "                         -166.,    332.,   3984.,   9379.,  -8051.,   2075.,  -1079.,    249.,\n",
       "                        -4980., -12367.,    664.,    498.,   1162.,   1494.,   3735.,     83.],\n",
       "                      [  4897., -23323.,   2656.,    747., -15770.,   1328.,   3403.,  11122.,\n",
       "                          830.,  -3237.,   1909.,   -913.,   3818., -15272.,    996.,  -8383.,\n",
       "                        -1411.,  18841., -16351.,     83.,  24153.,   -332.,   -913.,  -1079.,\n",
       "                        12782.,   8300., -17596.,   -415.,   7055., -20252.,  -5063.,  24983.],\n",
       "                      [  3403.,   5810.,  -3403.,   8217.,   1245.,  -8715.,  -6474.,   2822.,\n",
       "                       -21912.,   1494.,  -4980.,   -913.,   2988.,   2324.,   1411.,   2158.,\n",
       "                          -83.,  -8466.,   2656., -11371., -13778.,  -7968.,    166.,   1079.,\n",
       "                         2822.,  -8881.,  -1162.,   1245.,  12118.,   1494., -17845.,  -1743.],\n",
       "                      [ -3403., -36935.,   2822.,   3652.,  -6225.,   1577.,  -3569., -30046.,\n",
       "                         2739.,   4482.,   1162.,   -830.,   2573.,   4399.,   1826., -12616.,\n",
       "                         -249.,  -5312.,  -5561.,   4316., -15438.,   3735.,   1577.,   1577.,\n",
       "                       -16600.,   7719.,  -8217.,   -664.,  -8964.,  17845.,   6308., -29050.],\n",
       "                      [  3154., -10873.,   1992.,   2739.,   7387.,  -5478., -24070.,   -996.,\n",
       "                        29797.,   2988.,  -7055.,    -83.,    249., -11039.,   5478.,   2241.,\n",
       "                         -747.,   5976.,   -747.,   6391.,   6474.,   3652.,    415.,  -1162.,\n",
       "                        -1577.,  -4482.,   4399.,    249., -30793., -12533.,  -2656., -13944.],\n",
       "                      [   249.,  -8798.,   4731., -11371.,  -2075.,   5976., -20584., -33449.,\n",
       "                       -19339.,  -1162.,   7221.,   -664.,   2158.,   3403.,   3320.,  -2407.,\n",
       "                          249., -29714., -20667.,   5644.,  -9545.,   3818.,   -332.,   -581.,\n",
       "                        -1245.,  -6391.,  -1328.,   1079.,   5976., -20252.,   8549.,  -6059.]],\n",
       "                     device='cuda:0')),\n",
       "             ('liner1.bias',\n",
       "              tensor([ 4731.,   747.,  -830.,  3901., -6142.,  1826.,  -498.,  4316.,  2573.,\n",
       "                      -4316.], device='cuda:0'))])"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = torch.load( file_name)\n",
    "A=83\n",
    "for ele in model.state_dict():#turn to numpy\n",
    "    model.state_dict()[ele]=model.state_dict()[ele].cpu().numpy()\n",
    "#turn float to int\n",
    "for layers in model.state_dict():\n",
    "    try:\n",
    "        model.state_dict()[layers].shape[1]## if parameter is 2D\n",
    "        row,col=model.state_dict()[layers].shape\n",
    "        for row in range(model.state_dict()[layers].shape[0]):\n",
    "            for col in range(model.state_dict()[layers].shape[1]):\n",
    "                num=int((model.state_dict()[layers][row][col]+1)/2*255-127)\n",
    "                model.state_dict()[layers][row][col]= round(num)*A\n",
    "    except:\n",
    "        #model[layers].shape #1D\n",
    "        # print(model[layers].shape[0])\n",
    "        for i in range(model.state_dict()[layers].shape[0]):\n",
    "            num=int((model.state_dict()[layers][i]+1)/2*255-127)\n",
    "            model.state_dict()[layers][i]=round(num)*A\n",
    "test(test_dataloader, model, loss_fn)\n",
    "model.state_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "#turn img from float to int\n",
    "def int_conver(np_a):\n",
    "    for idx,ele in enumerate(np_a):\n",
    "        np_a[idx]=int((ele+1)/2*255-127)\n",
    "\n",
    "    return np_a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n",
      "0:  25\n",
      "1:  41\n",
      "4\n"
     ]
    }
   ],
   "source": [
    "hit=0\n",
    "lrsb0_len=layer0_output_size\n",
    "lrsb2_len=10\n",
    "max_0,min_0=0,0\n",
    "max_1,min_1=0,0\n",
    "\n",
    "lrsw0=model.state_dict()[\"liner0.weight\"].reshape(-1).cpu().numpy()\n",
    "lrsb0=model.state_dict()[\"liner0.bias\"].reshape(-1).cpu().numpy()\n",
    "lrsw2=model.state_dict()[\"liner1.weight\"].reshape(-1).cpu().numpy()\n",
    "lrsb2=model.state_dict()[\"liner1.bias\"].reshape(-1).cpu().numpy()\n",
    "for r in range(10):    \n",
    "    img,label=test_data[6]\n",
    "    img=img.reshape(-1)\n",
    "    img=int_conver(img)\n",
    "\n",
    "    out1=np.zeros(lrsb0_len)\n",
    "    out2=np.zeros(lrsb2_len)\n",
    "    \n",
    "    for i in range(lrsb0_len):\n",
    "        for j in range(input_img_sz*input_img_sz):\n",
    "            out1[i]+=lrsw0[i*input_img_sz*input_img_sz+j]*img[j]\n",
    "        out1[i]+=lrsb0[i]\n",
    "    # print(out1)\n",
    "\n",
    "    for i in range(lrsb0_len):\n",
    "        if(out1[i]>max_0):\n",
    "            max_0=out1[i]\n",
    "        if(out1[i]<min_0):\n",
    "            min_0=out1[i]\n",
    "        if(out1[i]<0):\n",
    "            out1[i]=0\n",
    "\n",
    "    for i in range(lrsb2_len):\n",
    "        for j in range(lrsb0_len):\n",
    "            out2[i]+=lrsw2[i*lrsb0_len+j]*out1[j]\n",
    "        out2[i]+=lrsb2[i]\n",
    "\n",
    "    for i in range(10):\n",
    "        if(out2[i]>max_1):\n",
    "            max_1=out2[i]\n",
    "        if(out2[i]<min_1):\n",
    "            min_1=out2[i]\n",
    "    \n",
    "    if(out2.argmax()==label):\n",
    "        hit+=1\n",
    "\n",
    "    # print(\"now:\",r+1,\"hit:\",hit)\n",
    "print(hit)\n",
    "layer0_bit = len(bin(int(max_0)))\n",
    "layer2_bit = len(bin(int(max_1)))+2\n",
    "print(\"0: \",layer0_bit)\n",
    "print(\"1: \",layer2_bit)\n",
    "print(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'-(0+(reg<<0)-(reg<<2)+(reg<<5))'"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import TCB\n",
    "def D2reg(num,reg_name):\n",
    "    if(num==0):\n",
    "        return None\n",
    "    else:\n",
    "        tcb_str=TCB.Bin2TCB(int(num))\n",
    "        temp=0\n",
    "        if(num>0):\n",
    "            out_s=\"+(0\"\n",
    "        else:\n",
    "            out_s=\"-(0\"\n",
    "        for s in reversed(tcb_str):\n",
    "            if(s==\"+\"):\n",
    "                out_s+=\"+(\"+reg_name+\"<<\"+str(temp)+\")\"\n",
    "            if(s==\"-\"):\n",
    "                out_s+=\"-(\"+reg_name+\"<<\"+str(temp)+\")\"\n",
    "            temp+=1         \n",
    "            \n",
    "        return out_s+\")\"\n",
    "D2reg(-29,\"reg\")        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "wire_cnt 32\n",
      "wire_cnt 32\n"
     ]
    }
   ],
   "source": [
    "\n",
    "img_size=input_img_sz*input_img_sz\n",
    "wire_cnt=layer0_output_size\n",
    "in_buffer_weight_name=\"in_buffer_weight\"\n",
    "weight_to_bias_name=\"weight_bias\"\n",
    "bias_relu_name=\"bias_relu\"\n",
    "in_buffer_weight_parameter=model.state_dict()[\"liner0.weight\"]\n",
    "weight_bias_parameter=model.state_dict()[\"liner0.bias\"]\n",
    "#data_bit_num=20\n",
    "data_bit_num=layer0_bit\n",
    "file_destination = \"verilog_net0\"\n",
    "\n",
    "layer0_verilog_file_name=\"layer0_tcb_\"+str(img_size)+\"x\"+str(layer0_output_size)+\"x10\"\n",
    "f=open(\"./\"+file_destination+\"/\"+layer0_verilog_file_name+\".v\",\"w\")\n",
    "f.write(\"module \"+layer0_verilog_file_name+\"\\n\")\n",
    "f.write(\"(\\n\")\n",
    "\n",
    "f.write(\"\\\n",
    "    input clk,\\n\\\n",
    "    input rst,\\n\\\n",
    "    input [\"+str(img_size)+\"*8-1:0] img,\\n\\\n",
    "    input valid,\\n\\\n",
    "    output  reg ready,\\n\\\n",
    "    output [\"+str(data_bit_num)+\"*\"+str(layer0_output_size)+\"-1:0] layer_out\\n\"\\\n",
    ")\n",
    "f.write(\");\\n\")\n",
    "f.write(\"parameter DATA_WIDTH = \"+str(data_bit_num)+\";\\n\")\n",
    "f.write(\"parameter IMG_SZ   =   \"+str(img_size)+\";\\n\")\n",
    "\n",
    "f.write(\"reg    signed [8-1:0]  in_buffer[0:IMG_SZ-1];\\n\")\n",
    "f.write(\"integer i;\\n\")\n",
    "f.write(\"always@(posedge clk )\\n\\\n",
    "    begin\\n\\\n",
    "        if(rst)\\n\\\n",
    "            begin\\n\\\n",
    "                for(i=0;i<IMG_SZ;i=i+1)\\n\\\n",
    "                    begin\\n\\\n",
    "                        in_buffer[i]<=0;\\n\\\n",
    "                    end\\n\\\n",
    "            end\\n\\\n",
    "        else\\n\\\n",
    "        begin\\n\")\n",
    "\n",
    "for i in range(img_size):\n",
    "    f.write(\"       in_buffer[\"+str(i)+\"]<=img[\"+str(7+i*8)+\":\"+str(0+i*8)+\"];\\n\")           \n",
    "f.write(\"        end\\n   end\\n\")\n",
    "for naming_idx in range(wire_cnt): \n",
    "    f.write(\"wire signed  [DATA_WIDTH-1:0]   \")   \n",
    "    f.write(in_buffer_weight_name+str(naming_idx)+\";\\n\")\n",
    "    f.write(\"assign \"+in_buffer_weight_name+str(naming_idx)+\"=0\")\n",
    "    #insert tcb\n",
    "    for in_buf_idx in range(img_size):\n",
    "        name=\"in_buffer[\" +str(in_buf_idx)+\"]\"\n",
    "        num=int(in_buffer_weight_parameter[naming_idx][in_buf_idx])\n",
    "        try:\n",
    "            f.write(D2reg(num,name))\n",
    "        except:\n",
    "            pass\n",
    "    f.write(\";\\n\")\n",
    "\n",
    "#weight0 to bias0\n",
    "previous_layer_name=in_buffer_weight_name\n",
    "#naming wire\n",
    "print(\"wire_cnt\",wire_cnt)\n",
    "for naming_idx in range(wire_cnt): \n",
    "    f.write(\"wire signed [DATA_WIDTH-1:0]   \")   \n",
    "    f.write(weight_to_bias_name+str(naming_idx)+\";\\n\")\n",
    "for naming_idx in range(wire_cnt):\n",
    "    f.write(\"assign \"+weight_to_bias_name+str(naming_idx)+\"=\")\n",
    "    f.write(previous_layer_name+str(naming_idx))\n",
    "    f.write(\"+(\")\n",
    "    f.write(str(int(weight_bias_parameter[naming_idx])))\n",
    "\n",
    "    f.write(\");\\n\")\n",
    "#bias0 to relu0\n",
    "previous_layer_name=weight_to_bias_name\n",
    "#naming wire\n",
    "print(\"wire_cnt\",wire_cnt)\n",
    "for naming_idx in range(wire_cnt): \n",
    "    f.write(\"wire signed [DATA_WIDTH-1:0]   \")   \n",
    "    f.write(bias_relu_name+str(naming_idx)+\";\\n\")\n",
    "for naming_idx in range(wire_cnt):\n",
    "    f.write(\"assign \"+bias_relu_name+str(naming_idx)+\"=(\")\n",
    "    f.write(previous_layer_name+str(naming_idx))\n",
    "    f.write(\"[DATA_WIDTH-1]==1'b1)   ?   \")\n",
    "    f.write(\"{DATA_WIDTH{1'b0}}:\")\n",
    "    f.write(previous_layer_name+str(naming_idx))\n",
    "    f.write(\";\\n\")\n",
    "\n",
    "\n",
    "f.write(\"assign layer_out={\")\n",
    "for naming_idx in range(wire_cnt-1,-1,-1):\n",
    "    if(naming_idx==0):\n",
    "        f.write(bias_relu_name+str(naming_idx))\n",
    "    else:\n",
    "        f.write(bias_relu_name+str(naming_idx)+\",\")\n",
    "f.write(\"};\\n\")\n",
    "f.write(\"always@(posedge clk)\\n\\\n",
    "    begin\\n\\\n",
    "        if(rst)\\n\\\n",
    "            begin\\n\\\n",
    "                ready<=1'b0;\\n\\\n",
    "            end\\n\\\n",
    "        else\\n\\\n",
    "            begin\\n\\\n",
    "                ready<=valid;\\n\\\n",
    "            end\\n\\\n",
    "    end\\n\")\n",
    "f.write(\"endmodule\")\n",
    "f.close()\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "last_output_sz=layer0_output_size\n",
    "last_layer_data_sz=layer0_bit\n",
    "\n",
    "wire_cnt=10\n",
    "in_buffer_weight_name=\"in_buffer_weight\"\n",
    "weight_to_bias_name=\"weight_bias\"\n",
    "bias_relu_name=\"bias_relu\"\n",
    "in_buffer_weight_parameter=model.state_dict()[\"liner1.weight\"]\n",
    "weight_bias_parameter=model.state_dict()[\"liner1.bias\"]\n",
    "\n",
    "layer2_verilog_file_name=\"layer2_tcb_\"+str(img_size)+\"x\"+str(layer0_output_size)+\"x10\"\n",
    "f=open(\"./\"+file_destination+\"/\"+layer2_verilog_file_name+\".v\",\"w\")\n",
    "f.write(\"module \"+layer2_verilog_file_name+\"\\n\")\n",
    "f.write(\"(\\n\")\n",
    "\n",
    "f.write(\"\\\n",
    "    input clk,\\n\\\n",
    "    input rst,\\n\")\n",
    "f.write(\"   input valid,\\n\")\n",
    "f.write(\"   output  reg ready,\\n\")\n",
    "f.write(\"    input [\"+str(last_layer_data_sz)+\"*\"+str(last_output_sz)+\"-1:0]  layer_in,\\n\")\n",
    "f.write(\"    output [\"+str(layer2_bit)+\"*10-1:0]   layer_out\\n\\\n",
    ");\\n\")\n",
    "f.write(\"parameter DATA_WIDTH   =   \"+str(layer2_bit)+\";\\n\")\n",
    "f.write(\"reg [DATA_WIDTH-1:0]    layer_in_buffer    [0:\"+str(last_output_sz)+\"-1];\\n\")\n",
    "f.write(\"integer i;\\n\")\n",
    "f.write(\"always@(posedge clk )\\n\\\n",
    "    begin\\n\\\n",
    "        if(rst)\\n\\\n",
    "            begin\\n\")\n",
    "f.write(\"                for(i=0;i<\"+str(last_output_sz)+\";i=i+1)\\n\\\n",
    "                    begin\\n\\\n",
    "                        layer_in_buffer[i]<=0;\\n\\\n",
    "                    end\\n\\\n",
    "            end\\n\\\n",
    "        else\\n\\\n",
    "        begin\\n\")\n",
    "for i in range(last_output_sz):\n",
    "    f.write(\"       layer_in_buffer[\"+str(i)+\"]<=layer_in[\"+str(last_layer_data_sz-1+i*last_layer_data_sz)+\":\"+str(0+i*last_layer_data_sz)+\"];\\n\")           \n",
    "f.write(\"        end\\n   end\\n\")\n",
    "\n",
    "\n",
    "f.write(\"\\n\")\n",
    "previous_layer_name=\"layer_in_buffer\"\n",
    "#naming wire\n",
    "for naming_idx in range(wire_cnt): \n",
    "    f.write(\"wire [DATA_WIDTH-1:0]   \")   \n",
    "    f.write(in_buffer_weight_name+str(naming_idx)+\";\\n\")\n",
    "    f.write(\"assign \"+in_buffer_weight_name+str(naming_idx)+\"=0\")\n",
    "    for previoud_layer_idx in range(last_output_sz):\n",
    "        name=previous_layer_name+\"[\"+str(previoud_layer_idx)+\"]\"\n",
    "        num=int(in_buffer_weight_parameter[naming_idx][previoud_layer_idx])\n",
    "        try:\n",
    "            f.write(D2reg(num,name))\n",
    "        except:\n",
    "            pass\n",
    "    f.write(\";\\n\")\n",
    "# weight4 to bias4 \n",
    "\n",
    "previous_layer_name=in_buffer_weight_name\n",
    "#naming wire\n",
    "for naming_idx in range(wire_cnt): \n",
    "    f.write(\"wire [DATA_WIDTH-1:0]   \")   \n",
    "    f.write(weight_to_bias_name+str(naming_idx)+\";\\n\")\n",
    "    f.write(\"assign \"+weight_to_bias_name+str(naming_idx)+\"=\")\n",
    "    f.write(previous_layer_name+str(naming_idx))\n",
    "    f.write(\"+(\")\n",
    "    f.write(str(int(weight_bias_parameter[naming_idx])))\n",
    "    f.write(\");\\n\")\n",
    "f.write(\"assign layer_out={\\n\")\n",
    "for naming_idx in range(wire_cnt-1,-1,-1): \n",
    "    if(naming_idx==0):\n",
    "        f.write(\"            \"+weight_to_bias_name+str(naming_idx))\n",
    "    else:\n",
    "        f.write(\"            \"+weight_to_bias_name+str(naming_idx)+\",\\n\")\n",
    "f.write(\"};\\n\")\n",
    "f.write(\"always@(posedge clk)\\n\\\n",
    "    begin\\n\\\n",
    "        if(rst)\\n\\\n",
    "            begin\\n\\\n",
    "                ready<=1'b0;\\n\\\n",
    "            end\\n\\\n",
    "        else\\n\\\n",
    "            begin\\n\\\n",
    "                ready<=valid;\\n\\\n",
    "            end\\n\\\n",
    "    end\\n\")\n",
    "f.write(\"endmodule\\n\")\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_sz=layer2_bit\n",
    "f=open(\"./\"+file_destination+\"/comparator_30bit.v\",\"w\")\n",
    "f.write(\"module comparator\\n\")\n",
    "f.write(\"(\\n\")\n",
    "f.write(\"input [\"+str(data_sz)+\"*10-1:0] layer_out,\\n\")\n",
    "f.write(\"input rst,\\n\")\n",
    "f.write(\"input clk,\\n\")\n",
    "f.write(\"input valid,\\n\")\n",
    "f.write(\"output  reg ready,\\n\")\n",
    "f.write(\"output reg [7:0] predict\\n\")\n",
    "f.write(\");\\n\")\n",
    "f.write(\"parameter DATA_WIDTH=\"+str(data_sz)+\";\\n\")\n",
    "f.write(\"reg [DATA_WIDTH-1: 0] result [0:9];\\n\")\n",
    "f.write(\"wire [4+DATA_WIDTH-1:0] com_re01,com_re23,com_re45,com_re67,com_re89;\\n\")\n",
    "f.write(\"reg ready_temp;\\n\")\n",
    "f.write(\"always@(posedge clk)\\n\\\n",
    "    begin\\n\\\n",
    "        if(rst)\\n\\\n",
    "            begin\\n\\\n",
    "                ready<=1'b0;\\n\\\n",
    "                ready_temp<=1'b0;\\n\\\n",
    "            end\\n\\\n",
    "        else\\n\\\n",
    "            begin\\n\\\n",
    "                ready_temp<=valid;\\n\\\n",
    "                ready<=ready_temp;\\n\\\n",
    "            end\\n\\\n",
    "    end\\n\")\n",
    "\n",
    "f.write(\" \\n\\\n",
    "assign com_re01=(result[0][DATA_WIDTH-1]^result[1][DATA_WIDTH-1]) ? \\n\\\n",
    "                                                        ((result[0][DATA_WIDTH-1]==1'b0)   ?   {4'd0,result[0]}:{4'd1,result[1]}):\\n\\\n",
    "                                                        ((result[0]>result[1]) ? {4'd0,result[0]}:{4'd1,result[1]});\\n\\\n",
    "assign com_re23=(result[2][DATA_WIDTH-1]^result[3][DATA_WIDTH-1]) ? \\n\\\n",
    "                                                        ((result[2][DATA_WIDTH-1]==1'b0)   ?   {4'd2,result[2]}:{4'd3,result[3]}):\\n\\\n",
    "                                                        ((result[2]>result[3]) ? {4'd2,result[2]}:{4'd3,result[3]});\\n\\\n",
    "assign com_re45=(result[4][DATA_WIDTH-1]^result[5][DATA_WIDTH-1]) ? \\n\\\n",
    "                                                        ((result[4][DATA_WIDTH-1]==1'b0)   ?   {4'd4,result[4]}:{4'd5,result[5]}):\\n\\\n",
    "                                                        ((result[4]>result[5]) ? {4'd4,result[4]}:{4'd5,result[5]});\\n\")  \n",
    "f.write(\"\\n\\\n",
    "assign com_re67=(result[6][DATA_WIDTH-1]^result[7][DATA_WIDTH-1]) ? \\n\\\n",
    "                                                        ((result[6][DATA_WIDTH-1]==1'b0)   ?   {4'd6,result[6]}:{4'd7,result[7]}):\\n\\\n",
    "                                                        ((result[6]>result[7]) ? {4'd6,result[6]}:{4'd7,result[7]});\\n\\\n",
    "assign com_re89=(result[8][DATA_WIDTH-1]^result[9][DATA_WIDTH-1]) ? \\n\\\n",
    "                                                        ((result[8][DATA_WIDTH-1]==1'b0)   ?   {4'd8,result[8]}:{4'd9,result[9]}):\\n\\\n",
    "                                                        ((result[8]>result[9]) ? {4'd8,result[8]}:{4'd9,result[9]});\\n\\\n",
    "wire [4+DATA_WIDTH-1:0] com_re01_23,com_re45_67,com_re0123_4567,com_re01234567_89;\\n\\\n",
    "assign com_re01_23=(com_re01[DATA_WIDTH-1]^com_re23[DATA_WIDTH-1])   ?\\n\\\n",
    "                                                        ((com_re01[DATA_WIDTH-1]==1'b0)  ?   com_re01:com_re23):\\n\\\n",
    "                                                        ((com_re01[DATA_WIDTH-1:0]>com_re23[DATA_WIDTH-1:0]) ?   com_re01:com_re23);\\n\\\n",
    "assign com_re45_67=(com_re45[DATA_WIDTH-1]^com_re67[DATA_WIDTH-1])   ?\\n\\\n",
    "                                                        ((com_re45[DATA_WIDTH-1]==1'b0)  ?   com_re45:com_re67):\\n\\\n",
    "                                                        ((com_re45[DATA_WIDTH-1:0]>com_re67[DATA_WIDTH-1:0]) ?   com_re45:com_re67);\\n\\\n",
    "assign com_re0123_4567=(com_re01_23[DATA_WIDTH-1]^com_re45_67[DATA_WIDTH-1])   ?\\n\\\n",
    "                                                        ((com_re01_23[DATA_WIDTH-1]==1'b0)  ?   com_re01_23:com_re45_67):\\n\\\n",
    "                                                        ((com_re01_23[DATA_WIDTH-1:0]>com_re45_67[DATA_WIDTH-1:0]) ?   com_re01_23:com_re45_67);\\n\\\n",
    "assign com_re01234567_89=(com_re0123_4567[DATA_WIDTH-1]^com_re89[DATA_WIDTH-1])   ?\\n\\\n",
    "                                                        ((com_re0123_4567[DATA_WIDTH-1]==1'b0)  ?   com_re0123_4567:com_re89):\\n\\\n",
    "                                                        ((com_re0123_4567[DATA_WIDTH-1:0]>com_re89[DATA_WIDTH-1:0]) ?   com_re0123_4567:com_re89);\\n\")\n",
    "f.write(\"integer i;\\n\")\n",
    "f.write(\"always@(posedge clk )\\n\")\n",
    "f.write(\"begin\\n\\\n",
    "    if(rst)\\n\\\n",
    "            begin\\n\\\n",
    "                for(i=0;i<10;i=i+1)\\n\\\n",
    "                    begin\\n\\\n",
    "                        result[i]<={\"+str(data_sz)+\"'b0};\\n\\\n",
    "                    end\\n\\\n",
    "                predict<=0;\\n\\\n",
    "            end\\n\\\n",
    "    else\\n\\\n",
    "    begin \\n\")\n",
    "f.write(\"\\\n",
    "        predict <={4'b0,com_re01234567_89[4+DATA_WIDTH-1:4+DATA_WIDTH-1-3]};\\n\")\n",
    "for i in range(10):\n",
    "    f.write(\"       result[\"+str(i)+\"]<=layer_out[\"+str(data_sz-1+data_sz*i)+\":\"+str(data_sz*i)+\"];\\n\")\n",
    "f.write(\"\\\n",
    "    end\\n\\\n",
    "end\\n\")\n",
    "\n",
    "\n",
    "\n",
    "f.write(\"endmodule\\n\")\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "layer0_port=layer0_output_size\n",
    "layer2_port=10\n",
    "tb_name=\"top_tcb_\"+str(input_img_sz*input_img_sz)+\"_\"+str(layer0_output_size)+\"_10\"\n",
    "f=open(\"./\"+file_destination+\"/\"+tb_name+\".v\",\"w\")\n",
    "f.write(\"module \"+tb_name+\"(\\n\")\n",
    "f.write(\"input clk,\\n\\\n",
    "input rst,\\n\\\n",
    "input [\"+str(input_img_sz*input_img_sz)+\"*8-1:0] img_source,\\n\\\n",
    "output [31:0] number,\\n\")\n",
    "f.write(\"input valid_top,\\n\")\n",
    "f.write(\"output  ready_top\\n\")\n",
    "f.write(\");\\n\")\n",
    "f.write(\"wire layer0_ready,layer2_ready\\n;\")\n",
    "f.write(\"wire   [\"+str(layer0_bit)+\"*\"+str(layer0_port)+\"-1:0] layer0_out;\\n\")\n",
    "f.write(\"wire   [\"+str(layer2_bit)+\"*\"+str(layer2_port)+\"-1:0] layer2_out;\\n\")\n",
    "f.write(layer0_verilog_file_name+\" DUT_layer0   (.clk(clk),.rst(rst),.img(img_source),.layer_out(layer0_out),.ready(layer0_ready),.valid(valid_top));\\n\")\n",
    "f.write(layer2_verilog_file_name+\" DUT_layer2   (.clk(clk),.rst(rst),.layer_in(layer0_out),.layer_out(layer2_out),.ready(layer2_ready),.valid(layer0_ready));\\n\")\n",
    "f.write(\"comparator DUT_comparator (.clk(clk),.rst(rst),.layer_out(layer2_out),.predict(number),.ready(ready_top),.valid(layer2_ready));\\n\")\n",
    "\n",
    "f.write(\"endmodule\\n\")\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "f=open(\"./\"+file_destination+\"/tb.v\",\"w\")\n",
    "f.write(\"`timescale 1ns/1ps\\n\")\n",
    "f.write(\"module tb;\\n\")\n",
    "\n",
    "f.write(\"reg clk,rst,valid;\\n\")\n",
    "f.write(\"reg [\"+str(input_img_sz*input_img_sz*8)+\"-1:0] img;\\n\")\n",
    "f.write(\"wire [7:0] number;\\n\")\n",
    "f.write(tb_name+\" top_DUT(\\n\\\n",
    "    .clk(clk),\\n\\\n",
    "    .rst(rst),\\n\\\n",
    "    .img_source(img),\\n\\\n",
    "    .valid_top(valid),\\n\\\n",
    "    .ready_top(ready_top),\\n\\\n",
    "    .number(number)\\n\\\n",
    ");\\n\")\n",
    "f.write(\"always #5 clk=~clk;\\n\")\n",
    "f.write(\"initial \\nbegin\\n\")\n",
    "f.write(\"$monitor(\\\"number is %d\\\",number);\\n\")\n",
    "f.write(\"clk=0;rst=1'b1;valid=1'b1;\\n\")\n",
    "f.write(\"img=\"+str(input_img_sz*input_img_sz)+\"'b0;\\n\")\n",
    "f.write(\"#10 rst=1'b0;\\n\")\n",
    "for i in range(10):\n",
    "    f.write(\"@(negedge clk) #(10/4) img=\"+str(input_img_sz*input_img_sz*8)+\"'b\")\n",
    "    img,idx=test_data[i]\n",
    "    img=img.reshape(-1)\n",
    "    img=np.asarray(img)\n",
    "    img=int_conver(img)\n",
    "    for ele in reversed(img):\n",
    "        eight_bit=\"{:08b}\".format(int(ele))\n",
    "        f.write(eight_bit)\n",
    "        #print(ele)\n",
    "    f.write(\";\\n\")\n",
    "\n",
    "\n",
    "\n",
    "f.write(\"#100 $finish;\\n\")\n",
    "\n",
    "\n",
    "f.write(\"end\\n\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "f.write(\"endmodule\\n\")\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "f=open(\"./\"+file_destination+\"/label.txt\",\"w\")\n",
    "for i in range(10):\n",
    "    img,idx=test_data[i]\n",
    "    f.write(str(idx))\n",
    "    f.write(\"\\n\")\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
