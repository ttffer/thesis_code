{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torchvision\n",
    "from torchvision import datasets\n",
    "from torchvision.transforms import ToTensor\n",
    "test_data = datasets.MNIST(\n",
    "    root=\"data\",\n",
    "    train=False,\n",
    "    download=True,\n",
    "    transform=ToTensor(),\n",
    ")\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets\n",
    "from torchvision.transforms import ToTensor\n",
    "import numpy as np\n",
    "import torch.onnx\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_img_sz=11\n",
    "layer0_output_size =64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "# Download training data from open datasets.\n",
    "training_data = datasets.MNIST(\n",
    "    root=\"../data\",    \n",
    "    train=True,\n",
    "    download=True,\n",
    "    transform=torchvision.transforms.Compose(\n",
    "        [torchvision.transforms.Resize(input_img_sz), torchvision.transforms.ToTensor()]\n",
    "    ),\n",
    ")\n",
    "\n",
    "# Download test data from open datasets.\n",
    "test_data = datasets.MNIST(\n",
    "    root=\"../data\",\n",
    "    train=False,\n",
    "    download=True,\n",
    "    transform=torchvision.transforms.Compose(\n",
    "        [torchvision.transforms.Resize(input_img_sz), torchvision.transforms.ToTensor()]\n",
    "    ),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda device\n",
      "NeuralNetwork(\n",
      "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
      "  (liner0): Linear(in_features=121, out_features=64, bias=True)\n",
      "  (relu): ReLU(inplace=True)\n",
      "  (liner1): Linear(in_features=64, out_features=10, bias=True)\n",
      ")\n",
      "Shape of X [N, C, H, W]: torch.Size([64, 1, 11, 11])\n",
      "Shape of y: torch.Size([64]) torch.int64\n"
     ]
    }
   ],
   "source": [
    "# Get cpu or gpu device for training.\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(f\"Using {device} device\")\n",
    "\n",
    "# Define model\n",
    "class NeuralNetwork(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(NeuralNetwork, self).__init__()\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.liner0 = nn.Linear(input_img_sz*input_img_sz, layer0_output_size)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.liner1 =nn.Linear(layer0_output_size, 10)\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.flatten(x)\n",
    "        x = self.liner0(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.liner1(x)\n",
    "        return x\n",
    "\n",
    "model = NeuralNetwork().to(device)\n",
    "print(model)\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "\n",
    "# optimizer = torch.optim.SGD(model.parameters(), lr=1e-3)\n",
    "optimizer = torch.optim.Adam(model.parameters(),lr=1e-3)\n",
    "def train(dataloader, model, loss_fn, optimizer):\n",
    "    size = len(dataloader.dataset)\n",
    "    model.train()\n",
    "    for batch, (X, y) in enumerate(dataloader):\n",
    "        X, y = X.to(device), y.to(device)\n",
    "\n",
    "        # Compute prediction error\n",
    "        pred = model(X)\n",
    "        loss = loss_fn(pred, y)\n",
    "\n",
    "        # Backpropagation\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        if batch % 100 == 0:\n",
    "            loss, current = loss.item(), batch * len(X)\n",
    "            print(f\"loss: {loss:>7f}  [{current:>5d}/{size:>5d}]\")\n",
    "\n",
    "def test(dataloader, model, loss_fn):\n",
    "    size = len(dataloader.dataset)\n",
    "    num_batches = len(dataloader)\n",
    "    model.eval()\n",
    "    test_loss, correct = 0, 0\n",
    "    with torch.no_grad():\n",
    "        for X, y in dataloader:\n",
    "            X, y = X.to(device), y.to(device)\n",
    "            pred = model(X)\n",
    "            test_loss += loss_fn(pred, y).item()\n",
    "            correct += (pred.argmax(1) == y).type(torch.float).sum().item()\n",
    "    test_loss /= num_batches\n",
    "    correct /= size\n",
    "    print(f\"Test Error: \\n Accuracy: {(100*correct):>0.1f}%, Avg loss: {test_loss:>8f} \\n\")\n",
    "batch_size = 64\n",
    "\n",
    "# Create data loaders.\n",
    "train_dataloader = DataLoader(training_data, batch_size=batch_size)\n",
    "test_dataloader = DataLoader(test_data, batch_size=batch_size)\n",
    "\n",
    "for X, y in test_dataloader:\n",
    "    print(f\"Shape of X [N, C, H, W]: {X.shape}\")\n",
    "    print(f\"Shape of y: {y.shape} {y.dtype}\")\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1\n",
      "-------------------------------\n",
      "loss: 2.315503  [    0/60000]\n",
      "loss: 1.340056  [ 6400/60000]\n",
      "loss: 0.805975  [12800/60000]\n",
      "loss: 0.563677  [19200/60000]\n",
      "loss: 0.469248  [25600/60000]\n",
      "loss: 0.441606  [32000/60000]\n",
      "loss: 0.298564  [38400/60000]\n",
      "loss: 0.499447  [44800/60000]\n",
      "loss: 0.418937  [51200/60000]\n",
      "loss: 0.445694  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 90.3%, Avg loss: 0.343857 \n",
      "\n",
      "Epoch 2\n",
      "-------------------------------\n",
      "loss: 0.342436  [    0/60000]\n",
      "loss: 0.321536  [ 6400/60000]\n",
      "loss: 0.277249  [12800/60000]\n",
      "loss: 0.383708  [19200/60000]\n",
      "loss: 0.272033  [25600/60000]\n",
      "loss: 0.346908  [32000/60000]\n",
      "loss: 0.177341  [38400/60000]\n",
      "loss: 0.380590  [44800/60000]\n",
      "loss: 0.303263  [51200/60000]\n",
      "loss: 0.394382  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 91.8%, Avg loss: 0.279700 \n",
      "\n",
      "Epoch 3\n",
      "-------------------------------\n",
      "loss: 0.241051  [    0/60000]\n",
      "loss: 0.275116  [ 6400/60000]\n",
      "loss: 0.223886  [12800/60000]\n",
      "loss: 0.326557  [19200/60000]\n",
      "loss: 0.232827  [25600/60000]\n",
      "loss: 0.298224  [32000/60000]\n",
      "loss: 0.136315  [38400/60000]\n",
      "loss: 0.336798  [44800/60000]\n",
      "loss: 0.230835  [51200/60000]\n",
      "loss: 0.367509  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 92.9%, Avg loss: 0.239281 \n",
      "\n",
      "Epoch 4\n",
      "-------------------------------\n",
      "loss: 0.190003  [    0/60000]\n",
      "loss: 0.237055  [ 6400/60000]\n",
      "loss: 0.189342  [12800/60000]\n",
      "loss: 0.284862  [19200/60000]\n",
      "loss: 0.215728  [25600/60000]\n",
      "loss: 0.263754  [32000/60000]\n",
      "loss: 0.108400  [38400/60000]\n",
      "loss: 0.310618  [44800/60000]\n",
      "loss: 0.185241  [51200/60000]\n",
      "loss: 0.350876  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 93.8%, Avg loss: 0.208877 \n",
      "\n",
      "Epoch 5\n",
      "-------------------------------\n",
      "loss: 0.158679  [    0/60000]\n",
      "loss: 0.207125  [ 6400/60000]\n",
      "loss: 0.163800  [12800/60000]\n",
      "loss: 0.256256  [19200/60000]\n",
      "loss: 0.201064  [25600/60000]\n",
      "loss: 0.241592  [32000/60000]\n",
      "loss: 0.088027  [38400/60000]\n",
      "loss: 0.289323  [44800/60000]\n",
      "loss: 0.165406  [51200/60000]\n",
      "loss: 0.331185  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 94.6%, Avg loss: 0.186481 \n",
      "\n",
      "Epoch 6\n",
      "-------------------------------\n",
      "loss: 0.139107  [    0/60000]\n",
      "loss: 0.183118  [ 6400/60000]\n",
      "loss: 0.149140  [12800/60000]\n",
      "loss: 0.236864  [19200/60000]\n",
      "loss: 0.190755  [25600/60000]\n",
      "loss: 0.226537  [32000/60000]\n",
      "loss: 0.073298  [38400/60000]\n",
      "loss: 0.270297  [44800/60000]\n",
      "loss: 0.152351  [51200/60000]\n",
      "loss: 0.310261  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 95.1%, Avg loss: 0.170502 \n",
      "\n",
      "Epoch 7\n",
      "-------------------------------\n",
      "loss: 0.123888  [    0/60000]\n",
      "loss: 0.165101  [ 6400/60000]\n",
      "loss: 0.139631  [12800/60000]\n",
      "loss: 0.213348  [19200/60000]\n",
      "loss: 0.181352  [25600/60000]\n",
      "loss: 0.216640  [32000/60000]\n",
      "loss: 0.062711  [38400/60000]\n",
      "loss: 0.253506  [44800/60000]\n",
      "loss: 0.141796  [51200/60000]\n",
      "loss: 0.294573  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 95.4%, Avg loss: 0.158111 \n",
      "\n",
      "Epoch 8\n",
      "-------------------------------\n",
      "loss: 0.113053  [    0/60000]\n",
      "loss: 0.153646  [ 6400/60000]\n",
      "loss: 0.131316  [12800/60000]\n",
      "loss: 0.183616  [19200/60000]\n",
      "loss: 0.172999  [25600/60000]\n",
      "loss: 0.207748  [32000/60000]\n",
      "loss: 0.056016  [38400/60000]\n",
      "loss: 0.242591  [44800/60000]\n",
      "loss: 0.133306  [51200/60000]\n",
      "loss: 0.273915  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 95.6%, Avg loss: 0.147696 \n",
      "\n",
      "Epoch 9\n",
      "-------------------------------\n",
      "loss: 0.104635  [    0/60000]\n",
      "loss: 0.146225  [ 6400/60000]\n",
      "loss: 0.124210  [12800/60000]\n",
      "loss: 0.158689  [19200/60000]\n",
      "loss: 0.159259  [25600/60000]\n",
      "loss: 0.197641  [32000/60000]\n",
      "loss: 0.049874  [38400/60000]\n",
      "loss: 0.230138  [44800/60000]\n",
      "loss: 0.125664  [51200/60000]\n",
      "loss: 0.256527  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 95.8%, Avg loss: 0.139019 \n",
      "\n",
      "Epoch 10\n",
      "-------------------------------\n",
      "loss: 0.099239  [    0/60000]\n",
      "loss: 0.139797  [ 6400/60000]\n",
      "loss: 0.118782  [12800/60000]\n",
      "loss: 0.137194  [19200/60000]\n",
      "loss: 0.145117  [25600/60000]\n",
      "loss: 0.191353  [32000/60000]\n",
      "loss: 0.044544  [38400/60000]\n",
      "loss: 0.223825  [44800/60000]\n",
      "loss: 0.119730  [51200/60000]\n",
      "loss: 0.244093  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 96.1%, Avg loss: 0.131573 \n",
      "\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "file_name =\"1MNIST\"+str(input_img_sz)+\"x\"+str(input_img_sz)+\"_\"+str(layer0_output_size)+\"_10.pth\"\n",
    "if not (os.path.isfile(file_name)):\n",
    "    epochs = 50\n",
    "    for t in range(epochs):\n",
    "        print(f\"Epoch {t+1}\\n-------------------------------\")\n",
    "        train(train_dataloader, model, loss_fn, optimizer)\n",
    "        test(test_dataloader, model, loss_fn)\n",
    "        #torch.save(model, file_name)\n",
    "    print(\"Done!\")\n",
    "else:\n",
    "    #model.load_state_dict(torch.load(\"model.pth\"))\n",
    "    model = torch.load( file_name)\n",
    "    print(\"Model loaded\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "myplot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Error: \n",
      " Accuracy: 96.0%, Avg loss: 1224.973508 \n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "OrderedDict([('liner0.weight',\n",
       "              tensor([[   9.,   45.,  -13.,  ...,  -78.,    0.,   27.],\n",
       "                      [  24.,   -5.,   17.,  ...,   22.,   -4.,   30.],\n",
       "                      [  44.,    6.,   48.,  ..., -126.,  -88.,   25.],\n",
       "                      ...,\n",
       "                      [  -7.,  -35.,  -69.,  ...,   79.,  102.,    0.],\n",
       "                      [  19.,   35.,  -12.,  ...,  -14.,   17.,   43.],\n",
       "                      [ -31.,  -44.,  -14.,  ...,  -75.,  -40.,    1.]], device='cuda:0')),\n",
       "             ('liner0.bias',\n",
       "              tensor([ 43.,  10.,   7.,   1.,   4.,  28.,  13.,  -8.,  39.,  23.,   9.,   6.,\n",
       "                       38.,  14.,   5., -10., -16.,  -1.,   4.,  16.,  -2.,   4.,  21.,  -9.,\n",
       "                       -5.,  -7.,  18.,  35.,   7.,  20.,  16.,  32.,  -2.,  -8.,  15.,  19.,\n",
       "                       12.,  51.,  28., -24.,  -9.,  19.,  43.,   1.,  16.,   9.,   3.,  30.,\n",
       "                       43., -11., -30.,   2.,  35.,   0.,  73.,  -3.,  49.,  -5.,  49.,   2.,\n",
       "                      -22.,  43.,  24.,  17.], device='cuda:0')),\n",
       "             ('liner1.weight',\n",
       "              tensor([[ -90.,   73.,  -67.,   26.,  -59.,    9.,   61.,   35.,   19.,  -66.,\n",
       "                         22.,   41.,  -82., -133.,   56.,   66.,   24.,   -8.,    5.,   69.,\n",
       "                        -20.,   38.,  -78.,   52.,  -65.,  -79.,  -20.,   34.,   20.,   -5.,\n",
       "                        -58.,   34.,    9.,    0.,   40.,   12.,  -28.,   -9.,   41.,  -17.,\n",
       "                        -63.,   59.,   18.,  -52., -108.,   47.,   34.,   53., -126.,   29.,\n",
       "                          4.,  -25.,  -44.,    1., -167.,  -66.,   91.,  -11.,   30.,   34.,\n",
       "                         27., -181., -110.,  -22.],\n",
       "                      [  65.,   70.,   31.,  -70.,  -20.,  -55.,   57.,  -38.,  -92.,   34.,\n",
       "                        -69.,  -78.,   25.,  -23.,  160.,  -61.,  -90.,   11.,   30.,    1.,\n",
       "                         51.,  -76.,    8.,   31.,  -89.,   -8.,   -4.,  -58.,  -48.,  -41.,\n",
       "                          7.,  -42.,    9.,   -5.,  -91.,   65.,   38.,  -96., -109.,   21.,\n",
       "                        -98.,  -54.,   32.,    8.,   24.,  -94.,  -88.,   19.,  102.,  -23.,\n",
       "                        -57.,   44.,   50., -125.,   66.,  -23.,   37.,   12.,  149.,  -12.,\n",
       "                        -60., -106.,   52.,  -28.],\n",
       "                      [  34.,   16.,   67.,   71.,  -69.,  106.,   19.,   27.,  -37.,  -20.,\n",
       "                         36.,   15.,   23.,   33., -215.,  -36.,  -36.,   41.,  -42.,   42.,\n",
       "                         41.,  -29.,  -26.,    7.,   24.,  124.,  -61.,   67.,   45.,    6.,\n",
       "                          3.,   59.,    0.,   26.,  -54., -127.,   13.,   -8.,  -10.,   46.,\n",
       "                        -87.,  -22., -231.,  -43.,  -13.,  -73.,   11.,   59.,  -75.,   71.,\n",
       "                         12.,   42.,   11.,   74.,  -76.,   29.,   56.,    8.,   41.,    9.,\n",
       "                         -7.,  -49.,   14.,   52.],\n",
       "                      [  27.,  -96.,  -31.,  -24.,   59.,   27.,   32.,    2.,  -44.,  -59.,\n",
       "                        -59.,   58.,   21.,    7.,  -75.,   63.,  -57.,   41.,   31.,   50.,\n",
       "                         54.,  -69.,  -14.,  -45.,   68.,  -80.,   15.,  -40.,   52.,  -22.,\n",
       "                        -48., -153.,   12.,   51.,  -17.,   50., -154.,  -49.,   -7.,   64.,\n",
       "                         11.,    8.,  -90.,   69.,   53., -106.,   -1.,   35.,  -24.,   22.,\n",
       "                         15.,   53.,    1.,   -3.,  -31.,    2.,  -80.,  -15.,  -91.,   36.,\n",
       "                         36.,  102.,   29.,  -56.],\n",
       "                      [  48.,   76.,  -32.,    0.,   29.,   33., -218.,   11.,   30.,   14.,\n",
       "                        -12.,  -30.,   -7.,   31.,    0.,   24.,   37., -191.,  -76., -248.,\n",
       "                        -78.,    4.,    0.,  -72.,   -5.,  -37.,    2., -140., -192.,   36.,\n",
       "                         44.,   43.,   12.,  -58.,   16.,   45.,  -50.,   35.,   18.,   34.,\n",
       "                         36.,  -77.,   22.,  -16.,  -29.,   -6.,   27.,  -48.,  -35., -184.,\n",
       "                        -13.,   27.,  -56.,   12.,   75., -209.,   -3.,   -2.,   17.,   39.,\n",
       "                        -90.,   54.,  -20.,   44.],\n",
       "                      [  36.,  -37.,   12.,    7.,    6.,   55.,  -50., -103.,   30.,  -29.,\n",
       "                          5.,   35.,    9., -187.,   39.,  -82.,  -36.,  -91.,   -4.,   75.,\n",
       "                        -42.,   -1.,   35.,  -20.,    2.,  -11.,   38.,   46.,  -43.,   39.,\n",
       "                        -58.,  -60.,  -11.,  -83.,   19.,  -14.,   -5.,  115.,   40., -230.,\n",
       "                        -12.,   17.,   48.,   23.,   40.,   59.,   13.,   22.,    5.,   53.,\n",
       "                         -5., -221.,   39.,  -61.,   67.,  115., -286.,   14.,   49.,    3.,\n",
       "                         -5.,   70.,   54.,  -44.],\n",
       "                      [  15.,   37.,   16.,  -15.,  -74.,   61.,  -25.,   15.,  -17.,  -46.,\n",
       "                         67.,   43.,   49.,  -15.,   86.,  -29.,   61.,    8.,  -12.,  -87.,\n",
       "                        -67.,    4.,   43.,  -15.,  -98.,  -18.,   -2.,  -56.,   36.,   20.,\n",
       "                         24.,   -3.,   -6., -177.,  -41.,   22.,   64., -194.,  -54., -134.,\n",
       "                        -11.,   -4.,   55.,  -99., -187.,   58.,  -28.,   33.,   28.,  -49.,\n",
       "                         -3., -166.,    4.,   36., -113.,   42.,   37.,   13.,   19.,   27.,\n",
       "                         44., -183.,  -51.,   38.],\n",
       "                      [ -38.,  -94.,  175., -100.,  -18.,   32.,   20.,   55.,   40.,   33.,\n",
       "                        -76., -124.,  -81.,   55.,  -38.,   46.,  -18.,   23.,  -17.,   21.,\n",
       "                        -53.,   38.,  -92.,   10.,  -22.,   18.,   32.,   84.,   85.,  -86.,\n",
       "                        -36.,   64.,  -14.,   44.,   30.,  119.,   22.,   31.,   27.,   52.,\n",
       "                         -6.,   34.,  -22.,   21.,    1.,  -45.,  -52.,    6.,   67.,  -37.,\n",
       "                        -93.,   17.,  -81.,  -72.,   10.,   27.,   60.,   -5., -109.,  -66.,\n",
       "                        -93.,   35.,  -11.,  -76.],\n",
       "                      [  14., -140.,  -98.,   40.,    4., -168.,    5.,   -7.,   -8.,   13.,\n",
       "                         35.,   -7.,  -28.,   -7., -112.,  -89.,   56.,   -2.,   25., -101.,\n",
       "                         19.,   59.,   41.,   46.,    8.,   54.,   21.,  -62.,  -74.,   23.,\n",
       "                         12.,  -71.,    4.,   22.,    7., -133.,   58.,  -45.,    7.,   -2.,\n",
       "                         30.,   13.,    7.,   -1.,   -5.,   -9.,   32., -136.,  -91.,   28.,\n",
       "                         52.,   -2.,   42.,  -63.,   -3.,  -13.,  -39.,    4., -126.,   24.,\n",
       "                         51.,  -58.,   19.,   -3.],\n",
       "                      [-150.,   83., -322.,   28.,   34., -157.,  -13.,    0.,   14.,   50.,\n",
       "                        -84.,  -42.,  -10.,   10.,   -4.,   26.,  -18.,   59.,   17.,  -50.,\n",
       "                        -21.,  -12.,  -12.,  -44.,   50., -212.,   -8.,    1.,  -77.,  -26.,\n",
       "                         35.,    5.,    7.,   52.,   29.,  -21., -208.,   34.,   -7.,   15.,\n",
       "                         28.,   24.,   72.,  -31.,   12.,   63.,   27., -151.,   23., -131.,\n",
       "                         18.,   45.,   -8.,   52.,   35.,  -79.,   59.,    6., -197.,  -99.,\n",
       "                         32.,   26.,  -77.,   24.]], device='cuda:0')),\n",
       "             ('liner1.bias',\n",
       "              tensor([-26.,  24.,  12., -17.,   8.,  33.,   0., -12., -27.,  -7.],\n",
       "                     device='cuda:0'))])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = torch.load( file_name)\n",
    "for ele in model.state_dict():#turn to numpy\n",
    "    model.state_dict()[ele]=model.state_dict()[ele].cpu().numpy()\n",
    "#turn float to int\n",
    "for layers in model.state_dict():\n",
    "    try:\n",
    "        model.state_dict()[layers].shape[1]## if parameter is 2D\n",
    "        row,col=model.state_dict()[layers].shape\n",
    "        for row in range(model.state_dict()[layers].shape[0]):\n",
    "            for col in range(model.state_dict()[layers].shape[1]):\n",
    "                num=int((model.state_dict()[layers][row][col]+1)/2*255-127)\n",
    "                model.state_dict()[layers][row][col]= num\n",
    "    except:\n",
    "        #model[layers].shape #1D\n",
    "        # print(model[layers].shape[0])\n",
    "        for i in range(model.state_dict()[layers].shape[0]):\n",
    "            num=int((model.state_dict()[layers][i]+1)/2*255-127)\n",
    "            model.state_dict()[layers][i]=num\n",
    "test(test_dataloader, model, loss_fn)\n",
    "model.state_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Error: \n",
      " Accuracy: 85.2%, Avg loss: 5425.295356 \n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "OrderedDict([('liner0.weight',\n",
       "              tensor([[   0.,   59.,    0.,  ...,  -59.,    0.,    0.],\n",
       "                      [   0.,    0.,    0.,  ...,    0.,    0.,   59.],\n",
       "                      [  59.,    0.,   59.,  ..., -118.,  -59.,    0.],\n",
       "                      ...,\n",
       "                      [   0.,  -59.,  -59.,  ...,   59.,  118.,    0.],\n",
       "                      [   0.,   59.,    0.,  ...,    0.,    0.,   59.],\n",
       "                      [ -59.,  -59.,    0.,  ...,  -59.,  -59.,    0.]], device='cuda:0')),\n",
       "             ('liner0.bias',\n",
       "              tensor([ 59.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,  59.,   0.,   0.,   0.,\n",
       "                       59.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "                        0.,   0.,   0.,  59.,   0.,   0.,   0.,  59.,   0.,   0.,   0.,   0.,\n",
       "                        0.,  59.,   0.,   0.,   0.,   0.,  59.,   0.,   0.,   0.,   0.,  59.,\n",
       "                       59.,   0., -59.,   0.,  59.,   0.,  59.,   0.,  59.,   0.,  59.,   0.,\n",
       "                        0.,  59.,   0.,   0.], device='cuda:0')),\n",
       "             ('liner1.weight',\n",
       "              tensor([[-118.,   59.,  -59.,    0.,  -59.,    0.,   59.,   59.,    0.,  -59.,\n",
       "                          0.,   59.,  -59., -118.,   59.,   59.,    0.,    0.,    0.,   59.,\n",
       "                          0.,   59.,  -59.,   59.,  -59.,  -59.,    0.,   59.,    0.,    0.,\n",
       "                        -59.,   59.,    0.,    0.,   59.,    0.,    0.,    0.,   59.,    0.,\n",
       "                        -59.,   59.,    0.,  -59., -118.,   59.,   59.,   59., -118.,    0.,\n",
       "                          0.,    0.,  -59.,    0., -177.,  -59.,  118.,    0.,   59.,   59.,\n",
       "                          0., -177., -118.,    0.],\n",
       "                      [  59.,   59.,   59.,  -59.,    0.,  -59.,   59.,  -59., -118.,   59.,\n",
       "                        -59.,  -59.,    0.,    0.,  177.,  -59., -118.,    0.,   59.,    0.,\n",
       "                         59.,  -59.,    0.,   59., -118.,    0.,    0.,  -59.,  -59.,  -59.,\n",
       "                          0.,  -59.,    0.,    0., -118.,   59.,   59., -118., -118.,    0.,\n",
       "                       -118.,  -59.,   59.,    0.,    0., -118.,  -59.,    0.,  118.,    0.,\n",
       "                        -59.,   59.,   59., -118.,   59.,    0.,   59.,    0.,  177.,    0.,\n",
       "                        -59., -118.,   59.,    0.],\n",
       "                      [  59.,    0.,   59.,   59.,  -59.,  118.,    0.,    0.,  -59.,    0.,\n",
       "                         59.,    0.,    0.,   59., -236.,  -59.,  -59.,   59.,  -59.,   59.,\n",
       "                         59.,    0.,    0.,    0.,    0.,  118.,  -59.,   59.,   59.,    0.,\n",
       "                          0.,   59.,    0.,    0.,  -59., -118.,    0.,    0.,    0.,   59.,\n",
       "                        -59.,    0., -236.,  -59.,    0.,  -59.,    0.,   59.,  -59.,   59.,\n",
       "                          0.,   59.,    0.,   59.,  -59.,    0.,   59.,    0.,   59.,    0.,\n",
       "                          0.,  -59.,    0.,   59.],\n",
       "                      [   0., -118.,  -59.,    0.,   59.,    0.,   59.,    0.,  -59.,  -59.,\n",
       "                        -59.,   59.,    0.,    0.,  -59.,   59.,  -59.,   59.,   59.,   59.,\n",
       "                         59.,  -59.,    0.,  -59.,   59.,  -59.,    0.,  -59.,   59.,    0.,\n",
       "                        -59., -177.,    0.,   59.,    0.,   59., -177.,  -59.,    0.,   59.,\n",
       "                          0.,    0., -118.,   59.,   59., -118.,    0.,   59.,    0.,    0.,\n",
       "                          0.,   59.,    0.,    0.,  -59.,    0.,  -59.,    0., -118.,   59.,\n",
       "                         59.,  118.,    0.,  -59.],\n",
       "                      [  59.,   59.,  -59.,    0.,    0.,   59., -236.,    0.,   59.,    0.,\n",
       "                          0.,  -59.,    0.,   59.,    0.,    0.,   59., -177.,  -59., -236.,\n",
       "                        -59.,    0.,    0.,  -59.,    0.,  -59.,    0., -118., -177.,   59.,\n",
       "                         59.,   59.,    0.,  -59.,    0.,   59.,  -59.,   59.,    0.,   59.,\n",
       "                         59.,  -59.,    0.,    0.,    0.,    0.,    0.,  -59.,  -59., -177.,\n",
       "                          0.,    0.,  -59.,    0.,   59., -236.,    0.,    0.,    0.,   59.,\n",
       "                       -118.,   59.,    0.,   59.],\n",
       "                      [  59.,  -59.,    0.,    0.,    0.,   59.,  -59., -118.,   59.,    0.,\n",
       "                          0.,   59.,    0., -177.,   59.,  -59.,  -59., -118.,    0.,   59.,\n",
       "                        -59.,    0.,   59.,    0.,    0.,    0.,   59.,   59.,  -59.,   59.,\n",
       "                        -59.,  -59.,    0.,  -59.,    0.,    0.,    0.,  118.,   59., -236.,\n",
       "                          0.,    0.,   59.,    0.,   59.,   59.,    0.,    0.,    0.,   59.,\n",
       "                          0., -236.,   59.,  -59.,   59.,  118., -295.,    0.,   59.,    0.,\n",
       "                          0.,   59.,   59.,  -59.],\n",
       "                      [   0.,   59.,    0.,    0.,  -59.,   59.,    0.,    0.,    0.,  -59.,\n",
       "                         59.,   59.,   59.,    0.,   59.,    0.,   59.,    0.,    0.,  -59.,\n",
       "                        -59.,    0.,   59.,    0., -118.,    0.,    0.,  -59.,   59.,    0.,\n",
       "                          0.,    0.,    0., -177.,  -59.,    0.,   59., -177.,  -59., -118.,\n",
       "                          0.,    0.,   59., -118., -177.,   59.,    0.,   59.,    0.,  -59.,\n",
       "                          0., -177.,    0.,   59., -118.,   59.,   59.,    0.,    0.,    0.,\n",
       "                         59., -177.,  -59.,   59.],\n",
       "                      [ -59., -118.,  177., -118.,    0.,   59.,    0.,   59.,   59.,   59.,\n",
       "                        -59., -118.,  -59.,   59.,  -59.,   59.,    0.,    0.,    0.,    0.,\n",
       "                        -59.,   59., -118.,    0.,    0.,    0.,   59.,   59.,   59.,  -59.,\n",
       "                        -59.,   59.,    0.,   59.,   59.,  118.,    0.,   59.,    0.,   59.,\n",
       "                          0.,   59.,    0.,    0.,    0.,  -59.,  -59.,    0.,   59.,  -59.,\n",
       "                       -118.,    0.,  -59.,  -59.,    0.,    0.,   59.,    0., -118.,  -59.,\n",
       "                       -118.,   59.,    0.,  -59.],\n",
       "                      [   0., -118., -118.,   59.,    0., -177.,    0.,    0.,    0.,    0.,\n",
       "                         59.,    0.,    0.,    0., -118., -118.,   59.,    0.,    0., -118.,\n",
       "                          0.,   59.,   59.,   59.,    0.,   59.,    0.,  -59.,  -59.,    0.,\n",
       "                          0.,  -59.,    0.,    0.,    0., -118.,   59.,  -59.,    0.,    0.,\n",
       "                         59.,    0.,    0.,    0.,    0.,    0.,   59., -118., -118.,    0.,\n",
       "                         59.,    0.,   59.,  -59.,    0.,    0.,  -59.,    0., -118.,    0.,\n",
       "                         59.,  -59.,    0.,    0.],\n",
       "                      [-177.,   59., -295.,    0.,   59., -177.,    0.,    0.,    0.,   59.,\n",
       "                        -59.,  -59.,    0.,    0.,    0.,    0.,    0.,   59.,    0.,  -59.,\n",
       "                          0.,    0.,    0.,  -59.,   59., -236.,    0.,    0.,  -59.,    0.,\n",
       "                         59.,    0.,    0.,   59.,    0.,    0., -236.,   59.,    0.,    0.,\n",
       "                          0.,    0.,   59.,  -59.,    0.,   59.,    0., -177.,    0., -118.,\n",
       "                          0.,   59.,    0.,   59.,   59.,  -59.,   59.,    0., -177., -118.,\n",
       "                         59.,    0.,  -59.,    0.]], device='cuda:0')),\n",
       "             ('liner1.bias',\n",
       "              tensor([ 0.,  0.,  0.,  0.,  0., 59.,  0.,  0.,  0.,  0.], device='cuda:0'))])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = torch.load( file_name)\n",
    "A=59\n",
    "for ele in model.state_dict():#turn to numpy\n",
    "    model.state_dict()[ele]=model.state_dict()[ele].cpu().numpy()\n",
    "#turn float to int\n",
    "for layers in model.state_dict():\n",
    "    try:\n",
    "        model.state_dict()[layers].shape[1]## if parameter is 2D\n",
    "        row,col=model.state_dict()[layers].shape\n",
    "        for row in range(model.state_dict()[layers].shape[0]):\n",
    "            for col in range(model.state_dict()[layers].shape[1]):\n",
    "                num=int((model.state_dict()[layers][row][col]+1)/2*255-127)\n",
    "                model.state_dict()[layers][row][col]= round(num/A)*A\n",
    "    except:\n",
    "        #model[layers].shape #1D\n",
    "        # print(model[layers].shape[0])\n",
    "        for i in range(model.state_dict()[layers].shape[0]):\n",
    "            num=int((model.state_dict()[layers][i]+1)/2*255-127)\n",
    "            model.state_dict()[layers][i]=round(num/A)*A\n",
    "test(test_dataloader, model, loss_fn)\n",
    "model.state_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#turn img from float to int\n",
    "def int_conver(np_a):\n",
    "    for idx,ele in enumerate(np_a):\n",
    "        np_a[idx]=int((ele+1)/2*255-127)\n",
    "\n",
    "    return np_a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ -3324355. -25188516.   2273093.  13199952. -30281219. -18351773.\n",
      " -34308736.  16841078. -10282874.  -6039535.]\n",
      "1\n",
      "0:  18\n",
      "1:  29\n"
     ]
    }
   ],
   "source": [
    "hit=0\n",
    "lrsb0_len=layer0_output_size\n",
    "lrsb2_len=10\n",
    "max_0,min_0=0,0\n",
    "max_1,min_1=0,0\n",
    "\n",
    "lrsw0=model.state_dict()[\"liner0.weight\"].reshape(-1).cpu().numpy()\n",
    "lrsb0=model.state_dict()[\"liner0.bias\"].reshape(-1).cpu().numpy()\n",
    "lrsw2=model.state_dict()[\"liner1.weight\"].reshape(-1).cpu().numpy()\n",
    "lrsb2=model.state_dict()[\"liner1.bias\"].reshape(-1).cpu().numpy()\n",
    "for r in range(1):    \n",
    "    img,label=test_data[r]\n",
    "    img=img.reshape(-1)\n",
    "    img=int_conver(img)\n",
    "\n",
    "    out1=np.zeros(lrsb0_len)\n",
    "    out2=np.zeros(lrsb2_len)\n",
    "    \n",
    "    for i in range(lrsb0_len):\n",
    "        for j in range(input_img_sz*input_img_sz):\n",
    "            out1[i]+=lrsw0[i*input_img_sz*input_img_sz+j]*img[j]\n",
    "        out1[i]+=lrsb0[i]\n",
    "    # print(out1)\n",
    "\n",
    "    for i in range(lrsb0_len):\n",
    "        if(out1[i]>max_0):\n",
    "            max_0=out1[i]\n",
    "        if(out1[i]<min_0):\n",
    "            min_0=out1[i]\n",
    "        if(out1[i]<0):\n",
    "            out1[i]=0\n",
    "\n",
    "    for i in range(lrsb2_len):\n",
    "        for j in range(lrsb0_len):\n",
    "            out2[i]+=lrsw2[i*lrsb0_len+j]*out1[j]\n",
    "        out2[i]+=lrsb2[i]\n",
    "\n",
    "    for i in range(10):\n",
    "        if(out2[i]>max_1):\n",
    "            max_1=out2[i]\n",
    "        if(out2[i]<min_1):\n",
    "            min_1=out2[i]\n",
    "    print(out2)\n",
    "    if(out2.argmax()==label):\n",
    "        hit+=1\n",
    "\n",
    "    # print(\"now:\",r+1,\"hit:\",hit)\n",
    "print(hit)\n",
    "layer0_bit = len(bin(int(max_0)))\n",
    "layer2_bit = len(bin(int(max_1)))+2\n",
    "print(\"0: \",layer0_bit)\n",
    "print(\"1: \",layer2_bit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'-(0+(reg<<0)-(reg<<2)+(reg<<5))'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import TCB\n",
    "def D2reg(num,reg_name):\n",
    "    if(num==0):\n",
    "        return None\n",
    "    else:\n",
    "        tcb_str=TCB.Bin2TCB(int(num))\n",
    "        temp=0\n",
    "        if(num>0):\n",
    "            out_s=\"+(0\"\n",
    "        else:\n",
    "            out_s=\"-(0\"\n",
    "        for s in reversed(tcb_str):\n",
    "            if(s==\"+\"):\n",
    "                out_s+=\"+(\"+reg_name+\"<<\"+str(temp)+\")\"\n",
    "            if(s==\"-\"):\n",
    "                out_s+=\"-(\"+reg_name+\"<<\"+str(temp)+\")\"\n",
    "            temp+=1         \n",
    "            \n",
    "        return out_s+\")\"\n",
    "D2reg(-29,\"reg\")        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "wire_cnt 64\n",
      "wire_cnt 64\n"
     ]
    }
   ],
   "source": [
    "\n",
    "img_size=input_img_sz*input_img_sz\n",
    "wire_cnt=layer0_output_size\n",
    "in_buffer_weight_name=\"in_buffer_weight\"\n",
    "weight_to_bias_name=\"weight_bias\"\n",
    "bias_relu_name=\"bias_relu\"\n",
    "in_buffer_weight_parameter=model.state_dict()[\"liner0.weight\"]\n",
    "weight_bias_parameter=model.state_dict()[\"liner0.bias\"]\n",
    "#data_bit_num=20\n",
    "data_bit_num=layer0_bit\n",
    "file_destination = \"verilog_net1\"\n",
    "\n",
    "layer0_verilog_file_name=\"layer0_tcb_\"+str(img_size)+\"x\"+str(layer0_output_size)+\"x10\"\n",
    "f=open(\"./\"+file_destination+\"/\"+layer0_verilog_file_name+\".v\",\"w\")\n",
    "f.write(\"module \"+layer0_verilog_file_name+\"\\n\")\n",
    "f.write(\"(\\n\")\n",
    "\n",
    "f.write(\"\\\n",
    "    input clk,\\n\\\n",
    "    input rst,\\n\\\n",
    "    input [\"+str(img_size)+\"*8-1:0] img,\\n\\\n",
    "    input valid,\\n\\\n",
    "    output  reg ready,\\n\\\n",
    "    output [\"+str(data_bit_num)+\"*\"+str(layer0_output_size)+\"-1:0] layer_out\\n\"\\\n",
    ")\n",
    "f.write(\");\\n\")\n",
    "f.write(\"parameter DATA_WIDTH = \"+str(data_bit_num)+\";\\n\")\n",
    "f.write(\"parameter IMG_SZ   =   \"+str(img_size)+\";\\n\")\n",
    "\n",
    "f.write(\"reg    signed [8-1:0]  in_buffer[0:IMG_SZ-1];\\n\")\n",
    "f.write(\"integer i;\\n\")\n",
    "f.write(\"always@(posedge clk )\\n\\\n",
    "    begin\\n\\\n",
    "        if(rst)\\n\\\n",
    "            begin\\n\\\n",
    "                for(i=0;i<IMG_SZ;i=i+1)\\n\\\n",
    "                    begin\\n\\\n",
    "                        in_buffer[i]<=0;\\n\\\n",
    "                    end\\n\\\n",
    "            end\\n\\\n",
    "        else\\n\\\n",
    "        begin\\n\")\n",
    "\n",
    "for i in range(img_size):\n",
    "    f.write(\"       in_buffer[\"+str(i)+\"]<=img[\"+str(7+i*8)+\":\"+str(0+i*8)+\"];\\n\")           \n",
    "f.write(\"        end\\n   end\\n\")\n",
    "for naming_idx in range(wire_cnt): \n",
    "    f.write(\"wire signed  [DATA_WIDTH-1:0]   \")   \n",
    "    f.write(in_buffer_weight_name+str(naming_idx)+\";\\n\")\n",
    "    f.write(\"assign \"+in_buffer_weight_name+str(naming_idx)+\"=0\")\n",
    "    #insert tcb\n",
    "    for in_buf_idx in range(img_size):\n",
    "        name=\"in_buffer[\" +str(in_buf_idx)+\"]\"\n",
    "        num=int(in_buffer_weight_parameter[naming_idx][in_buf_idx])\n",
    "        try:\n",
    "            f.write(D2reg(num,name))\n",
    "        except:\n",
    "            pass\n",
    "    f.write(\";\\n\")\n",
    "\n",
    "#weight0 to bias0\n",
    "previous_layer_name=in_buffer_weight_name\n",
    "#naming wire\n",
    "print(\"wire_cnt\",wire_cnt)\n",
    "for naming_idx in range(wire_cnt): \n",
    "    f.write(\"wire signed [DATA_WIDTH-1:0]   \")   \n",
    "    f.write(weight_to_bias_name+str(naming_idx)+\";\\n\")\n",
    "for naming_idx in range(wire_cnt):\n",
    "    f.write(\"assign \"+weight_to_bias_name+str(naming_idx)+\"=\")\n",
    "    f.write(previous_layer_name+str(naming_idx))\n",
    "    f.write(\"+(\")\n",
    "    f.write(str(int(weight_bias_parameter[naming_idx])))\n",
    "\n",
    "    f.write(\");\\n\")\n",
    "#bias0 to relu0\n",
    "previous_layer_name=weight_to_bias_name\n",
    "#naming wire\n",
    "print(\"wire_cnt\",wire_cnt)\n",
    "for naming_idx in range(wire_cnt): \n",
    "    f.write(\"wire signed [DATA_WIDTH-1:0]   \")   \n",
    "    f.write(bias_relu_name+str(naming_idx)+\";\\n\")\n",
    "for naming_idx in range(wire_cnt):\n",
    "    f.write(\"assign \"+bias_relu_name+str(naming_idx)+\"=(\")\n",
    "    f.write(previous_layer_name+str(naming_idx))\n",
    "    f.write(\"[DATA_WIDTH-1]==1'b1)   ?   \")\n",
    "    f.write(\"{DATA_WIDTH{1'b0}}:\")\n",
    "    f.write(previous_layer_name+str(naming_idx))\n",
    "    f.write(\";\\n\")\n",
    "\n",
    "\n",
    "f.write(\"assign layer_out={\")\n",
    "for naming_idx in range(wire_cnt-1,-1,-1):\n",
    "    if(naming_idx==0):\n",
    "        f.write(bias_relu_name+str(naming_idx))\n",
    "    else:\n",
    "        f.write(bias_relu_name+str(naming_idx)+\",\")\n",
    "f.write(\"};\\n\")\n",
    "f.write(\"always@(posedge clk)\\n\\\n",
    "    begin\\n\\\n",
    "        if(rst)\\n\\\n",
    "            begin\\n\\\n",
    "                ready<=1'b0;\\n\\\n",
    "            end\\n\\\n",
    "        else\\n\\\n",
    "            begin\\n\\\n",
    "                ready<=valid;\\n\\\n",
    "            end\\n\\\n",
    "    end\\n\")\n",
    "f.write(\"endmodule\")\n",
    "f.close()\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "last_output_sz=layer0_output_size\n",
    "last_layer_data_sz=layer0_bit\n",
    "\n",
    "wire_cnt=10\n",
    "in_buffer_weight_name=\"in_buffer_weight\"\n",
    "weight_to_bias_name=\"weight_bias\"\n",
    "bias_relu_name=\"bias_relu\"\n",
    "in_buffer_weight_parameter=model.state_dict()[\"liner1.weight\"]\n",
    "weight_bias_parameter=model.state_dict()[\"liner1.bias\"]\n",
    "\n",
    "layer2_verilog_file_name=\"layer2_tcb_\"+str(img_size)+\"x\"+str(layer0_output_size)+\"x10\"\n",
    "f=open(\"./\"+file_destination+\"/\"+layer2_verilog_file_name+\".v\",\"w\")\n",
    "f.write(\"module \"+layer2_verilog_file_name+\"\\n\")\n",
    "f.write(\"(\\n\")\n",
    "\n",
    "f.write(\"\\\n",
    "    input clk,\\n\\\n",
    "    input rst,\\n\")\n",
    "f.write(\"   input valid,\\n\")\n",
    "f.write(\"   output  reg ready,\\n\")\n",
    "f.write(\"    input [\"+str(last_layer_data_sz)+\"*\"+str(last_output_sz)+\"-1:0]  layer_in,\\n\")\n",
    "f.write(\"    output [\"+str(layer2_bit)+\"*10-1:0]   layer_out\\n\\\n",
    ");\\n\")\n",
    "f.write(\"parameter DATA_WIDTH   =   \"+str(layer2_bit)+\";\\n\")\n",
    "f.write(\"reg [DATA_WIDTH-1:0]    layer_in_buffer    [0:\"+str(last_output_sz)+\"-1];\\n\")\n",
    "f.write(\"integer i;\\n\")\n",
    "f.write(\"always@(posedge clk )\\n\\\n",
    "    begin\\n\\\n",
    "        if(rst)\\n\\\n",
    "            begin\\n\")\n",
    "f.write(\"                for(i=0;i<\"+str(last_output_sz)+\";i=i+1)\\n\\\n",
    "                    begin\\n\\\n",
    "                        layer_in_buffer[i]<=0;\\n\\\n",
    "                    end\\n\\\n",
    "            end\\n\\\n",
    "        else\\n\\\n",
    "        begin\\n\")\n",
    "for i in range(last_output_sz):\n",
    "    f.write(\"       layer_in_buffer[\"+str(i)+\"]<=layer_in[\"+str(last_layer_data_sz-1+i*last_layer_data_sz)+\":\"+str(0+i*last_layer_data_sz)+\"];\\n\")           \n",
    "f.write(\"        end\\n   end\\n\")\n",
    "\n",
    "\n",
    "f.write(\"\\n\")\n",
    "previous_layer_name=\"layer_in_buffer\"\n",
    "#naming wire\n",
    "for naming_idx in range(wire_cnt): \n",
    "    f.write(\"wire [DATA_WIDTH-1:0]   \")   \n",
    "    f.write(in_buffer_weight_name+str(naming_idx)+\";\\n\")\n",
    "    f.write(\"assign \"+in_buffer_weight_name+str(naming_idx)+\"=0\")\n",
    "    for previoud_layer_idx in range(last_output_sz):\n",
    "        name=previous_layer_name+\"[\"+str(previoud_layer_idx)+\"]\"\n",
    "        num=int(in_buffer_weight_parameter[naming_idx][previoud_layer_idx])\n",
    "        try:\n",
    "            f.write(D2reg(num,name))\n",
    "        except:\n",
    "            pass\n",
    "    f.write(\";\\n\")\n",
    "# weight4 to bias4 \n",
    "\n",
    "previous_layer_name=in_buffer_weight_name\n",
    "#naming wire\n",
    "for naming_idx in range(wire_cnt): \n",
    "    f.write(\"wire [DATA_WIDTH-1:0]   \")   \n",
    "    f.write(weight_to_bias_name+str(naming_idx)+\";\\n\")\n",
    "    f.write(\"assign \"+weight_to_bias_name+str(naming_idx)+\"=\")\n",
    "    f.write(previous_layer_name+str(naming_idx))\n",
    "    f.write(\"+(\")\n",
    "    f.write(str(int(weight_bias_parameter[naming_idx])))\n",
    "    f.write(\");\\n\")\n",
    "f.write(\"assign layer_out={\\n\")\n",
    "for naming_idx in range(wire_cnt-1,-1,-1): \n",
    "    if(naming_idx==0):\n",
    "        f.write(\"            \"+weight_to_bias_name+str(naming_idx))\n",
    "    else:\n",
    "        f.write(\"            \"+weight_to_bias_name+str(naming_idx)+\",\\n\")\n",
    "f.write(\"};\\n\")\n",
    "f.write(\"always@(posedge clk)\\n\\\n",
    "    begin\\n\\\n",
    "        if(rst)\\n\\\n",
    "            begin\\n\\\n",
    "                ready<=1'b0;\\n\\\n",
    "            end\\n\\\n",
    "        else\\n\\\n",
    "            begin\\n\\\n",
    "                ready<=valid;\\n\\\n",
    "            end\\n\\\n",
    "    end\\n\")\n",
    "f.write(\"endmodule\\n\")\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_sz=layer2_bit\n",
    "f=open(\"./\"+file_destination+\"/comparator_30bit.v\",\"w\")\n",
    "f.write(\"module comparator\\n\")\n",
    "f.write(\"(\\n\")\n",
    "f.write(\"input [\"+str(data_sz)+\"*10-1:0] layer_out,\\n\")\n",
    "f.write(\"input rst,\\n\")\n",
    "f.write(\"input clk,\\n\")\n",
    "f.write(\"input valid,\\n\")\n",
    "f.write(\"output  reg ready,\\n\")\n",
    "f.write(\"output reg [7:0] predict\\n\")\n",
    "f.write(\");\\n\")\n",
    "f.write(\"parameter DATA_WIDTH=\"+str(data_sz)+\";\\n\")\n",
    "f.write(\"reg [DATA_WIDTH-1: 0] result [0:9];\\n\")\n",
    "f.write(\"wire [4+DATA_WIDTH-1:0] com_re01,com_re23,com_re45,com_re67,com_re89;\\n\")\n",
    "f.write(\"reg ready_temp;\\n\")\n",
    "f.write(\"always@(posedge clk)\\n\\\n",
    "    begin\\n\\\n",
    "        if(rst)\\n\\\n",
    "            begin\\n\\\n",
    "                ready<=1'b0;\\n\\\n",
    "                ready_temp<=1'b0;\\n\\\n",
    "            end\\n\\\n",
    "        else\\n\\\n",
    "            begin\\n\\\n",
    "                ready_temp<=valid;\\n\\\n",
    "                ready<=ready_temp;\\n\\\n",
    "            end\\n\\\n",
    "    end\\n\")\n",
    "\n",
    "f.write(\" \\n\\\n",
    "assign com_re01=(result[0][DATA_WIDTH-1]^result[1][DATA_WIDTH-1]) ? \\n\\\n",
    "                                                        ((result[0][DATA_WIDTH-1]==1'b0)   ?   {4'd0,result[0]}:{4'd1,result[1]}):\\n\\\n",
    "                                                        ((result[0]>result[1]) ? {4'd0,result[0]}:{4'd1,result[1]});\\n\\\n",
    "assign com_re23=(result[2][DATA_WIDTH-1]^result[3][DATA_WIDTH-1]) ? \\n\\\n",
    "                                                        ((result[2][DATA_WIDTH-1]==1'b0)   ?   {4'd2,result[2]}:{4'd3,result[3]}):\\n\\\n",
    "                                                        ((result[2]>result[3]) ? {4'd2,result[2]}:{4'd3,result[3]});\\n\\\n",
    "assign com_re45=(result[4][DATA_WIDTH-1]^result[5][DATA_WIDTH-1]) ? \\n\\\n",
    "                                                        ((result[4][DATA_WIDTH-1]==1'b0)   ?   {4'd4,result[4]}:{4'd5,result[5]}):\\n\\\n",
    "                                                        ((result[4]>result[5]) ? {4'd4,result[4]}:{4'd5,result[5]});\\n\")  \n",
    "f.write(\"\\n\\\n",
    "assign com_re67=(result[6][DATA_WIDTH-1]^result[7][DATA_WIDTH-1]) ? \\n\\\n",
    "                                                        ((result[6][DATA_WIDTH-1]==1'b0)   ?   {4'd6,result[6]}:{4'd7,result[7]}):\\n\\\n",
    "                                                        ((result[6]>result[7]) ? {4'd6,result[6]}:{4'd7,result[7]});\\n\\\n",
    "assign com_re89=(result[8][DATA_WIDTH-1]^result[9][DATA_WIDTH-1]) ? \\n\\\n",
    "                                                        ((result[8][DATA_WIDTH-1]==1'b0)   ?   {4'd8,result[8]}:{4'd9,result[9]}):\\n\\\n",
    "                                                        ((result[8]>result[9]) ? {4'd8,result[8]}:{4'd9,result[9]});\\n\\\n",
    "wire [4+DATA_WIDTH-1:0] com_re01_23,com_re45_67,com_re0123_4567,com_re01234567_89;\\n\\\n",
    "assign com_re01_23=(com_re01[DATA_WIDTH-1]^com_re23[DATA_WIDTH-1])   ?\\n\\\n",
    "                                                        ((com_re01[DATA_WIDTH-1]==1'b0)  ?   com_re01:com_re23):\\n\\\n",
    "                                                        ((com_re01[DATA_WIDTH-1:0]>com_re23[DATA_WIDTH-1:0]) ?   com_re01:com_re23);\\n\\\n",
    "assign com_re45_67=(com_re45[DATA_WIDTH-1]^com_re67[DATA_WIDTH-1])   ?\\n\\\n",
    "                                                        ((com_re45[DATA_WIDTH-1]==1'b0)  ?   com_re45:com_re67):\\n\\\n",
    "                                                        ((com_re45[DATA_WIDTH-1:0]>com_re67[DATA_WIDTH-1:0]) ?   com_re45:com_re67);\\n\\\n",
    "assign com_re0123_4567=(com_re01_23[DATA_WIDTH-1]^com_re45_67[DATA_WIDTH-1])   ?\\n\\\n",
    "                                                        ((com_re01_23[DATA_WIDTH-1]==1'b0)  ?   com_re01_23:com_re45_67):\\n\\\n",
    "                                                        ((com_re01_23[DATA_WIDTH-1:0]>com_re45_67[DATA_WIDTH-1:0]) ?   com_re01_23:com_re45_67);\\n\\\n",
    "assign com_re01234567_89=(com_re0123_4567[DATA_WIDTH-1]^com_re89[DATA_WIDTH-1])   ?\\n\\\n",
    "                                                        ((com_re0123_4567[DATA_WIDTH-1]==1'b0)  ?   com_re0123_4567:com_re89):\\n\\\n",
    "                                                        ((com_re0123_4567[DATA_WIDTH-1:0]>com_re89[DATA_WIDTH-1:0]) ?   com_re0123_4567:com_re89);\\n\")\n",
    "f.write(\"integer i;\\n\")\n",
    "f.write(\"always@(posedge clk )\\n\")\n",
    "f.write(\"begin\\n\\\n",
    "    if(rst)\\n\\\n",
    "            begin\\n\\\n",
    "                for(i=0;i<10;i=i+1)\\n\\\n",
    "                    begin\\n\\\n",
    "                        result[i]<={\"+str(data_sz)+\"'b0};\\n\\\n",
    "                    end\\n\\\n",
    "                predict<=0;\\n\\\n",
    "            end\\n\\\n",
    "    else\\n\\\n",
    "    begin \\n\")\n",
    "f.write(\"\\\n",
    "        predict <={4'b0,com_re01234567_89[4+DATA_WIDTH-1:4+DATA_WIDTH-1-3]};\\n\")\n",
    "for i in range(10):\n",
    "    f.write(\"       result[\"+str(i)+\"]<=layer_out[\"+str(data_sz-1+data_sz*i)+\":\"+str(data_sz*i)+\"];\\n\")\n",
    "f.write(\"\\\n",
    "    end\\n\\\n",
    "end\\n\")\n",
    "\n",
    "\n",
    "\n",
    "f.write(\"endmodule\\n\")\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "layer0_port=layer0_output_size\n",
    "layer2_port=10\n",
    "tb_name=\"top_tcb_\"+str(input_img_sz*input_img_sz)+\"_\"+str(layer0_output_size)+\"_10\"\n",
    "f=open(\"./\"+file_destination+\"/\"+tb_name+\".v\",\"w\")\n",
    "f.write(\"module \"+tb_name+\"(\\n\")\n",
    "f.write(\"input clk,\\n\\\n",
    "input rst,\\n\\\n",
    "input [\"+str(input_img_sz*input_img_sz)+\"*8-1:0] img_source,\\n\\\n",
    "output [31:0] number,\\n\")\n",
    "f.write(\"input valid_top,\\n\")\n",
    "f.write(\"output  ready_top\\n\")\n",
    "f.write(\");\\n\")\n",
    "f.write(\"wire layer0_ready,layer2_ready\\n;\")\n",
    "f.write(\"wire   [\"+str(layer0_bit)+\"*\"+str(layer0_port)+\"-1:0] layer0_out;\\n\")\n",
    "f.write(\"wire   [\"+str(layer2_bit)+\"*\"+str(layer2_port)+\"-1:0] layer2_out;\\n\")\n",
    "f.write(layer0_verilog_file_name+\" DUT_layer0   (.clk(clk),.rst(rst),.img(img_source),.layer_out(layer0_out),.ready(layer0_ready),.valid(valid_top));\\n\")\n",
    "f.write(layer2_verilog_file_name+\" DUT_layer2   (.clk(clk),.rst(rst),.layer_in(layer0_out),.layer_out(layer2_out),.ready(layer2_ready),.valid(layer0_ready));\\n\")\n",
    "f.write(\"comparator DUT_comparator (.clk(clk),.rst(rst),.layer_out(layer2_out),.predict(number),.ready(ready_top),.valid(layer2_ready));\\n\")\n",
    "\n",
    "f.write(\"endmodule\\n\")\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "f=open(\"./\"+file_destination+\"/tb.v\",\"w\")\n",
    "f.write(\"`timescale 1ns/1ps\\n\")\n",
    "f.write(\"module tb;\\n\")\n",
    "\n",
    "f.write(\"reg clk,rst,valid;\\n\")\n",
    "f.write(\"reg [\"+str(input_img_sz*input_img_sz*8)+\"-1:0] img;\\n\")\n",
    "f.write(\"wire [7:0] number;\\n\")\n",
    "f.write(tb_name+\" top_DUT(\\n\\\n",
    "    .clk(clk),\\n\\\n",
    "    .rst(rst),\\n\\\n",
    "    .img_source(img),\\n\\\n",
    "    .valid_top(valid),\\n\\\n",
    "    .ready_top(ready_top),\\n\\\n",
    "    .number(number)\\n\\\n",
    ");\\n\")\n",
    "f.write(\"always #5 clk=~clk;\\n\")\n",
    "f.write(\"initial \\nbegin\\n\")\n",
    "f.write(\"$monitor(\\\"number is %d\\\",number);\\n\")\n",
    "f.write(\"clk=0;rst=1'b1;valid=1'b1;\\n\")\n",
    "f.write(\"img=\"+str(input_img_sz*input_img_sz)+\"'b0;\\n\")\n",
    "f.write(\"#10 rst=1'b0;\\n\")\n",
    "for i in range(10):\n",
    "    f.write(\"@(negedge clk) #(10/4) img=\"+str(input_img_sz*input_img_sz*8)+\"'b\")\n",
    "    img,idx=test_data[i]\n",
    "    img=img.reshape(-1)\n",
    "    img=np.asarray(img)\n",
    "    img=int_conver(img)\n",
    "    for ele in reversed(img):\n",
    "        eight_bit=\"{:08b}\".format(int(ele))\n",
    "        f.write(eight_bit)\n",
    "        #print(ele)\n",
    "    f.write(\";\\n\")\n",
    "\n",
    "\n",
    "\n",
    "f.write(\"#100 $finish;\\n\")\n",
    "\n",
    "\n",
    "f.write(\"end\\n\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "f.write(\"endmodule\\n\")\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "f=open(\"./\"+file_destination+\"/label.txt\",\"w\")\n",
    "for i in range(10):\n",
    "    img,idx=test_data[i]\n",
    "    f.write(str(idx))\n",
    "    f.write(\"\\n\")\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
