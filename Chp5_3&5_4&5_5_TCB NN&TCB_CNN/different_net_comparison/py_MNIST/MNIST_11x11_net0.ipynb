{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torchvision\n",
    "from torchvision import datasets\n",
    "from torchvision.transforms import ToTensor\n",
    "test_data = datasets.MNIST(\n",
    "    root=\"data\",\n",
    "    train=False,\n",
    "    download=True,\n",
    "    transform=ToTensor(),\n",
    ")\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets\n",
    "from torchvision.transforms import ToTensor\n",
    "import numpy as np\n",
    "import torch.onnx\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_img_sz=11\n",
    "layer0_output_size =16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "# Download training data from open datasets.\n",
    "training_data = datasets.MNIST(\n",
    "    root=\"../data\",    \n",
    "    train=True,\n",
    "    download=True,\n",
    "    transform=torchvision.transforms.Compose(\n",
    "        [torchvision.transforms.Resize(input_img_sz), torchvision.transforms.ToTensor()]\n",
    "    ),\n",
    ")\n",
    "\n",
    "# Download test data from open datasets.\n",
    "test_data = datasets.MNIST(\n",
    "    root=\"../data\",\n",
    "    train=False,\n",
    "    download=True,\n",
    "    transform=torchvision.transforms.Compose(\n",
    "        [torchvision.transforms.Resize(input_img_sz), torchvision.transforms.ToTensor()]\n",
    "    ),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda device\n",
      "NeuralNetwork(\n",
      "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
      "  (liner0): Linear(in_features=121, out_features=16, bias=True)\n",
      "  (relu): ReLU(inplace=True)\n",
      "  (liner1): Linear(in_features=16, out_features=10, bias=True)\n",
      ")\n",
      "Shape of X [N, C, H, W]: torch.Size([64, 1, 11, 11])\n",
      "Shape of y: torch.Size([64]) torch.int64\n"
     ]
    }
   ],
   "source": [
    "# Get cpu or gpu device for training.\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(f\"Using {device} device\")\n",
    "\n",
    "# Define model\n",
    "class NeuralNetwork(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(NeuralNetwork, self).__init__()\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.liner0 = nn.Linear(input_img_sz*input_img_sz, layer0_output_size)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.liner1 =nn.Linear(layer0_output_size, 10)\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.flatten(x)\n",
    "        x = self.liner0(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.liner1(x)\n",
    "        return x\n",
    "\n",
    "model = NeuralNetwork().to(device)\n",
    "print(model)\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "\n",
    "# optimizer = torch.optim.SGD(model.parameters(), lr=1e-3)\n",
    "optimizer = torch.optim.Adam(model.parameters(),lr=1e-3)\n",
    "def train(dataloader, model, loss_fn, optimizer):\n",
    "    size = len(dataloader.dataset)\n",
    "    model.train()\n",
    "    for batch, (X, y) in enumerate(dataloader):\n",
    "        X, y = X.to(device), y.to(device)\n",
    "\n",
    "        # Compute prediction error\n",
    "        pred = model(X)\n",
    "        loss = loss_fn(pred, y)\n",
    "\n",
    "        # Backpropagation\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        if batch % 100 == 0:\n",
    "            loss, current = loss.item(), batch * len(X)\n",
    "            print(f\"loss: {loss:>7f}  [{current:>5d}/{size:>5d}]\")\n",
    "\n",
    "def test(dataloader, model, loss_fn):\n",
    "    size = len(dataloader.dataset)\n",
    "    num_batches = len(dataloader)\n",
    "    model.eval()\n",
    "    test_loss, correct = 0, 0\n",
    "    with torch.no_grad():\n",
    "        for X, y in dataloader:\n",
    "            X, y = X.to(device), y.to(device)\n",
    "            pred = model(X)\n",
    "            test_loss += loss_fn(pred, y).item()\n",
    "            correct += (pred.argmax(1) == y).type(torch.float).sum().item()\n",
    "    test_loss /= num_batches\n",
    "    correct /= size\n",
    "    print(f\"Test Error: \\n Accuracy: {(100*correct):>0.1f}%, Avg loss: {test_loss:>8f} \\n\")\n",
    "    return correct\n",
    "batch_size = 64\n",
    "\n",
    "# Create data loaders.\n",
    "train_dataloader = DataLoader(training_data, batch_size=batch_size)\n",
    "test_dataloader = DataLoader(test_data, batch_size=batch_size)\n",
    "\n",
    "for X, y in test_dataloader:\n",
    "    print(f\"Shape of X [N, C, H, W]: {X.shape}\")\n",
    "    print(f\"Shape of y: {y.shape} {y.dtype}\")\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "def myplot(x_data,ydata,name):\n",
    "    import matplotlib.pyplot as plt\n",
    "    plt.plot(x_data,ydata)\n",
    "    plt.title(\"Learning Curve \"+name,fontsize=18)\n",
    "    plt.xlabel(\"Epoch\",fontsize=30)\n",
    "    plt.xticks(fontsize=20)\n",
    "    plt.ylabel(\"Accuracy(%)\",fontsize=20)\n",
    "    plt.yticks(fontsize=20)\n",
    "    plt.grid()\n",
    "    fig = plt.gcf()\n",
    "    fig.set_size_inches(12,10)\n",
    "    fig.savefig('./Learning_curve_png/'+name, dpi=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1\n",
      "-------------------------------\n",
      "loss: 2.323524  [    0/60000]\n",
      "loss: 1.926659  [ 6400/60000]\n",
      "loss: 1.461270  [12800/60000]\n",
      "loss: 0.959743  [19200/60000]\n",
      "loss: 0.802869  [25600/60000]\n",
      "loss: 0.678762  [32000/60000]\n",
      "loss: 0.502430  [38400/60000]\n",
      "loss: 0.681568  [44800/60000]\n",
      "loss: 0.589091  [51200/60000]\n",
      "loss: 0.542241  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 87.6%, Avg loss: 0.468602 \n",
      "\n",
      "Epoch 2\n",
      "-------------------------------\n",
      "loss: 0.518869  [    0/60000]\n",
      "loss: 0.429030  [ 6400/60000]\n",
      "loss: 0.400153  [12800/60000]\n",
      "loss: 0.445035  [19200/60000]\n",
      "loss: 0.401973  [25600/60000]\n",
      "loss: 0.414819  [32000/60000]\n",
      "loss: 0.272269  [38400/60000]\n",
      "loss: 0.463455  [44800/60000]\n",
      "loss: 0.399035  [51200/60000]\n",
      "loss: 0.438740  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 90.1%, Avg loss: 0.352857 \n",
      "\n",
      "Epoch 3\n",
      "-------------------------------\n",
      "loss: 0.350658  [    0/60000]\n",
      "loss: 0.345944  [ 6400/60000]\n",
      "loss: 0.302196  [12800/60000]\n",
      "loss: 0.393148  [19200/60000]\n",
      "loss: 0.321957  [25600/60000]\n",
      "loss: 0.369006  [32000/60000]\n",
      "loss: 0.223903  [38400/60000]\n",
      "loss: 0.399311  [44800/60000]\n",
      "loss: 0.346267  [51200/60000]\n",
      "loss: 0.396509  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 90.8%, Avg loss: 0.315258 \n",
      "\n",
      "Epoch 4\n",
      "-------------------------------\n",
      "loss: 0.281946  [    0/60000]\n",
      "loss: 0.319245  [ 6400/60000]\n",
      "loss: 0.260589  [12800/60000]\n",
      "loss: 0.374161  [19200/60000]\n",
      "loss: 0.283426  [25600/60000]\n",
      "loss: 0.350403  [32000/60000]\n",
      "loss: 0.200428  [38400/60000]\n",
      "loss: 0.369299  [44800/60000]\n",
      "loss: 0.320130  [51200/60000]\n",
      "loss: 0.368784  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 91.3%, Avg loss: 0.295712 \n",
      "\n",
      "Epoch 5\n",
      "-------------------------------\n",
      "loss: 0.239518  [    0/60000]\n",
      "loss: 0.305098  [ 6400/60000]\n",
      "loss: 0.233434  [12800/60000]\n",
      "loss: 0.359621  [19200/60000]\n",
      "loss: 0.262237  [25600/60000]\n",
      "loss: 0.339753  [32000/60000]\n",
      "loss: 0.185046  [38400/60000]\n",
      "loss: 0.350326  [44800/60000]\n",
      "loss: 0.302191  [51200/60000]\n",
      "loss: 0.350526  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 91.7%, Avg loss: 0.282722 \n",
      "\n",
      "Epoch 6\n",
      "-------------------------------\n",
      "loss: 0.210213  [    0/60000]\n",
      "loss: 0.299382  [ 6400/60000]\n",
      "loss: 0.214776  [12800/60000]\n",
      "loss: 0.346488  [19200/60000]\n",
      "loss: 0.253367  [25600/60000]\n",
      "loss: 0.333627  [32000/60000]\n",
      "loss: 0.174103  [38400/60000]\n",
      "loss: 0.335924  [44800/60000]\n",
      "loss: 0.285815  [51200/60000]\n",
      "loss: 0.338188  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 91.9%, Avg loss: 0.273131 \n",
      "\n",
      "Epoch 7\n",
      "-------------------------------\n",
      "loss: 0.189767  [    0/60000]\n",
      "loss: 0.295399  [ 6400/60000]\n",
      "loss: 0.202232  [12800/60000]\n",
      "loss: 0.337224  [19200/60000]\n",
      "loss: 0.248020  [25600/60000]\n",
      "loss: 0.332231  [32000/60000]\n",
      "loss: 0.165098  [38400/60000]\n",
      "loss: 0.323884  [44800/60000]\n",
      "loss: 0.264242  [51200/60000]\n",
      "loss: 0.326699  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 92.1%, Avg loss: 0.265491 \n",
      "\n",
      "Epoch 8\n",
      "-------------------------------\n",
      "loss: 0.172698  [    0/60000]\n",
      "loss: 0.292541  [ 6400/60000]\n",
      "loss: 0.193552  [12800/60000]\n",
      "loss: 0.331624  [19200/60000]\n",
      "loss: 0.247227  [25600/60000]\n",
      "loss: 0.332432  [32000/60000]\n",
      "loss: 0.159098  [38400/60000]\n",
      "loss: 0.314368  [44800/60000]\n",
      "loss: 0.243579  [51200/60000]\n",
      "loss: 0.318688  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 92.4%, Avg loss: 0.259039 \n",
      "\n",
      "Epoch 9\n",
      "-------------------------------\n",
      "loss: 0.159339  [    0/60000]\n",
      "loss: 0.289713  [ 6400/60000]\n",
      "loss: 0.185600  [12800/60000]\n",
      "loss: 0.325429  [19200/60000]\n",
      "loss: 0.246113  [25600/60000]\n",
      "loss: 0.329565  [32000/60000]\n",
      "loss: 0.152806  [38400/60000]\n",
      "loss: 0.306383  [44800/60000]\n",
      "loss: 0.229729  [51200/60000]\n",
      "loss: 0.310098  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 92.5%, Avg loss: 0.253723 \n",
      "\n",
      "Epoch 10\n",
      "-------------------------------\n",
      "loss: 0.148833  [    0/60000]\n",
      "loss: 0.286824  [ 6400/60000]\n",
      "loss: 0.178786  [12800/60000]\n",
      "loss: 0.317404  [19200/60000]\n",
      "loss: 0.245535  [25600/60000]\n",
      "loss: 0.326133  [32000/60000]\n",
      "loss: 0.146857  [38400/60000]\n",
      "loss: 0.300079  [44800/60000]\n",
      "loss: 0.217160  [51200/60000]\n",
      "loss: 0.302094  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 92.6%, Avg loss: 0.248954 \n",
      "\n",
      "Epoch 11\n",
      "-------------------------------\n",
      "loss: 0.140268  [    0/60000]\n",
      "loss: 0.281321  [ 6400/60000]\n",
      "loss: 0.174027  [12800/60000]\n",
      "loss: 0.311716  [19200/60000]\n",
      "loss: 0.246124  [25600/60000]\n",
      "loss: 0.323841  [32000/60000]\n",
      "loss: 0.141130  [38400/60000]\n",
      "loss: 0.292586  [44800/60000]\n",
      "loss: 0.207473  [51200/60000]\n",
      "loss: 0.296993  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 92.7%, Avg loss: 0.244611 \n",
      "\n",
      "Epoch 12\n",
      "-------------------------------\n",
      "loss: 0.134531  [    0/60000]\n",
      "loss: 0.277096  [ 6400/60000]\n",
      "loss: 0.169826  [12800/60000]\n",
      "loss: 0.308258  [19200/60000]\n",
      "loss: 0.245971  [25600/60000]\n",
      "loss: 0.321826  [32000/60000]\n",
      "loss: 0.135209  [38400/60000]\n",
      "loss: 0.289718  [44800/60000]\n",
      "loss: 0.198766  [51200/60000]\n",
      "loss: 0.290965  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 92.9%, Avg loss: 0.240766 \n",
      "\n",
      "Epoch 13\n",
      "-------------------------------\n",
      "loss: 0.130547  [    0/60000]\n",
      "loss: 0.273025  [ 6400/60000]\n",
      "loss: 0.165472  [12800/60000]\n",
      "loss: 0.307995  [19200/60000]\n",
      "loss: 0.244082  [25600/60000]\n",
      "loss: 0.320491  [32000/60000]\n",
      "loss: 0.130375  [38400/60000]\n",
      "loss: 0.285631  [44800/60000]\n",
      "loss: 0.192344  [51200/60000]\n",
      "loss: 0.284762  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 93.0%, Avg loss: 0.236753 \n",
      "\n",
      "Epoch 14\n",
      "-------------------------------\n",
      "loss: 0.129158  [    0/60000]\n",
      "loss: 0.268818  [ 6400/60000]\n",
      "loss: 0.163228  [12800/60000]\n",
      "loss: 0.309588  [19200/60000]\n",
      "loss: 0.244099  [25600/60000]\n",
      "loss: 0.319488  [32000/60000]\n",
      "loss: 0.126942  [38400/60000]\n",
      "loss: 0.283570  [44800/60000]\n",
      "loss: 0.186473  [51200/60000]\n",
      "loss: 0.277478  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 93.0%, Avg loss: 0.233211 \n",
      "\n",
      "Epoch 15\n",
      "-------------------------------\n",
      "loss: 0.127699  [    0/60000]\n",
      "loss: 0.265201  [ 6400/60000]\n",
      "loss: 0.158536  [12800/60000]\n",
      "loss: 0.310653  [19200/60000]\n",
      "loss: 0.244177  [25600/60000]\n",
      "loss: 0.319915  [32000/60000]\n",
      "loss: 0.125047  [38400/60000]\n",
      "loss: 0.281644  [44800/60000]\n",
      "loss: 0.181839  [51200/60000]\n",
      "loss: 0.270433  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 93.1%, Avg loss: 0.229581 \n",
      "\n",
      "Epoch 16\n",
      "-------------------------------\n",
      "loss: 0.126067  [    0/60000]\n",
      "loss: 0.260356  [ 6400/60000]\n",
      "loss: 0.153999  [12800/60000]\n",
      "loss: 0.314203  [19200/60000]\n",
      "loss: 0.245911  [25600/60000]\n",
      "loss: 0.319343  [32000/60000]\n",
      "loss: 0.122820  [38400/60000]\n",
      "loss: 0.280778  [44800/60000]\n",
      "loss: 0.178564  [51200/60000]\n",
      "loss: 0.263664  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 93.2%, Avg loss: 0.226407 \n",
      "\n",
      "Epoch 17\n",
      "-------------------------------\n",
      "loss: 0.124496  [    0/60000]\n",
      "loss: 0.256395  [ 6400/60000]\n",
      "loss: 0.148964  [12800/60000]\n",
      "loss: 0.315325  [19200/60000]\n",
      "loss: 0.246869  [25600/60000]\n",
      "loss: 0.320126  [32000/60000]\n",
      "loss: 0.120385  [38400/60000]\n",
      "loss: 0.280945  [44800/60000]\n",
      "loss: 0.176434  [51200/60000]\n",
      "loss: 0.257701  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 93.4%, Avg loss: 0.223268 \n",
      "\n",
      "Epoch 18\n",
      "-------------------------------\n",
      "loss: 0.123426  [    0/60000]\n",
      "loss: 0.253698  [ 6400/60000]\n",
      "loss: 0.144301  [12800/60000]\n",
      "loss: 0.317152  [19200/60000]\n",
      "loss: 0.247040  [25600/60000]\n",
      "loss: 0.318599  [32000/60000]\n",
      "loss: 0.118862  [38400/60000]\n",
      "loss: 0.282789  [44800/60000]\n",
      "loss: 0.173685  [51200/60000]\n",
      "loss: 0.255296  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 93.5%, Avg loss: 0.220104 \n",
      "\n",
      "Epoch 19\n",
      "-------------------------------\n",
      "loss: 0.122164  [    0/60000]\n",
      "loss: 0.248941  [ 6400/60000]\n",
      "loss: 0.140435  [12800/60000]\n",
      "loss: 0.319093  [19200/60000]\n",
      "loss: 0.248182  [25600/60000]\n",
      "loss: 0.315915  [32000/60000]\n",
      "loss: 0.116894  [38400/60000]\n",
      "loss: 0.283557  [44800/60000]\n",
      "loss: 0.171029  [51200/60000]\n",
      "loss: 0.251110  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 93.6%, Avg loss: 0.217184 \n",
      "\n",
      "Epoch 20\n",
      "-------------------------------\n",
      "loss: 0.121387  [    0/60000]\n",
      "loss: 0.245466  [ 6400/60000]\n",
      "loss: 0.135115  [12800/60000]\n",
      "loss: 0.321348  [19200/60000]\n",
      "loss: 0.247298  [25600/60000]\n",
      "loss: 0.310976  [32000/60000]\n",
      "loss: 0.114670  [38400/60000]\n",
      "loss: 0.285853  [44800/60000]\n",
      "loss: 0.168750  [51200/60000]\n",
      "loss: 0.247073  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 93.7%, Avg loss: 0.214162 \n",
      "\n",
      "Epoch 21\n",
      "-------------------------------\n",
      "loss: 0.119888  [    0/60000]\n",
      "loss: 0.240490  [ 6400/60000]\n",
      "loss: 0.131934  [12800/60000]\n",
      "loss: 0.322526  [19200/60000]\n",
      "loss: 0.247536  [25600/60000]\n",
      "loss: 0.305341  [32000/60000]\n",
      "loss: 0.113065  [38400/60000]\n",
      "loss: 0.289063  [44800/60000]\n",
      "loss: 0.168667  [51200/60000]\n",
      "loss: 0.243608  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 93.8%, Avg loss: 0.211628 \n",
      "\n",
      "Epoch 22\n",
      "-------------------------------\n",
      "loss: 0.118904  [    0/60000]\n",
      "loss: 0.235348  [ 6400/60000]\n",
      "loss: 0.128820  [12800/60000]\n",
      "loss: 0.326400  [19200/60000]\n",
      "loss: 0.246313  [25600/60000]\n",
      "loss: 0.299175  [32000/60000]\n",
      "loss: 0.111848  [38400/60000]\n",
      "loss: 0.292604  [44800/60000]\n",
      "loss: 0.169461  [51200/60000]\n",
      "loss: 0.241354  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 93.9%, Avg loss: 0.209039 \n",
      "\n",
      "Epoch 23\n",
      "-------------------------------\n",
      "loss: 0.117464  [    0/60000]\n",
      "loss: 0.230332  [ 6400/60000]\n",
      "loss: 0.123925  [12800/60000]\n",
      "loss: 0.328639  [19200/60000]\n",
      "loss: 0.243437  [25600/60000]\n",
      "loss: 0.295182  [32000/60000]\n",
      "loss: 0.111610  [38400/60000]\n",
      "loss: 0.294326  [44800/60000]\n",
      "loss: 0.170362  [51200/60000]\n",
      "loss: 0.239717  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 93.9%, Avg loss: 0.206676 \n",
      "\n",
      "Epoch 24\n",
      "-------------------------------\n",
      "loss: 0.116610  [    0/60000]\n",
      "loss: 0.222492  [ 6400/60000]\n",
      "loss: 0.119554  [12800/60000]\n",
      "loss: 0.328242  [19200/60000]\n",
      "loss: 0.240213  [25600/60000]\n",
      "loss: 0.288256  [32000/60000]\n",
      "loss: 0.110223  [38400/60000]\n",
      "loss: 0.291524  [44800/60000]\n",
      "loss: 0.170465  [51200/60000]\n",
      "loss: 0.238752  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 94.0%, Avg loss: 0.204129 \n",
      "\n",
      "Epoch 25\n",
      "-------------------------------\n",
      "loss: 0.115179  [    0/60000]\n",
      "loss: 0.214780  [ 6400/60000]\n",
      "loss: 0.114677  [12800/60000]\n",
      "loss: 0.329021  [19200/60000]\n",
      "loss: 0.237068  [25600/60000]\n",
      "loss: 0.283889  [32000/60000]\n",
      "loss: 0.109001  [38400/60000]\n",
      "loss: 0.290427  [44800/60000]\n",
      "loss: 0.171502  [51200/60000]\n",
      "loss: 0.238444  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 94.1%, Avg loss: 0.201924 \n",
      "\n",
      "Epoch 26\n",
      "-------------------------------\n",
      "loss: 0.114298  [    0/60000]\n",
      "loss: 0.208451  [ 6400/60000]\n",
      "loss: 0.109733  [12800/60000]\n",
      "loss: 0.329035  [19200/60000]\n",
      "loss: 0.234532  [25600/60000]\n",
      "loss: 0.279100  [32000/60000]\n",
      "loss: 0.107947  [38400/60000]\n",
      "loss: 0.287790  [44800/60000]\n",
      "loss: 0.172692  [51200/60000]\n",
      "loss: 0.236016  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 94.1%, Avg loss: 0.199782 \n",
      "\n",
      "Epoch 27\n",
      "-------------------------------\n",
      "loss: 0.114525  [    0/60000]\n",
      "loss: 0.202580  [ 6400/60000]\n",
      "loss: 0.105496  [12800/60000]\n",
      "loss: 0.330008  [19200/60000]\n",
      "loss: 0.230834  [25600/60000]\n",
      "loss: 0.273802  [32000/60000]\n",
      "loss: 0.106034  [38400/60000]\n",
      "loss: 0.284547  [44800/60000]\n",
      "loss: 0.175186  [51200/60000]\n",
      "loss: 0.234897  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 94.2%, Avg loss: 0.197865 \n",
      "\n",
      "Epoch 28\n",
      "-------------------------------\n",
      "loss: 0.114880  [    0/60000]\n",
      "loss: 0.197715  [ 6400/60000]\n",
      "loss: 0.101563  [12800/60000]\n",
      "loss: 0.332167  [19200/60000]\n",
      "loss: 0.225084  [25600/60000]\n",
      "loss: 0.270528  [32000/60000]\n",
      "loss: 0.105767  [38400/60000]\n",
      "loss: 0.281991  [44800/60000]\n",
      "loss: 0.175637  [51200/60000]\n",
      "loss: 0.232866  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 94.2%, Avg loss: 0.196194 \n",
      "\n",
      "Epoch 29\n",
      "-------------------------------\n",
      "loss: 0.114604  [    0/60000]\n",
      "loss: 0.195241  [ 6400/60000]\n",
      "loss: 0.098781  [12800/60000]\n",
      "loss: 0.333607  [19200/60000]\n",
      "loss: 0.220106  [25600/60000]\n",
      "loss: 0.268652  [32000/60000]\n",
      "loss: 0.104677  [38400/60000]\n",
      "loss: 0.281326  [44800/60000]\n",
      "loss: 0.175584  [51200/60000]\n",
      "loss: 0.232262  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 94.3%, Avg loss: 0.194640 \n",
      "\n",
      "Epoch 30\n",
      "-------------------------------\n",
      "loss: 0.115760  [    0/60000]\n",
      "loss: 0.193503  [ 6400/60000]\n",
      "loss: 0.096310  [12800/60000]\n",
      "loss: 0.334439  [19200/60000]\n",
      "loss: 0.215429  [25600/60000]\n",
      "loss: 0.265948  [32000/60000]\n",
      "loss: 0.104244  [38400/60000]\n",
      "loss: 0.280465  [44800/60000]\n",
      "loss: 0.177268  [51200/60000]\n",
      "loss: 0.231494  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 94.3%, Avg loss: 0.193256 \n",
      "\n",
      "Epoch 31\n",
      "-------------------------------\n",
      "loss: 0.117220  [    0/60000]\n",
      "loss: 0.191251  [ 6400/60000]\n",
      "loss: 0.093866  [12800/60000]\n",
      "loss: 0.334947  [19200/60000]\n",
      "loss: 0.210130  [25600/60000]\n",
      "loss: 0.264769  [32000/60000]\n",
      "loss: 0.104347  [38400/60000]\n",
      "loss: 0.278626  [44800/60000]\n",
      "loss: 0.178513  [51200/60000]\n",
      "loss: 0.231037  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 94.3%, Avg loss: 0.192016 \n",
      "\n",
      "Epoch 32\n",
      "-------------------------------\n",
      "loss: 0.118998  [    0/60000]\n",
      "loss: 0.188347  [ 6400/60000]\n",
      "loss: 0.091624  [12800/60000]\n",
      "loss: 0.334362  [19200/60000]\n",
      "loss: 0.205921  [25600/60000]\n",
      "loss: 0.262761  [32000/60000]\n",
      "loss: 0.104090  [38400/60000]\n",
      "loss: 0.276803  [44800/60000]\n",
      "loss: 0.179439  [51200/60000]\n",
      "loss: 0.230970  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 94.4%, Avg loss: 0.190858 \n",
      "\n",
      "Epoch 33\n",
      "-------------------------------\n",
      "loss: 0.120895  [    0/60000]\n",
      "loss: 0.186929  [ 6400/60000]\n",
      "loss: 0.090378  [12800/60000]\n",
      "loss: 0.335953  [19200/60000]\n",
      "loss: 0.201647  [25600/60000]\n",
      "loss: 0.261224  [32000/60000]\n",
      "loss: 0.103775  [38400/60000]\n",
      "loss: 0.275850  [44800/60000]\n",
      "loss: 0.180863  [51200/60000]\n",
      "loss: 0.231021  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 94.5%, Avg loss: 0.189773 \n",
      "\n",
      "Epoch 34\n",
      "-------------------------------\n",
      "loss: 0.121902  [    0/60000]\n",
      "loss: 0.185618  [ 6400/60000]\n",
      "loss: 0.089043  [12800/60000]\n",
      "loss: 0.334821  [19200/60000]\n",
      "loss: 0.195993  [25600/60000]\n",
      "loss: 0.259974  [32000/60000]\n",
      "loss: 0.104160  [38400/60000]\n",
      "loss: 0.275060  [44800/60000]\n",
      "loss: 0.181198  [51200/60000]\n",
      "loss: 0.230961  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 94.5%, Avg loss: 0.188657 \n",
      "\n",
      "Epoch 35\n",
      "-------------------------------\n",
      "loss: 0.122195  [    0/60000]\n",
      "loss: 0.184559  [ 6400/60000]\n",
      "loss: 0.087687  [12800/60000]\n",
      "loss: 0.334579  [19200/60000]\n",
      "loss: 0.192561  [25600/60000]\n",
      "loss: 0.259551  [32000/60000]\n",
      "loss: 0.104320  [38400/60000]\n",
      "loss: 0.273470  [44800/60000]\n",
      "loss: 0.181958  [51200/60000]\n",
      "loss: 0.232164  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 94.6%, Avg loss: 0.187777 \n",
      "\n",
      "Epoch 36\n",
      "-------------------------------\n",
      "loss: 0.122581  [    0/60000]\n",
      "loss: 0.183191  [ 6400/60000]\n",
      "loss: 0.086684  [12800/60000]\n",
      "loss: 0.332614  [19200/60000]\n",
      "loss: 0.188933  [25600/60000]\n",
      "loss: 0.257757  [32000/60000]\n",
      "loss: 0.105032  [38400/60000]\n",
      "loss: 0.272881  [44800/60000]\n",
      "loss: 0.183369  [51200/60000]\n",
      "loss: 0.233176  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 94.6%, Avg loss: 0.186854 \n",
      "\n",
      "Epoch 37\n",
      "-------------------------------\n",
      "loss: 0.123095  [    0/60000]\n",
      "loss: 0.181775  [ 6400/60000]\n",
      "loss: 0.085624  [12800/60000]\n",
      "loss: 0.331238  [19200/60000]\n",
      "loss: 0.186495  [25600/60000]\n",
      "loss: 0.256182  [32000/60000]\n",
      "loss: 0.105162  [38400/60000]\n",
      "loss: 0.273036  [44800/60000]\n",
      "loss: 0.183352  [51200/60000]\n",
      "loss: 0.233720  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 94.6%, Avg loss: 0.186118 \n",
      "\n",
      "Epoch 38\n",
      "-------------------------------\n",
      "loss: 0.123854  [    0/60000]\n",
      "loss: 0.179503  [ 6400/60000]\n",
      "loss: 0.084438  [12800/60000]\n",
      "loss: 0.329822  [19200/60000]\n",
      "loss: 0.184213  [25600/60000]\n",
      "loss: 0.255250  [32000/60000]\n",
      "loss: 0.106287  [38400/60000]\n",
      "loss: 0.272898  [44800/60000]\n",
      "loss: 0.183931  [51200/60000]\n",
      "loss: 0.234938  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 94.6%, Avg loss: 0.185360 \n",
      "\n",
      "Epoch 39\n",
      "-------------------------------\n",
      "loss: 0.125030  [    0/60000]\n",
      "loss: 0.177896  [ 6400/60000]\n",
      "loss: 0.083658  [12800/60000]\n",
      "loss: 0.327578  [19200/60000]\n",
      "loss: 0.182032  [25600/60000]\n",
      "loss: 0.254622  [32000/60000]\n",
      "loss: 0.107103  [38400/60000]\n",
      "loss: 0.271122  [44800/60000]\n",
      "loss: 0.184153  [51200/60000]\n",
      "loss: 0.235981  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 94.6%, Avg loss: 0.184669 \n",
      "\n",
      "Epoch 40\n",
      "-------------------------------\n",
      "loss: 0.126238  [    0/60000]\n",
      "loss: 0.177044  [ 6400/60000]\n",
      "loss: 0.083027  [12800/60000]\n",
      "loss: 0.324521  [19200/60000]\n",
      "loss: 0.178518  [25600/60000]\n",
      "loss: 0.253977  [32000/60000]\n",
      "loss: 0.107689  [38400/60000]\n",
      "loss: 0.269714  [44800/60000]\n",
      "loss: 0.184604  [51200/60000]\n",
      "loss: 0.237006  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 94.6%, Avg loss: 0.184115 \n",
      "\n",
      "Epoch 41\n",
      "-------------------------------\n",
      "loss: 0.128073  [    0/60000]\n",
      "loss: 0.175781  [ 6400/60000]\n",
      "loss: 0.082306  [12800/60000]\n",
      "loss: 0.322127  [19200/60000]\n",
      "loss: 0.176074  [25600/60000]\n",
      "loss: 0.253765  [32000/60000]\n",
      "loss: 0.108228  [38400/60000]\n",
      "loss: 0.268576  [44800/60000]\n",
      "loss: 0.184249  [51200/60000]\n",
      "loss: 0.237210  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 94.7%, Avg loss: 0.183463 \n",
      "\n",
      "Epoch 42\n",
      "-------------------------------\n",
      "loss: 0.129870  [    0/60000]\n",
      "loss: 0.174875  [ 6400/60000]\n",
      "loss: 0.081462  [12800/60000]\n",
      "loss: 0.320163  [19200/60000]\n",
      "loss: 0.173494  [25600/60000]\n",
      "loss: 0.253796  [32000/60000]\n",
      "loss: 0.108646  [38400/60000]\n",
      "loss: 0.267274  [44800/60000]\n",
      "loss: 0.184254  [51200/60000]\n",
      "loss: 0.237680  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 94.7%, Avg loss: 0.183060 \n",
      "\n",
      "Epoch 43\n",
      "-------------------------------\n",
      "loss: 0.131709  [    0/60000]\n",
      "loss: 0.173092  [ 6400/60000]\n",
      "loss: 0.080750  [12800/60000]\n",
      "loss: 0.317389  [19200/60000]\n",
      "loss: 0.172018  [25600/60000]\n",
      "loss: 0.253316  [32000/60000]\n",
      "loss: 0.109898  [38400/60000]\n",
      "loss: 0.266261  [44800/60000]\n",
      "loss: 0.183554  [51200/60000]\n",
      "loss: 0.238340  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 94.7%, Avg loss: 0.182556 \n",
      "\n",
      "Epoch 44\n",
      "-------------------------------\n",
      "loss: 0.133148  [    0/60000]\n",
      "loss: 0.170766  [ 6400/60000]\n",
      "loss: 0.080115  [12800/60000]\n",
      "loss: 0.314241  [19200/60000]\n",
      "loss: 0.168978  [25600/60000]\n",
      "loss: 0.253279  [32000/60000]\n",
      "loss: 0.111278  [38400/60000]\n",
      "loss: 0.264844  [44800/60000]\n",
      "loss: 0.182245  [51200/60000]\n",
      "loss: 0.237987  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 94.7%, Avg loss: 0.182113 \n",
      "\n",
      "Epoch 45\n",
      "-------------------------------\n",
      "loss: 0.134901  [    0/60000]\n",
      "loss: 0.169311  [ 6400/60000]\n",
      "loss: 0.079437  [12800/60000]\n",
      "loss: 0.311182  [19200/60000]\n",
      "loss: 0.168057  [25600/60000]\n",
      "loss: 0.253056  [32000/60000]\n",
      "loss: 0.112220  [38400/60000]\n",
      "loss: 0.263740  [44800/60000]\n",
      "loss: 0.182329  [51200/60000]\n",
      "loss: 0.238237  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 94.7%, Avg loss: 0.181609 \n",
      "\n",
      "Epoch 46\n",
      "-------------------------------\n",
      "loss: 0.136849  [    0/60000]\n",
      "loss: 0.166287  [ 6400/60000]\n",
      "loss: 0.078751  [12800/60000]\n",
      "loss: 0.306746  [19200/60000]\n",
      "loss: 0.166773  [25600/60000]\n",
      "loss: 0.253497  [32000/60000]\n",
      "loss: 0.113129  [38400/60000]\n",
      "loss: 0.261942  [44800/60000]\n",
      "loss: 0.181481  [51200/60000]\n",
      "loss: 0.237624  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 94.8%, Avg loss: 0.181229 \n",
      "\n",
      "Epoch 47\n",
      "-------------------------------\n",
      "loss: 0.138576  [    0/60000]\n",
      "loss: 0.164915  [ 6400/60000]\n",
      "loss: 0.078212  [12800/60000]\n",
      "loss: 0.303967  [19200/60000]\n",
      "loss: 0.165050  [25600/60000]\n",
      "loss: 0.252205  [32000/60000]\n",
      "loss: 0.113545  [38400/60000]\n",
      "loss: 0.259577  [44800/60000]\n",
      "loss: 0.180233  [51200/60000]\n",
      "loss: 0.237547  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 94.8%, Avg loss: 0.180774 \n",
      "\n",
      "Epoch 48\n",
      "-------------------------------\n",
      "loss: 0.139505  [    0/60000]\n",
      "loss: 0.163307  [ 6400/60000]\n",
      "loss: 0.077673  [12800/60000]\n",
      "loss: 0.301876  [19200/60000]\n",
      "loss: 0.163651  [25600/60000]\n",
      "loss: 0.252605  [32000/60000]\n",
      "loss: 0.114208  [38400/60000]\n",
      "loss: 0.258188  [44800/60000]\n",
      "loss: 0.179485  [51200/60000]\n",
      "loss: 0.237432  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 94.8%, Avg loss: 0.180358 \n",
      "\n",
      "Epoch 49\n",
      "-------------------------------\n",
      "loss: 0.141410  [    0/60000]\n",
      "loss: 0.162073  [ 6400/60000]\n",
      "loss: 0.077089  [12800/60000]\n",
      "loss: 0.299547  [19200/60000]\n",
      "loss: 0.161623  [25600/60000]\n",
      "loss: 0.251594  [32000/60000]\n",
      "loss: 0.114842  [38400/60000]\n",
      "loss: 0.257467  [44800/60000]\n",
      "loss: 0.179067  [51200/60000]\n",
      "loss: 0.237445  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 94.8%, Avg loss: 0.180023 \n",
      "\n",
      "Epoch 50\n",
      "-------------------------------\n",
      "loss: 0.143037  [    0/60000]\n",
      "loss: 0.161764  [ 6400/60000]\n",
      "loss: 0.076950  [12800/60000]\n",
      "loss: 0.296687  [19200/60000]\n",
      "loss: 0.160337  [25600/60000]\n",
      "loss: 0.251814  [32000/60000]\n",
      "loss: 0.115501  [38400/60000]\n",
      "loss: 0.255774  [44800/60000]\n",
      "loss: 0.178813  [51200/60000]\n",
      "loss: 0.237188  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 94.8%, Avg loss: 0.179693 \n",
      "\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "acc_line = []\n",
    "file_name =\"1MNIST\"+str(input_img_sz)+\"x\"+str(input_img_sz)+\"_\"+str(layer0_output_size)+\"_10.pth\"\n",
    "if not (os.path.isfile(file_name)):\n",
    "    epochs = 50\n",
    "    for t in range(epochs):\n",
    "        print(f\"Epoch {t+1}\\n-------------------------------\")\n",
    "        train(train_dataloader, model, loss_fn, optimizer)\n",
    "        acc_result=test(test_dataloader, model, loss_fn)\n",
    "        acc_line.append(acc_result)\n",
    "        # torch.save(model, file_name)\n",
    "    print(\"Done!\")\n",
    "\n",
    "else:\n",
    "    #model.load_state_dict(torch.load(\"model.pth\"))\n",
    "    model = torch.load( file_name)\n",
    "    print(\"Model loaded\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 864x720 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "myplot(np.arange(1,epochs+1),acc_line,\"net2 121x16x10\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Error: \n",
      " Accuracy: 94.6%, Avg loss: 1621.702323 \n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "OrderedDict([('liner0.weight',\n",
       "              tensor([[ 19.,  33., -23.,  ...,   0.,   8., -15.],\n",
       "                      [-21.,  27.,  73.,  ..., -18.,  31.,  57.],\n",
       "                      [ 18.,  13.,  60.,  ...,  55., -14.,  14.],\n",
       "                      ...,\n",
       "                      [-25., -56., -60.,  ..., -24., -12., -24.],\n",
       "                      [ -9., -35., -55.,  ...,  62., 113.,  25.],\n",
       "                      [-51., -50., -80.,  ...,  46., -10., -26.]], device='cuda:0')),\n",
       "             ('liner0.bias',\n",
       "              tensor([-26.,  45., -11.,  34.,  58.,  36.,  29.,  20.,  55.,  33., -25.,  -1.,\n",
       "                       34.,  13.,  39.,  33.,  -9.,  18.,  11.,   1.,  30.,   8.,  45.,  -5.,\n",
       "                      -33., -28., -15.,   6.,  -9.,  50.,  77., -19.], device='cuda:0')),\n",
       "             ('liner1.weight',\n",
       "              tensor([[  62.,    3.,   62.,   54.,   28., -140., -104.,  -81.,  -66.,  -24.,\n",
       "                        -96.,   77.,  -66., -161., -130.,   86.,  -22.,  -56.,  -11.,   -1.,\n",
       "                         62.,   80.,  -93.,   63.,   22., -100.,   45.,  -38., -175.,  -84.,\n",
       "                         65.,   11.],\n",
       "                      [ -95., -106., -111., -120.,   14.,   23., -148.,   96.,   36., -172.,\n",
       "                       -135.,  -11.,  105.,   40.,   56.,   46.,   20.,  -23.,    5.,  -17.,\n",
       "                         43.,  -92.,   63., -117.,   27.,   55.,  -92.,   65.,   47.,   60.,\n",
       "                       -107., -123.],\n",
       "                      [ -83.,   41.,   72.,  -70.,  -63.,  -69.,    4.,   70., -194.,  -35.,\n",
       "                        -46.,   52.,   47.,  106.,   41.,   62.,  -14.,   42.,   90.,   -6.,\n",
       "                        -24.,   66.,  -63.,   12.,   25.,  -62.,   22.,   87.,   59., -162.,\n",
       "                         44.,   -8.],\n",
       "                      [  78.,   18.,   49.,  -86.,  -28.,  -62.,   31.,   53.,  -53., -145.,\n",
       "                         54.,  -95.,   73.,   30.,  -69.,   46.,   16.,   59., -114.,   -8.,\n",
       "                         66.,  -77.,    8.,   14., -144.,   23.,   23.,  -24.,   39.,  -49.,\n",
       "                        -94.,   33.],\n",
       "                      [ -43.,   52., -141.,   10.,   27.,   -6.,   69.,  -18.,    3.,   81.,\n",
       "                         -1.,  -16.,   87.,   31.,   53., -220., -126.,  -87., -129.,    0.,\n",
       "                        -52.,   20.,  -43.,   40.,   31.,   78.,  -88., -131., -137.,   87.,\n",
       "                         31.,   26.],\n",
       "                      [  25.,   44.,  -21.,   29.,   29.,  106.,  -44.,   -7.,  115.,   39.,\n",
       "                         19.,  -75., -383.,  -27.,  -23.,   61.,   19.,   60.,  -17.,   15.,\n",
       "                         62.,   11.,  -30.,   13., -143.,  -94.,  -73.,  -54.,   64.,  -17.,\n",
       "                         86., -131.],\n",
       "                      [ -75.,   48.,  -47.,  -26.,   89.,   68., -144.,  -39.,   92.,   85.,\n",
       "                       -175.,   90., -181.,    6.,   12.,  -55.,   71.,   22., -109.,    6.,\n",
       "                        -77.,  -14., -109.,   -6.,   90.,   55.,   52.,  -91.,  -87.,  -90.,\n",
       "                       -112.,  -87.],\n",
       "                      [ -10.,  -94.,   71.,   57.,   57., -103.,   53.,  160., -115.,  -42.,\n",
       "                         18.,  -17.,   50.,    6.,   14.,   61., -117.,   46.,   85.,  -19.,\n",
       "                       -187., -111.,   36.,  -94.,  -59.,  -52.,  -55.,  -57.,    5.,   74.,\n",
       "                         83.,   45.],\n",
       "                      [  44.,  -61.,  -13.,   10., -178.,   35.,  -95., -134.,   41.,   35.,\n",
       "                         77.,   10.,  -70.,   -3.,   16.,  -50.,   49.,  -19.,   51.,    6.,\n",
       "                         -6.,   23.,  -13.,   28.,   88.,   55.,  -27.,   31.,   -7.,  -39.,\n",
       "                       -155.,   -1.],\n",
       "                      [ -58.,    7.,   30.,   45.,  -38.,    6.,   56., -320.,   38.,  -10.,\n",
       "                         52.,  -82.,   51., -194.,   -3., -117.,   63., -149.,  -47.,   -5.,\n",
       "                        -26.,  -52.,   74.,  -28.,  -63.,  -72.,   67.,    0., -117.,   34.,\n",
       "                         24.,   99.]], device='cuda:0')),\n",
       "             ('liner1.bias',\n",
       "              tensor([ -8.,  56.,  12., -20., -10.,  67.,  19.,  35., -53.,  17.],\n",
       "                     device='cuda:0'))])"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = torch.load( file_name)\n",
    "for ele in model.state_dict():#turn to numpy\n",
    "    model.state_dict()[ele]=model.state_dict()[ele].cpu().numpy()\n",
    "#turn float to int\n",
    "for layers in model.state_dict():\n",
    "    try:\n",
    "        model.state_dict()[layers].shape[1]## if parameter is 2D\n",
    "        row,col=model.state_dict()[layers].shape\n",
    "        for row in range(model.state_dict()[layers].shape[0]):\n",
    "            for col in range(model.state_dict()[layers].shape[1]):\n",
    "                num=int((model.state_dict()[layers][row][col]+1)/2*255-127)\n",
    "                model.state_dict()[layers][row][col]= num\n",
    "    except:\n",
    "        #model[layers].shape #1D\n",
    "        # print(model[layers].shape[0])\n",
    "        for i in range(model.state_dict()[layers].shape[0]):\n",
    "            num=int((model.state_dict()[layers][i]+1)/2*255-127)\n",
    "            model.state_dict()[layers][i]=num\n",
    "test(test_dataloader, model, loss_fn)\n",
    "model.state_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Error: \n",
      " Accuracy: 89.6%, Avg loss: 3117.486193 \n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "OrderedDict([('liner0.weight',\n",
       "              tensor([[  0.,  59.,   0.,  ...,   0.,   0.,   0.],\n",
       "                      [  0.,   0.,  59.,  ...,   0.,  59.,  59.],\n",
       "                      [  0.,   0.,  59.,  ...,  59.,   0.,   0.],\n",
       "                      ...,\n",
       "                      [  0., -59., -59.,  ...,   0.,   0.,   0.],\n",
       "                      [  0., -59., -59.,  ...,  59., 118.,   0.],\n",
       "                      [-59., -59., -59.,  ...,  59.,   0.,   0.]], device='cuda:0')),\n",
       "             ('liner0.bias',\n",
       "              tensor([  0.,  59.,   0.,  59.,  59.,  59.,   0.,   0.,  59.,  59.,   0.,   0.,\n",
       "                       59.,   0.,  59.,  59.,   0.,   0.,   0.,   0.,  59.,   0.,  59.,   0.,\n",
       "                      -59.,   0.,   0.,   0.,   0.,  59.,  59.,   0.], device='cuda:0')),\n",
       "             ('liner1.weight',\n",
       "              tensor([[  59.,    0.,   59.,   59.,    0., -118., -118.,  -59.,  -59.,    0.,\n",
       "                       -118.,   59.,  -59., -177., -118.,   59.,    0.,  -59.,    0.,    0.,\n",
       "                         59.,   59., -118.,   59.,    0., -118.,   59.,  -59., -177.,  -59.,\n",
       "                         59.,    0.],\n",
       "                      [-118., -118., -118., -118.,    0.,    0., -177.,  118.,   59., -177.,\n",
       "                       -118.,    0.,  118.,   59.,   59.,   59.,    0.,    0.,    0.,    0.,\n",
       "                         59., -118.,   59., -118.,    0.,   59., -118.,   59.,   59.,   59.,\n",
       "                       -118., -118.],\n",
       "                      [ -59.,   59.,   59.,  -59.,  -59.,  -59.,    0.,   59., -177.,  -59.,\n",
       "                        -59.,   59.,   59.,  118.,   59.,   59.,    0.,   59.,  118.,    0.,\n",
       "                          0.,   59.,  -59.,    0.,    0.,  -59.,    0.,   59.,   59., -177.,\n",
       "                         59.,    0.],\n",
       "                      [  59.,    0.,   59.,  -59.,    0.,  -59.,   59.,   59.,  -59., -118.,\n",
       "                         59., -118.,   59.,   59.,  -59.,   59.,    0.,   59., -118.,    0.,\n",
       "                         59.,  -59.,    0.,    0., -118.,    0.,    0.,    0.,   59.,  -59.,\n",
       "                       -118.,   59.],\n",
       "                      [ -59.,   59., -118.,    0.,    0.,    0.,   59.,    0.,    0.,   59.,\n",
       "                          0.,    0.,   59.,   59.,   59., -236., -118.,  -59., -118.,    0.,\n",
       "                        -59.,    0.,  -59.,   59.,   59.,   59.,  -59., -118., -118.,   59.,\n",
       "                         59.,    0.],\n",
       "                      [   0.,   59.,    0.,    0.,    0.,  118.,  -59.,    0.,  118.,   59.,\n",
       "                          0.,  -59., -354.,    0.,    0.,   59.,    0.,   59.,    0.,    0.,\n",
       "                         59.,    0.,  -59.,    0., -118., -118.,  -59.,  -59.,   59.,    0.,\n",
       "                         59., -118.],\n",
       "                      [ -59.,   59.,  -59.,    0.,  118.,   59., -118.,  -59.,  118.,   59.,\n",
       "                       -177.,  118., -177.,    0.,    0.,  -59.,   59.,    0., -118.,    0.,\n",
       "                        -59.,    0., -118.,    0.,  118.,   59.,   59., -118.,  -59., -118.,\n",
       "                       -118.,  -59.],\n",
       "                      [   0., -118.,   59.,   59.,   59., -118.,   59.,  177., -118.,  -59.,\n",
       "                          0.,    0.,   59.,    0.,    0.,   59., -118.,   59.,   59.,    0.,\n",
       "                       -177., -118.,   59., -118.,  -59.,  -59.,  -59.,  -59.,    0.,   59.,\n",
       "                         59.,   59.],\n",
       "                      [  59.,  -59.,    0.,    0., -177.,   59., -118., -118.,   59.,   59.,\n",
       "                         59.,    0.,  -59.,    0.,    0.,  -59.,   59.,    0.,   59.,    0.,\n",
       "                          0.,    0.,    0.,    0.,   59.,   59.,    0.,   59.,    0.,  -59.,\n",
       "                       -177.,    0.],\n",
       "                      [ -59.,    0.,   59.,   59.,  -59.,    0.,   59., -295.,   59.,    0.,\n",
       "                         59.,  -59.,   59., -177.,    0., -118.,   59., -177.,  -59.,    0.,\n",
       "                          0.,  -59.,   59.,    0.,  -59.,  -59.,   59.,    0., -118.,   59.,\n",
       "                          0.,  118.]], device='cuda:0')),\n",
       "             ('liner1.bias',\n",
       "              tensor([  0.,  59.,   0.,   0.,   0.,  59.,   0.,  59., -59.,   0.],\n",
       "                     device='cuda:0'))])"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = torch.load( file_name)\n",
    "A=59\n",
    "for ele in model.state_dict():#turn to numpy\n",
    "    model.state_dict()[ele]=model.state_dict()[ele].cpu().numpy()\n",
    "#turn float to int\n",
    "for layers in model.state_dict():\n",
    "    try:\n",
    "        model.state_dict()[layers].shape[1]## if parameter is 2D\n",
    "        row,col=model.state_dict()[layers].shape\n",
    "        for row in range(model.state_dict()[layers].shape[0]):\n",
    "            for col in range(model.state_dict()[layers].shape[1]):\n",
    "                num=int((model.state_dict()[layers][row][col]+1)/2*255-127)\n",
    "                model.state_dict()[layers][row][col]= round(num/A)*A\n",
    "    except:\n",
    "        #model[layers].shape #1D\n",
    "        # print(model[layers].shape[0])\n",
    "        for i in range(model.state_dict()[layers].shape[0]):\n",
    "            num=int((model.state_dict()[layers][i]+1)/2*255-127)\n",
    "            model.state_dict()[layers][i]=round(num/A)*A\n",
    "test(test_dataloader, model, loss_fn)\n",
    "model.state_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "#turn img from float to int\n",
    "def int_conver(np_a):\n",
    "    for idx,ele in enumerate(np_a):\n",
    "        np_a[idx]=int((ele+1)/2*255-127)\n",
    "\n",
    "    return np_a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ -9771167. -32453304.   -549998.  13854380. -26145791.  -6363209.\n",
      " -34273926.  16454746.  -2461126.   2607269.]\n",
      "1\n",
      "0:  18\n",
      "1:  28\n"
     ]
    }
   ],
   "source": [
    "hit=0\n",
    "lrsb0_len=layer0_output_size\n",
    "lrsb2_len=10\n",
    "max_0,min_0=0,0\n",
    "max_1,min_1=0,0\n",
    "\n",
    "lrsw0=model.state_dict()[\"liner0.weight\"].reshape(-1).cpu().numpy()\n",
    "lrsb0=model.state_dict()[\"liner0.bias\"].reshape(-1).cpu().numpy()\n",
    "lrsw2=model.state_dict()[\"liner1.weight\"].reshape(-1).cpu().numpy()\n",
    "lrsb2=model.state_dict()[\"liner1.bias\"].reshape(-1).cpu().numpy()\n",
    "for r in range(1):    \n",
    "    img,label=test_data[r]\n",
    "    img=img.reshape(-1)\n",
    "    img=int_conver(img)\n",
    "\n",
    "    out1=np.zeros(lrsb0_len)\n",
    "    out2=np.zeros(lrsb2_len)\n",
    "    \n",
    "    for i in range(lrsb0_len):\n",
    "        for j in range(input_img_sz*input_img_sz):\n",
    "            out1[i]+=lrsw0[i*input_img_sz*input_img_sz+j]*img[j]\n",
    "        out1[i]+=lrsb0[i]\n",
    "    # print(out1)\n",
    "\n",
    "    for i in range(lrsb0_len):\n",
    "        if(out1[i]>max_0):\n",
    "            max_0=out1[i]\n",
    "        if(out1[i]<min_0):\n",
    "            min_0=out1[i]\n",
    "        if(out1[i]<0):\n",
    "            out1[i]=0\n",
    "\n",
    "    for i in range(lrsb2_len):\n",
    "        for j in range(lrsb0_len):\n",
    "            out2[i]+=lrsw2[i*lrsb0_len+j]*out1[j]\n",
    "        out2[i]+=lrsb2[i]\n",
    "\n",
    "    for i in range(10):\n",
    "        if(out2[i]>max_1):\n",
    "            max_1=out2[i]\n",
    "        if(out2[i]<min_1):\n",
    "            min_1=out2[i]\n",
    "    print(out2)\n",
    "    if(out2.argmax()==label):\n",
    "        hit+=1\n",
    "\n",
    "    # print(\"now:\",r+1,\"hit:\",hit)\n",
    "print(hit)\n",
    "layer0_bit = len(bin(int(max_0)))\n",
    "layer2_bit = len(bin(int(max_1)))+2\n",
    "print(\"0: \",layer0_bit)\n",
    "print(\"1: \",layer2_bit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'-(0+(reg<<0)-(reg<<2)+(reg<<5))'"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import TCB\n",
    "def D2reg(num,reg_name):\n",
    "    if(num==0):\n",
    "        return None\n",
    "    else:\n",
    "        tcb_str=TCB.Bin2TCB(int(num))\n",
    "        temp=0\n",
    "        if(num>0):\n",
    "            out_s=\"+(0\"\n",
    "        else:\n",
    "            out_s=\"-(0\"\n",
    "        for s in reversed(tcb_str):\n",
    "            if(s==\"+\"):\n",
    "                out_s+=\"+(\"+reg_name+\"<<\"+str(temp)+\")\"\n",
    "            if(s==\"-\"):\n",
    "                out_s+=\"-(\"+reg_name+\"<<\"+str(temp)+\")\"\n",
    "            temp+=1         \n",
    "            \n",
    "        return out_s+\")\"\n",
    "D2reg(-29,\"reg\")        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "wire_cnt 32\n",
      "wire_cnt 32\n"
     ]
    }
   ],
   "source": [
    "\n",
    "img_size=input_img_sz*input_img_sz\n",
    "wire_cnt=layer0_output_size\n",
    "in_buffer_weight_name=\"in_buffer_weight\"\n",
    "weight_to_bias_name=\"weight_bias\"\n",
    "bias_relu_name=\"bias_relu\"\n",
    "in_buffer_weight_parameter=model.state_dict()[\"liner0.weight\"]\n",
    "weight_bias_parameter=model.state_dict()[\"liner0.bias\"]\n",
    "#data_bit_num=20\n",
    "data_bit_num=layer0_bit\n",
    "file_destination = \"verilog_net0\"\n",
    "\n",
    "layer0_verilog_file_name=\"layer0_tcb_\"+str(img_size)+\"x\"+str(layer0_output_size)+\"x10\"\n",
    "f=open(\"./\"+file_destination+\"/\"+layer0_verilog_file_name+\".v\",\"w\")\n",
    "f.write(\"module \"+layer0_verilog_file_name+\"\\n\")\n",
    "f.write(\"(\\n\")\n",
    "\n",
    "f.write(\"\\\n",
    "    input clk,\\n\\\n",
    "    input rst,\\n\\\n",
    "    input [\"+str(img_size)+\"*8-1:0] img,\\n\\\n",
    "    input valid,\\n\\\n",
    "    output  reg ready,\\n\\\n",
    "    output [\"+str(data_bit_num)+\"*\"+str(layer0_output_size)+\"-1:0] layer_out\\n\"\\\n",
    ")\n",
    "f.write(\");\\n\")\n",
    "f.write(\"parameter DATA_WIDTH = \"+str(data_bit_num)+\";\\n\")\n",
    "f.write(\"parameter IMG_SZ   =   \"+str(img_size)+\";\\n\")\n",
    "\n",
    "f.write(\"reg    signed [8-1:0]  in_buffer[0:IMG_SZ-1];\\n\")\n",
    "f.write(\"integer i;\\n\")\n",
    "f.write(\"always@(posedge clk )\\n\\\n",
    "    begin\\n\\\n",
    "        if(rst)\\n\\\n",
    "            begin\\n\\\n",
    "                for(i=0;i<IMG_SZ;i=i+1)\\n\\\n",
    "                    begin\\n\\\n",
    "                        in_buffer[i]<=0;\\n\\\n",
    "                    end\\n\\\n",
    "            end\\n\\\n",
    "        else\\n\\\n",
    "        begin\\n\")\n",
    "\n",
    "for i in range(img_size):\n",
    "    f.write(\"       in_buffer[\"+str(i)+\"]<=img[\"+str(7+i*8)+\":\"+str(0+i*8)+\"];\\n\")           \n",
    "f.write(\"        end\\n   end\\n\")\n",
    "for naming_idx in range(wire_cnt): \n",
    "    f.write(\"wire signed  [DATA_WIDTH-1:0]   \")   \n",
    "    f.write(in_buffer_weight_name+str(naming_idx)+\";\\n\")\n",
    "    f.write(\"assign \"+in_buffer_weight_name+str(naming_idx)+\"=0\")\n",
    "    #insert tcb\n",
    "    for in_buf_idx in range(img_size):\n",
    "        name=\"in_buffer[\" +str(in_buf_idx)+\"]\"\n",
    "        num=int(in_buffer_weight_parameter[naming_idx][in_buf_idx])\n",
    "        try:\n",
    "            f.write(D2reg(num,name))\n",
    "        except:\n",
    "            pass\n",
    "    f.write(\";\\n\")\n",
    "\n",
    "#weight0 to bias0\n",
    "previous_layer_name=in_buffer_weight_name\n",
    "#naming wire\n",
    "print(\"wire_cnt\",wire_cnt)\n",
    "for naming_idx in range(wire_cnt): \n",
    "    f.write(\"wire signed [DATA_WIDTH-1:0]   \")   \n",
    "    f.write(weight_to_bias_name+str(naming_idx)+\";\\n\")\n",
    "for naming_idx in range(wire_cnt):\n",
    "    f.write(\"assign \"+weight_to_bias_name+str(naming_idx)+\"=\")\n",
    "    f.write(previous_layer_name+str(naming_idx))\n",
    "    f.write(\"+(\")\n",
    "    f.write(str(int(weight_bias_parameter[naming_idx])))\n",
    "\n",
    "    f.write(\");\\n\")\n",
    "#bias0 to relu0\n",
    "previous_layer_name=weight_to_bias_name\n",
    "#naming wire\n",
    "print(\"wire_cnt\",wire_cnt)\n",
    "for naming_idx in range(wire_cnt): \n",
    "    f.write(\"wire signed [DATA_WIDTH-1:0]   \")   \n",
    "    f.write(bias_relu_name+str(naming_idx)+\";\\n\")\n",
    "for naming_idx in range(wire_cnt):\n",
    "    f.write(\"assign \"+bias_relu_name+str(naming_idx)+\"=(\")\n",
    "    f.write(previous_layer_name+str(naming_idx))\n",
    "    f.write(\"[DATA_WIDTH-1]==1'b1)   ?   \")\n",
    "    f.write(\"{DATA_WIDTH{1'b0}}:\")\n",
    "    f.write(previous_layer_name+str(naming_idx))\n",
    "    f.write(\";\\n\")\n",
    "\n",
    "\n",
    "f.write(\"assign layer_out={\")\n",
    "for naming_idx in range(wire_cnt-1,-1,-1):\n",
    "    if(naming_idx==0):\n",
    "        f.write(bias_relu_name+str(naming_idx))\n",
    "    else:\n",
    "        f.write(bias_relu_name+str(naming_idx)+\",\")\n",
    "f.write(\"};\\n\")\n",
    "f.write(\"always@(posedge clk)\\n\\\n",
    "    begin\\n\\\n",
    "        if(rst)\\n\\\n",
    "            begin\\n\\\n",
    "                ready<=1'b0;\\n\\\n",
    "            end\\n\\\n",
    "        else\\n\\\n",
    "            begin\\n\\\n",
    "                ready<=valid;\\n\\\n",
    "            end\\n\\\n",
    "    end\\n\")\n",
    "f.write(\"endmodule\")\n",
    "f.close()\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "last_output_sz=layer0_output_size\n",
    "last_layer_data_sz=layer0_bit\n",
    "\n",
    "wire_cnt=10\n",
    "in_buffer_weight_name=\"in_buffer_weight\"\n",
    "weight_to_bias_name=\"weight_bias\"\n",
    "bias_relu_name=\"bias_relu\"\n",
    "in_buffer_weight_parameter=model.state_dict()[\"liner1.weight\"]\n",
    "weight_bias_parameter=model.state_dict()[\"liner1.bias\"]\n",
    "\n",
    "layer2_verilog_file_name=\"layer2_tcb_\"+str(img_size)+\"x\"+str(layer0_output_size)+\"x10\"\n",
    "f=open(\"./\"+file_destination+\"/\"+layer2_verilog_file_name+\".v\",\"w\")\n",
    "f.write(\"module \"+layer2_verilog_file_name+\"\\n\")\n",
    "f.write(\"(\\n\")\n",
    "\n",
    "f.write(\"\\\n",
    "    input clk,\\n\\\n",
    "    input rst,\\n\")\n",
    "f.write(\"   input valid,\\n\")\n",
    "f.write(\"   output  reg ready,\\n\")\n",
    "f.write(\"    input [\"+str(last_layer_data_sz)+\"*\"+str(last_output_sz)+\"-1:0]  layer_in,\\n\")\n",
    "f.write(\"    output [\"+str(layer2_bit)+\"*10-1:0]   layer_out\\n\\\n",
    ");\\n\")\n",
    "f.write(\"parameter DATA_WIDTH   =   \"+str(layer2_bit)+\";\\n\")\n",
    "f.write(\"reg [DATA_WIDTH-1:0]    layer_in_buffer    [0:\"+str(last_output_sz)+\"-1];\\n\")\n",
    "f.write(\"integer i;\\n\")\n",
    "f.write(\"always@(posedge clk )\\n\\\n",
    "    begin\\n\\\n",
    "        if(rst)\\n\\\n",
    "            begin\\n\")\n",
    "f.write(\"                for(i=0;i<\"+str(last_output_sz)+\";i=i+1)\\n\\\n",
    "                    begin\\n\\\n",
    "                        layer_in_buffer[i]<=0;\\n\\\n",
    "                    end\\n\\\n",
    "            end\\n\\\n",
    "        else\\n\\\n",
    "        begin\\n\")\n",
    "for i in range(last_output_sz):\n",
    "    f.write(\"       layer_in_buffer[\"+str(i)+\"]<=layer_in[\"+str(last_layer_data_sz-1+i*last_layer_data_sz)+\":\"+str(0+i*last_layer_data_sz)+\"];\\n\")           \n",
    "f.write(\"        end\\n   end\\n\")\n",
    "\n",
    "\n",
    "f.write(\"\\n\")\n",
    "previous_layer_name=\"layer_in_buffer\"\n",
    "#naming wire\n",
    "for naming_idx in range(wire_cnt): \n",
    "    f.write(\"wire [DATA_WIDTH-1:0]   \")   \n",
    "    f.write(in_buffer_weight_name+str(naming_idx)+\";\\n\")\n",
    "    f.write(\"assign \"+in_buffer_weight_name+str(naming_idx)+\"=0\")\n",
    "    for previoud_layer_idx in range(last_output_sz):\n",
    "        name=previous_layer_name+\"[\"+str(previoud_layer_idx)+\"]\"\n",
    "        num=int(in_buffer_weight_parameter[naming_idx][previoud_layer_idx])\n",
    "        try:\n",
    "            f.write(D2reg(num,name))\n",
    "        except:\n",
    "            pass\n",
    "    f.write(\";\\n\")\n",
    "# weight4 to bias4 \n",
    "\n",
    "previous_layer_name=in_buffer_weight_name\n",
    "#naming wire\n",
    "for naming_idx in range(wire_cnt): \n",
    "    f.write(\"wire [DATA_WIDTH-1:0]   \")   \n",
    "    f.write(weight_to_bias_name+str(naming_idx)+\";\\n\")\n",
    "    f.write(\"assign \"+weight_to_bias_name+str(naming_idx)+\"=\")\n",
    "    f.write(previous_layer_name+str(naming_idx))\n",
    "    f.write(\"+(\")\n",
    "    f.write(str(int(weight_bias_parameter[naming_idx])))\n",
    "    f.write(\");\\n\")\n",
    "f.write(\"assign layer_out={\\n\")\n",
    "for naming_idx in range(wire_cnt-1,-1,-1): \n",
    "    if(naming_idx==0):\n",
    "        f.write(\"            \"+weight_to_bias_name+str(naming_idx))\n",
    "    else:\n",
    "        f.write(\"            \"+weight_to_bias_name+str(naming_idx)+\",\\n\")\n",
    "f.write(\"};\\n\")\n",
    "f.write(\"always@(posedge clk)\\n\\\n",
    "    begin\\n\\\n",
    "        if(rst)\\n\\\n",
    "            begin\\n\\\n",
    "                ready<=1'b0;\\n\\\n",
    "            end\\n\\\n",
    "        else\\n\\\n",
    "            begin\\n\\\n",
    "                ready<=valid;\\n\\\n",
    "            end\\n\\\n",
    "    end\\n\")\n",
    "f.write(\"endmodule\\n\")\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_sz=layer2_bit\n",
    "f=open(\"./\"+file_destination+\"/comparator_30bit.v\",\"w\")\n",
    "f.write(\"module comparator\\n\")\n",
    "f.write(\"(\\n\")\n",
    "f.write(\"input [\"+str(data_sz)+\"*10-1:0] layer_out,\\n\")\n",
    "f.write(\"input rst,\\n\")\n",
    "f.write(\"input clk,\\n\")\n",
    "f.write(\"input valid,\\n\")\n",
    "f.write(\"output  reg ready,\\n\")\n",
    "f.write(\"output reg [7:0] predict\\n\")\n",
    "f.write(\");\\n\")\n",
    "f.write(\"parameter DATA_WIDTH=\"+str(data_sz)+\";\\n\")\n",
    "f.write(\"reg [DATA_WIDTH-1: 0] result [0:9];\\n\")\n",
    "f.write(\"wire [4+DATA_WIDTH-1:0] com_re01,com_re23,com_re45,com_re67,com_re89;\\n\")\n",
    "f.write(\"reg ready_temp;\\n\")\n",
    "f.write(\"always@(posedge clk)\\n\\\n",
    "    begin\\n\\\n",
    "        if(rst)\\n\\\n",
    "            begin\\n\\\n",
    "                ready<=1'b0;\\n\\\n",
    "                ready_temp<=1'b0;\\n\\\n",
    "            end\\n\\\n",
    "        else\\n\\\n",
    "            begin\\n\\\n",
    "                ready_temp<=valid;\\n\\\n",
    "                ready<=ready_temp;\\n\\\n",
    "            end\\n\\\n",
    "    end\\n\")\n",
    "\n",
    "f.write(\" \\n\\\n",
    "assign com_re01=(result[0][DATA_WIDTH-1]^result[1][DATA_WIDTH-1]) ? \\n\\\n",
    "                                                        ((result[0][DATA_WIDTH-1]==1'b0)   ?   {4'd0,result[0]}:{4'd1,result[1]}):\\n\\\n",
    "                                                        ((result[0]>result[1]) ? {4'd0,result[0]}:{4'd1,result[1]});\\n\\\n",
    "assign com_re23=(result[2][DATA_WIDTH-1]^result[3][DATA_WIDTH-1]) ? \\n\\\n",
    "                                                        ((result[2][DATA_WIDTH-1]==1'b0)   ?   {4'd2,result[2]}:{4'd3,result[3]}):\\n\\\n",
    "                                                        ((result[2]>result[3]) ? {4'd2,result[2]}:{4'd3,result[3]});\\n\\\n",
    "assign com_re45=(result[4][DATA_WIDTH-1]^result[5][DATA_WIDTH-1]) ? \\n\\\n",
    "                                                        ((result[4][DATA_WIDTH-1]==1'b0)   ?   {4'd4,result[4]}:{4'd5,result[5]}):\\n\\\n",
    "                                                        ((result[4]>result[5]) ? {4'd4,result[4]}:{4'd5,result[5]});\\n\")  \n",
    "f.write(\"\\n\\\n",
    "assign com_re67=(result[6][DATA_WIDTH-1]^result[7][DATA_WIDTH-1]) ? \\n\\\n",
    "                                                        ((result[6][DATA_WIDTH-1]==1'b0)   ?   {4'd6,result[6]}:{4'd7,result[7]}):\\n\\\n",
    "                                                        ((result[6]>result[7]) ? {4'd6,result[6]}:{4'd7,result[7]});\\n\\\n",
    "assign com_re89=(result[8][DATA_WIDTH-1]^result[9][DATA_WIDTH-1]) ? \\n\\\n",
    "                                                        ((result[8][DATA_WIDTH-1]==1'b0)   ?   {4'd8,result[8]}:{4'd9,result[9]}):\\n\\\n",
    "                                                        ((result[8]>result[9]) ? {4'd8,result[8]}:{4'd9,result[9]});\\n\\\n",
    "wire [4+DATA_WIDTH-1:0] com_re01_23,com_re45_67,com_re0123_4567,com_re01234567_89;\\n\\\n",
    "assign com_re01_23=(com_re01[DATA_WIDTH-1]^com_re23[DATA_WIDTH-1])   ?\\n\\\n",
    "                                                        ((com_re01[DATA_WIDTH-1]==1'b0)  ?   com_re01:com_re23):\\n\\\n",
    "                                                        ((com_re01[DATA_WIDTH-1:0]>com_re23[DATA_WIDTH-1:0]) ?   com_re01:com_re23);\\n\\\n",
    "assign com_re45_67=(com_re45[DATA_WIDTH-1]^com_re67[DATA_WIDTH-1])   ?\\n\\\n",
    "                                                        ((com_re45[DATA_WIDTH-1]==1'b0)  ?   com_re45:com_re67):\\n\\\n",
    "                                                        ((com_re45[DATA_WIDTH-1:0]>com_re67[DATA_WIDTH-1:0]) ?   com_re45:com_re67);\\n\\\n",
    "assign com_re0123_4567=(com_re01_23[DATA_WIDTH-1]^com_re45_67[DATA_WIDTH-1])   ?\\n\\\n",
    "                                                        ((com_re01_23[DATA_WIDTH-1]==1'b0)  ?   com_re01_23:com_re45_67):\\n\\\n",
    "                                                        ((com_re01_23[DATA_WIDTH-1:0]>com_re45_67[DATA_WIDTH-1:0]) ?   com_re01_23:com_re45_67);\\n\\\n",
    "assign com_re01234567_89=(com_re0123_4567[DATA_WIDTH-1]^com_re89[DATA_WIDTH-1])   ?\\n\\\n",
    "                                                        ((com_re0123_4567[DATA_WIDTH-1]==1'b0)  ?   com_re0123_4567:com_re89):\\n\\\n",
    "                                                        ((com_re0123_4567[DATA_WIDTH-1:0]>com_re89[DATA_WIDTH-1:0]) ?   com_re0123_4567:com_re89);\\n\")\n",
    "f.write(\"integer i;\\n\")\n",
    "f.write(\"always@(posedge clk )\\n\")\n",
    "f.write(\"begin\\n\\\n",
    "    if(rst)\\n\\\n",
    "            begin\\n\\\n",
    "                for(i=0;i<10;i=i+1)\\n\\\n",
    "                    begin\\n\\\n",
    "                        result[i]<={\"+str(data_sz)+\"'b0};\\n\\\n",
    "                    end\\n\\\n",
    "                predict<=0;\\n\\\n",
    "            end\\n\\\n",
    "    else\\n\\\n",
    "    begin \\n\")\n",
    "f.write(\"\\\n",
    "        predict <={4'b0,com_re01234567_89[4+DATA_WIDTH-1:4+DATA_WIDTH-1-3]};\\n\")\n",
    "for i in range(10):\n",
    "    f.write(\"       result[\"+str(i)+\"]<=layer_out[\"+str(data_sz-1+data_sz*i)+\":\"+str(data_sz*i)+\"];\\n\")\n",
    "f.write(\"\\\n",
    "    end\\n\\\n",
    "end\\n\")\n",
    "\n",
    "\n",
    "\n",
    "f.write(\"endmodule\\n\")\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "layer0_port=layer0_output_size\n",
    "layer2_port=10\n",
    "tb_name=\"top_tcb_\"+str(input_img_sz*input_img_sz)+\"_\"+str(layer0_output_size)+\"_10\"\n",
    "f=open(\"./\"+file_destination+\"/\"+tb_name+\".v\",\"w\")\n",
    "f.write(\"module \"+tb_name+\"(\\n\")\n",
    "f.write(\"input clk,\\n\\\n",
    "input rst,\\n\\\n",
    "input [\"+str(input_img_sz*input_img_sz)+\"*8-1:0] img_source,\\n\\\n",
    "output [31:0] number,\\n\")\n",
    "f.write(\"input valid_top,\\n\")\n",
    "f.write(\"output  ready_top\\n\")\n",
    "f.write(\");\\n\")\n",
    "f.write(\"wire layer0_ready,layer2_ready\\n;\")\n",
    "f.write(\"wire   [\"+str(layer0_bit)+\"*\"+str(layer0_port)+\"-1:0] layer0_out;\\n\")\n",
    "f.write(\"wire   [\"+str(layer2_bit)+\"*\"+str(layer2_port)+\"-1:0] layer2_out;\\n\")\n",
    "f.write(layer0_verilog_file_name+\" DUT_layer0   (.clk(clk),.rst(rst),.img(img_source),.layer_out(layer0_out),.ready(layer0_ready),.valid(valid_top));\\n\")\n",
    "f.write(layer2_verilog_file_name+\" DUT_layer2   (.clk(clk),.rst(rst),.layer_in(layer0_out),.layer_out(layer2_out),.ready(layer2_ready),.valid(layer0_ready));\\n\")\n",
    "f.write(\"comparator DUT_comparator (.clk(clk),.rst(rst),.layer_out(layer2_out),.predict(number),.ready(ready_top),.valid(layer2_ready));\\n\")\n",
    "\n",
    "f.write(\"endmodule\\n\")\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "f=open(\"./\"+file_destination+\"/tb.v\",\"w\")\n",
    "f.write(\"`timescale 1ns/1ps\\n\")\n",
    "f.write(\"module tb;\\n\")\n",
    "\n",
    "f.write(\"reg clk,rst,valid;\\n\")\n",
    "f.write(\"reg [\"+str(input_img_sz*input_img_sz*8)+\"-1:0] img;\\n\")\n",
    "f.write(\"wire [7:0] number;\\n\")\n",
    "f.write(tb_name+\" top_DUT(\\n\\\n",
    "    .clk(clk),\\n\\\n",
    "    .rst(rst),\\n\\\n",
    "    .img_source(img),\\n\\\n",
    "    .valid_top(valid),\\n\\\n",
    "    .ready_top(ready_top),\\n\\\n",
    "    .number(number)\\n\\\n",
    ");\\n\")\n",
    "f.write(\"always #5 clk=~clk;\\n\")\n",
    "f.write(\"initial \\nbegin\\n\")\n",
    "f.write(\"$monitor(\\\"number is %d\\\",number);\\n\")\n",
    "f.write(\"clk=0;rst=1'b1;valid=1'b1;\\n\")\n",
    "f.write(\"img=\"+str(input_img_sz*input_img_sz)+\"'b0;\\n\")\n",
    "f.write(\"#10 rst=1'b0;\\n\")\n",
    "for i in range(10):\n",
    "    f.write(\"@(negedge clk) #(10/4) img=\"+str(input_img_sz*input_img_sz*8)+\"'b\")\n",
    "    img,idx=test_data[i]\n",
    "    img=img.reshape(-1)\n",
    "    img=np.asarray(img)\n",
    "    img=int_conver(img)\n",
    "    for ele in reversed(img):\n",
    "        eight_bit=\"{:08b}\".format(int(ele))\n",
    "        f.write(eight_bit)\n",
    "        #print(ele)\n",
    "    f.write(\";\\n\")\n",
    "\n",
    "\n",
    "\n",
    "f.write(\"#100 $finish;\\n\")\n",
    "\n",
    "\n",
    "f.write(\"end\\n\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "f.write(\"endmodule\\n\")\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "f=open(\"./\"+file_destination+\"/label.txt\",\"w\")\n",
    "for i in range(10):\n",
    "    img,idx=test_data[i]\n",
    "    f.write(str(idx))\n",
    "    f.write(\"\\n\")\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
