{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torchvision\n",
    "from torchvision import datasets\n",
    "from torchvision.transforms import ToTensor\n",
    "test_data = datasets.MNIST(\n",
    "    root=\"data\",\n",
    "    train=False,\n",
    "    download=True,\n",
    "    transform=ToTensor(),\n",
    ")\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets\n",
    "from torchvision.transforms import ToTensor\n",
    "import numpy as np\n",
    "import torch.onnx\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_img_sz=11\n",
    "layer0_output_size =16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "# Download training data from open datasets.\n",
    "training_data = datasets.MNIST(\n",
    "    root=\"../data\",    \n",
    "    train=True,\n",
    "    download=True,\n",
    "    transform=torchvision.transforms.Compose(\n",
    "        [torchvision.transforms.Resize(input_img_sz), torchvision.transforms.ToTensor()]\n",
    "    ),\n",
    ")\n",
    "\n",
    "# Download test data from open datasets.\n",
    "test_data = datasets.MNIST(\n",
    "    root=\"../data\",\n",
    "    train=False,\n",
    "    download=True,\n",
    "    transform=torchvision.transforms.Compose(\n",
    "        [torchvision.transforms.Resize(input_img_sz), torchvision.transforms.ToTensor()]\n",
    "    ),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda device\n",
      "NeuralNetwork(\n",
      "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
      "  (liner0): Linear(in_features=121, out_features=16, bias=True)\n",
      "  (relu): ReLU(inplace=True)\n",
      "  (liner1): Linear(in_features=16, out_features=10, bias=True)\n",
      ")\n",
      "Shape of X [N, C, H, W]: torch.Size([64, 1, 11, 11])\n",
      "Shape of y: torch.Size([64]) torch.int64\n"
     ]
    }
   ],
   "source": [
    "# Get cpu or gpu device for training.\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(f\"Using {device} device\")\n",
    "\n",
    "# Define model\n",
    "class NeuralNetwork(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(NeuralNetwork, self).__init__()\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.liner0 = nn.Linear(input_img_sz*input_img_sz, layer0_output_size)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.liner1 =nn.Linear(layer0_output_size, 10)\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.flatten(x)\n",
    "        x = self.liner0(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.liner1(x)\n",
    "        return x\n",
    "\n",
    "model = NeuralNetwork().to(device)\n",
    "print(model)\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "\n",
    "# optimizer = torch.optim.SGD(model.parameters(), lr=1e-3)\n",
    "optimizer = torch.optim.Adam(model.parameters(),lr=1e-3)\n",
    "def train(dataloader, model, loss_fn, optimizer):\n",
    "    size = len(dataloader.dataset)\n",
    "    model.train()\n",
    "    for batch, (X, y) in enumerate(dataloader):\n",
    "        X, y = X.to(device), y.to(device)\n",
    "\n",
    "        # Compute prediction error\n",
    "        pred = model(X)\n",
    "        loss = loss_fn(pred, y)\n",
    "\n",
    "        # Backpropagation\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        if batch % 100 == 0:\n",
    "            loss, current = loss.item(), batch * len(X)\n",
    "            print(f\"loss: {loss:>7f}  [{current:>5d}/{size:>5d}]\")\n",
    "\n",
    "def test(dataloader, model, loss_fn):\n",
    "    size = len(dataloader.dataset)\n",
    "    num_batches = len(dataloader)\n",
    "    model.eval()\n",
    "    test_loss, correct = 0, 0\n",
    "    with torch.no_grad():\n",
    "        for X, y in dataloader:\n",
    "            X, y = X.to(device), y.to(device)\n",
    "            pred = model(X)\n",
    "            test_loss += loss_fn(pred, y).item()\n",
    "            correct += (pred.argmax(1) == y).type(torch.float).sum().item()\n",
    "    test_loss /= num_batches\n",
    "    correct /= size\n",
    "    print(f\"Test Error: \\n Accuracy: {(100*correct):>0.1f}%, Avg loss: {test_loss:>8f} \\n\")\n",
    "batch_size = 64\n",
    "\n",
    "# Create data loaders.\n",
    "train_dataloader = DataLoader(training_data, batch_size=batch_size)\n",
    "test_dataloader = DataLoader(test_data, batch_size=batch_size)\n",
    "\n",
    "for X, y in test_dataloader:\n",
    "    print(f\"Shape of X [N, C, H, W]: {X.shape}\")\n",
    "    print(f\"Shape of y: {y.shape} {y.dtype}\")\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1\n",
      "-------------------------------\n",
      "loss: 2.317972  [    0/60000]\n",
      "loss: 1.960031  [ 6400/60000]\n",
      "loss: 1.433156  [12800/60000]\n",
      "loss: 0.946025  [19200/60000]\n",
      "loss: 0.801908  [25600/60000]\n",
      "loss: 0.671353  [32000/60000]\n",
      "loss: 0.491297  [38400/60000]\n",
      "loss: 0.675953  [44800/60000]\n",
      "loss: 0.540725  [51200/60000]\n",
      "loss: 0.552438  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 88.3%, Avg loss: 0.448110 \n",
      "\n",
      "Epoch 2\n",
      "-------------------------------\n",
      "loss: 0.466229  [    0/60000]\n",
      "loss: 0.413196  [ 6400/60000]\n",
      "loss: 0.375911  [12800/60000]\n",
      "loss: 0.453868  [19200/60000]\n",
      "loss: 0.354784  [25600/60000]\n",
      "loss: 0.417361  [32000/60000]\n",
      "loss: 0.267484  [38400/60000]\n",
      "loss: 0.500445  [44800/60000]\n",
      "loss: 0.391992  [51200/60000]\n",
      "loss: 0.465112  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 90.2%, Avg loss: 0.344660 \n",
      "\n",
      "Epoch 3\n",
      "-------------------------------\n",
      "loss: 0.324755  [    0/60000]\n",
      "loss: 0.346263  [ 6400/60000]\n",
      "loss: 0.290165  [12800/60000]\n",
      "loss: 0.391371  [19200/60000]\n",
      "loss: 0.280659  [25600/60000]\n",
      "loss: 0.371350  [32000/60000]\n",
      "loss: 0.220757  [38400/60000]\n",
      "loss: 0.454803  [44800/60000]\n",
      "loss: 0.358562  [51200/60000]\n",
      "loss: 0.436259  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 91.0%, Avg loss: 0.312673 \n",
      "\n",
      "Epoch 4\n",
      "-------------------------------\n",
      "loss: 0.270741  [    0/60000]\n",
      "loss: 0.328631  [ 6400/60000]\n",
      "loss: 0.250589  [12800/60000]\n",
      "loss: 0.363631  [19200/60000]\n",
      "loss: 0.252269  [25600/60000]\n",
      "loss: 0.345520  [32000/60000]\n",
      "loss: 0.201277  [38400/60000]\n",
      "loss: 0.430968  [44800/60000]\n",
      "loss: 0.340709  [51200/60000]\n",
      "loss: 0.419903  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 91.3%, Avg loss: 0.295692 \n",
      "\n",
      "Epoch 5\n",
      "-------------------------------\n",
      "loss: 0.237819  [    0/60000]\n",
      "loss: 0.318709  [ 6400/60000]\n",
      "loss: 0.225550  [12800/60000]\n",
      "loss: 0.349649  [19200/60000]\n",
      "loss: 0.238212  [25600/60000]\n",
      "loss: 0.326290  [32000/60000]\n",
      "loss: 0.192833  [38400/60000]\n",
      "loss: 0.415984  [44800/60000]\n",
      "loss: 0.325072  [51200/60000]\n",
      "loss: 0.410943  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 91.6%, Avg loss: 0.284445 \n",
      "\n",
      "Epoch 6\n",
      "-------------------------------\n",
      "loss: 0.214298  [    0/60000]\n",
      "loss: 0.312856  [ 6400/60000]\n",
      "loss: 0.206526  [12800/60000]\n",
      "loss: 0.337232  [19200/60000]\n",
      "loss: 0.229331  [25600/60000]\n",
      "loss: 0.311063  [32000/60000]\n",
      "loss: 0.187200  [38400/60000]\n",
      "loss: 0.402503  [44800/60000]\n",
      "loss: 0.305747  [51200/60000]\n",
      "loss: 0.403792  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 91.8%, Avg loss: 0.275909 \n",
      "\n",
      "Epoch 7\n",
      "-------------------------------\n",
      "loss: 0.198140  [    0/60000]\n",
      "loss: 0.307902  [ 6400/60000]\n",
      "loss: 0.194393  [12800/60000]\n",
      "loss: 0.326671  [19200/60000]\n",
      "loss: 0.223418  [25600/60000]\n",
      "loss: 0.299581  [32000/60000]\n",
      "loss: 0.180743  [38400/60000]\n",
      "loss: 0.388754  [44800/60000]\n",
      "loss: 0.287526  [51200/60000]\n",
      "loss: 0.398872  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 91.9%, Avg loss: 0.268497 \n",
      "\n",
      "Epoch 8\n",
      "-------------------------------\n",
      "loss: 0.184334  [    0/60000]\n",
      "loss: 0.302544  [ 6400/60000]\n",
      "loss: 0.184503  [12800/60000]\n",
      "loss: 0.319430  [19200/60000]\n",
      "loss: 0.218305  [25600/60000]\n",
      "loss: 0.288918  [32000/60000]\n",
      "loss: 0.174807  [38400/60000]\n",
      "loss: 0.377787  [44800/60000]\n",
      "loss: 0.271711  [51200/60000]\n",
      "loss: 0.393078  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 92.1%, Avg loss: 0.262206 \n",
      "\n",
      "Epoch 9\n",
      "-------------------------------\n",
      "loss: 0.174851  [    0/60000]\n",
      "loss: 0.297227  [ 6400/60000]\n",
      "loss: 0.176029  [12800/60000]\n",
      "loss: 0.312126  [19200/60000]\n",
      "loss: 0.215447  [25600/60000]\n",
      "loss: 0.281547  [32000/60000]\n",
      "loss: 0.170399  [38400/60000]\n",
      "loss: 0.370387  [44800/60000]\n",
      "loss: 0.256299  [51200/60000]\n",
      "loss: 0.385757  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 92.2%, Avg loss: 0.256216 \n",
      "\n",
      "Epoch 10\n",
      "-------------------------------\n",
      "loss: 0.166934  [    0/60000]\n",
      "loss: 0.290633  [ 6400/60000]\n",
      "loss: 0.169418  [12800/60000]\n",
      "loss: 0.306656  [19200/60000]\n",
      "loss: 0.210670  [25600/60000]\n",
      "loss: 0.273669  [32000/60000]\n",
      "loss: 0.164231  [38400/60000]\n",
      "loss: 0.359804  [44800/60000]\n",
      "loss: 0.242506  [51200/60000]\n",
      "loss: 0.377518  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 92.5%, Avg loss: 0.249779 \n",
      "\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "file_name =\"MNIST\"+str(input_img_sz)+\"x\"+str(input_img_sz)+\"_\"+str(layer0_output_size)+\"_10.pth\"\n",
    "if not (os.path.isfile(file_name)):\n",
    "    epochs = 10\n",
    "    for t in range(epochs):\n",
    "        print(f\"Epoch {t+1}\\n-------------------------------\")\n",
    "        train(train_dataloader, model, loss_fn, optimizer)\n",
    "        test(test_dataloader, model, loss_fn)\n",
    "        torch.save(model, file_name)\n",
    "    print(\"Done!\")\n",
    "else:\n",
    "    #model.load_state_dict(torch.load(\"model.pth\"))\n",
    "    model = torch.load( file_name)\n",
    "    print(\"Model loaded\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Error: \n",
      " Accuracy: 92.4%, Avg loss: 2421.509083 \n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "OrderedDict([('liner0.weight',\n",
       "              tensor([[   4.,  -28.,  -83.,  ...,   85.,   58.,   22.],\n",
       "                      [   2.,   -5.,    7.,  ...,  -10.,   -9.,    2.],\n",
       "                      [   3.,  -12.,  -62.,  ...,   49.,   31.,   51.],\n",
       "                      ...,\n",
       "                      [ -13.,    5.,  -28.,  ...,  -31.,  -56.,  -52.],\n",
       "                      [  21.,   14.,   51.,  ...,   11.,  -28.,   28.],\n",
       "                      [ -28.,  -42.,  -58.,  ..., -128.,  -43.,   19.]], device='cuda:0')),\n",
       "             ('liner0.bias',\n",
       "              tensor([ 86.,   1.,  28.,   1.,  65.,  59., -10.,  45.,  22.,  50., -62.,  -9.,\n",
       "                       20.,   5., -23.,  29.], device='cuda:0')),\n",
       "             ('liner1.weight',\n",
       "              tensor([[ 123.,    0.,  -71.,  -41., -193.,   -6.,   -2., -103.,   76., -106.,\n",
       "                         94., -113., -121.,  -53.,   67.,   59.],\n",
       "                      [-158.,  -15.,   72.,   86.,   98.,  161.,  -75.,  -60.,  -64., -100.,\n",
       "                        -68., -179.,  130.,  110., -132., -104.],\n",
       "                      [   3.,  -10.,   75.,   26.,  -77.,  -65., -121.,  -32., -132.,  -20.,\n",
       "                        -32.,    0.,   92., -111.,   76.,   57.],\n",
       "                      [ -92.,   20.,   56.,  -65., -121.,   71.,  104.,  -47., -146.,   88.,\n",
       "                         85., -112.,   36.,    0.,  -44.,  -37.],\n",
       "                      [   0.,   -7.,  -85.,  -93.,    6., -198.,   59.,   57.,   -2.,  -25.,\n",
       "                       -207.,   85.,  -70.,  118., -168.,  100.],\n",
       "                      [ -15.,   24.,   29., -189.,   80.,   32.,  -37.,   64.,   99.,   96.,\n",
       "                         39., -107.,  -39., -183., -136.,   42.],\n",
       "                      [ -70.,    4., -108., -166., -172.,  129.,  -92.,  125.,  111., -185.,\n",
       "                        -30.,   88.,   77.,   24.,    6.,    9.],\n",
       "                      [  71.,  -14., -135.,   81.,   79.,   60.,   75., -171.,  -99.,  113.,\n",
       "                       -153.,    2.,   76.,  -39.,   54.,  -89.],\n",
       "                      [-138.,   19.,   35.,   63.,   45., -121.,   51.,  -57.,   73., -122.,\n",
       "                         66.,   47.,  -65.,  -24.,   -8.,    0.],\n",
       "                      [  77.,   20.,  -20.,   88.,   38., -160.,   66.,  108.,  -76.,  -31.,\n",
       "                        -33.,   12., -255.,   54.,    8., -123.]], device='cuda:0')),\n",
       "             ('liner1.bias',\n",
       "              tensor([  1.,  51.,  44.,   0.,   2.,  85., -32.,  18., -65.,   1.],\n",
       "                     device='cuda:0'))])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = torch.load( file_name)\n",
    "for ele in model.state_dict():#turn to numpy\n",
    "    model.state_dict()[ele]=model.state_dict()[ele].cpu().numpy()\n",
    "#turn float to int\n",
    "for layers in model.state_dict():\n",
    "    try:\n",
    "        model.state_dict()[layers].shape[1]## if parameter is 2D\n",
    "        row,col=model.state_dict()[layers].shape\n",
    "        for row in range(model.state_dict()[layers].shape[0]):\n",
    "            for col in range(model.state_dict()[layers].shape[1]):\n",
    "                num=int((model.state_dict()[layers][row][col]+1)/2*255-127)\n",
    "                model.state_dict()[layers][row][col]= num\n",
    "    except:\n",
    "        #model[layers].shape #1D\n",
    "        # print(model[layers].shape[0])\n",
    "        for i in range(model.state_dict()[layers].shape[0]):\n",
    "            num=int((model.state_dict()[layers][i]+1)/2*255-127)\n",
    "            model.state_dict()[layers][i]=num\n",
    "test(test_dataloader, model, loss_fn)\n",
    "model.state_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Error: \n",
      " Accuracy: 77.9%, Avg loss: 8011.202906 \n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "OrderedDict([('liner0.weight',\n",
       "              tensor([[   0.,    0.,  -59.,  ...,   59.,   59.,    0.],\n",
       "                      [   0.,    0.,    0.,  ...,    0.,    0.,    0.],\n",
       "                      [   0.,    0.,  -59.,  ...,   59.,   59.,   59.],\n",
       "                      ...,\n",
       "                      [   0.,    0.,    0.,  ...,  -59.,  -59.,  -59.],\n",
       "                      [   0.,    0.,   59.,  ...,    0.,    0.,    0.],\n",
       "                      [   0.,  -59.,  -59.,  ..., -118.,  -59.,    0.]], device='cuda:0')),\n",
       "             ('liner0.bias',\n",
       "              tensor([ 59.,   0.,   0.,   0.,  59.,  59.,   0.,  59.,   0.,  59., -59.,   0.,\n",
       "                        0.,   0.,   0.,   0.], device='cuda:0')),\n",
       "             ('liner1.weight',\n",
       "              tensor([[ 118.,    0.,  -59.,  -59., -177.,    0.,    0., -118.,   59., -118.,\n",
       "                        118., -118., -118.,  -59.,   59.,   59.],\n",
       "                      [-177.,    0.,   59.,   59.,  118.,  177.,  -59.,  -59.,  -59., -118.,\n",
       "                        -59., -177.,  118.,  118., -118., -118.],\n",
       "                      [   0.,    0.,   59.,    0.,  -59.,  -59., -118.,  -59., -118.,    0.,\n",
       "                        -59.,    0.,  118., -118.,   59.,   59.],\n",
       "                      [-118.,    0.,   59.,  -59., -118.,   59.,  118.,  -59., -118.,   59.,\n",
       "                         59., -118.,   59.,    0.,  -59.,  -59.],\n",
       "                      [   0.,    0.,  -59., -118.,    0., -177.,   59.,   59.,    0.,    0.,\n",
       "                       -236.,   59.,  -59.,  118., -177.,  118.],\n",
       "                      [   0.,    0.,    0., -177.,   59.,   59.,  -59.,   59.,  118.,  118.,\n",
       "                         59., -118.,  -59., -177., -118.,   59.],\n",
       "                      [ -59.,    0., -118., -177., -177.,  118., -118.,  118.,  118., -177.,\n",
       "                        -59.,   59.,   59.,    0.,    0.,    0.],\n",
       "                      [  59.,    0., -118.,   59.,   59.,   59.,   59., -177., -118.,  118.,\n",
       "                       -177.,    0.,   59.,  -59.,   59., -118.],\n",
       "                      [-118.,    0.,   59.,   59.,   59., -118.,   59.,  -59.,   59., -118.,\n",
       "                         59.,   59.,  -59.,    0.,    0.,    0.],\n",
       "                      [  59.,    0.,    0.,   59.,   59., -177.,   59.,  118.,  -59.,  -59.,\n",
       "                        -59.,    0., -236.,   59.,    0., -118.]], device='cuda:0')),\n",
       "             ('liner1.bias',\n",
       "              tensor([  0.,  59.,  59.,   0.,   0.,  59., -59.,   0., -59.,   0.],\n",
       "                     device='cuda:0'))])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = torch.load( file_name)\n",
    "A=59\n",
    "for ele in model.state_dict():#turn to numpy\n",
    "    model.state_dict()[ele]=model.state_dict()[ele].cpu().numpy()\n",
    "#turn float to int\n",
    "for layers in model.state_dict():\n",
    "    try:\n",
    "        model.state_dict()[layers].shape[1]## if parameter is 2D\n",
    "        row,col=model.state_dict()[layers].shape\n",
    "        for row in range(model.state_dict()[layers].shape[0]):\n",
    "            for col in range(model.state_dict()[layers].shape[1]):\n",
    "                num=int((model.state_dict()[layers][row][col]+1)/2*255-127)\n",
    "                model.state_dict()[layers][row][col]= round(num/A)*A\n",
    "    except:\n",
    "        #model[layers].shape #1D\n",
    "        # print(model[layers].shape[0])\n",
    "        for i in range(model.state_dict()[layers].shape[0]):\n",
    "            num=int((model.state_dict()[layers][i]+1)/2*255-127)\n",
    "            model.state_dict()[layers][i]=round(num/A)*A\n",
    "test(test_dataloader, model, loss_fn)\n",
    "model.state_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#turn img from float to int\n",
    "def int_conver(np_a):\n",
    "    for idx,ele in enumerate(np_a):\n",
    "        np_a[idx]=int((ele+1)/2*255-127)\n",
    "\n",
    "    return np_a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ -2882268. -29769453.  -5778401.   3393975. -16882850.  -3818598.\n",
      " -33368925.  10892049.  -4159854.    205379.]\n",
      "1\n",
      "0:  19\n",
      "1:  28\n"
     ]
    }
   ],
   "source": [
    "hit=0\n",
    "lrsb0_len=layer0_output_size\n",
    "lrsb2_len=10\n",
    "max_0,min_0=0,0\n",
    "max_1,min_1=0,0\n",
    "\n",
    "lrsw0=model.state_dict()[\"liner0.weight\"].reshape(-1).cpu().numpy()\n",
    "lrsb0=model.state_dict()[\"liner0.bias\"].reshape(-1).cpu().numpy()\n",
    "lrsw2=model.state_dict()[\"liner1.weight\"].reshape(-1).cpu().numpy()\n",
    "lrsb2=model.state_dict()[\"liner1.bias\"].reshape(-1).cpu().numpy()\n",
    "for r in range(1):    \n",
    "    img,label=test_data[r]\n",
    "    img=img.reshape(-1)\n",
    "    img=int_conver(img)\n",
    "\n",
    "    out1=np.zeros(lrsb0_len)\n",
    "    out2=np.zeros(lrsb2_len)\n",
    "    \n",
    "    for i in range(lrsb0_len):\n",
    "        for j in range(input_img_sz*input_img_sz):\n",
    "            out1[i]+=lrsw0[i*input_img_sz*input_img_sz+j]*img[j]\n",
    "        out1[i]+=lrsb0[i]\n",
    "    # print(out1)\n",
    "\n",
    "    for i in range(lrsb0_len):\n",
    "        if(out1[i]>max_0):\n",
    "            max_0=out1[i]\n",
    "        if(out1[i]<min_0):\n",
    "            min_0=out1[i]\n",
    "        if(out1[i]<0):\n",
    "            out1[i]=0\n",
    "\n",
    "    for i in range(lrsb2_len):\n",
    "        for j in range(lrsb0_len):\n",
    "            out2[i]+=lrsw2[i*lrsb0_len+j]*out1[j]\n",
    "        out2[i]+=lrsb2[i]\n",
    "\n",
    "    for i in range(10):\n",
    "        if(out2[i]>max_1):\n",
    "            max_1=out2[i]\n",
    "        if(out2[i]<min_1):\n",
    "            min_1=out2[i]\n",
    "    print(out2)\n",
    "    if(out2.argmax()==label):\n",
    "        hit+=1\n",
    "\n",
    "    # print(\"now:\",r+1,\"hit:\",hit)\n",
    "print(hit)\n",
    "layer0_bit = len(bin(int(max_0)))\n",
    "layer2_bit = len(bin(int(max_1)))+2\n",
    "print(\"0: \",layer0_bit)\n",
    "print(\"1: \",layer2_bit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'-(0+(reg<<0)-(reg<<2)+(reg<<5))'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import TCB\n",
    "def D2reg(num,reg_name):\n",
    "    if(num==0):\n",
    "        return None\n",
    "    else:\n",
    "        tcb_str=TCB.Bin2TCB(int(num))\n",
    "        temp=0\n",
    "        if(num>0):\n",
    "            out_s=\"+(0\"\n",
    "        else:\n",
    "            out_s=\"-(0\"\n",
    "        for s in reversed(tcb_str):\n",
    "            if(s==\"+\"):\n",
    "                out_s+=\"+(\"+reg_name+\"<<\"+str(temp)+\")\"\n",
    "            if(s==\"-\"):\n",
    "                out_s+=\"-(\"+reg_name+\"<<\"+str(temp)+\")\"\n",
    "            temp+=1         \n",
    "            \n",
    "        return out_s+\")\"\n",
    "D2reg(-29,\"reg\")        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "wire_cnt 16\n",
      "wire_cnt 16\n"
     ]
    }
   ],
   "source": [
    "\n",
    "img_size=input_img_sz*input_img_sz\n",
    "wire_cnt=layer0_output_size\n",
    "in_buffer_weight_name=\"in_buffer_weight\"\n",
    "weight_to_bias_name=\"weight_bias\"\n",
    "bias_relu_name=\"bias_relu\"\n",
    "in_buffer_weight_parameter=model.state_dict()[\"liner0.weight\"]\n",
    "weight_bias_parameter=model.state_dict()[\"liner0.bias\"]\n",
    "#data_bit_num=20\n",
    "data_bit_num=layer0_bit\n",
    "file_destination = \"verilog_net2\"\n",
    "\n",
    "layer0_verilog_file_name=\"layer0_tcb_\"+str(img_size)+\"x\"+str(layer0_output_size)+\"x10\"\n",
    "f=open(\"./\"+file_destination+\"/\"+layer0_verilog_file_name+\".v\",\"w\")\n",
    "f.write(\"module \"+layer0_verilog_file_name+\"\\n\")\n",
    "f.write(\"(\\n\")\n",
    "\n",
    "f.write(\"\\\n",
    "    input clk,\\n\\\n",
    "    input rst,\\n\\\n",
    "    input [\"+str(img_size)+\"*8-1:0] img,\\n\\\n",
    "    input valid,\\n\\\n",
    "    output  reg ready,\\n\\\n",
    "    output [\"+str(data_bit_num)+\"*\"+str(layer0_output_size)+\"-1:0] layer_out\\n\"\\\n",
    ")\n",
    "f.write(\");\\n\")\n",
    "f.write(\"parameter DATA_WIDTH = \"+str(data_bit_num)+\";\\n\")\n",
    "f.write(\"parameter IMG_SZ   =   \"+str(img_size)+\";\\n\")\n",
    "\n",
    "f.write(\"reg    signed [8-1:0]  in_buffer[0:IMG_SZ-1];\\n\")\n",
    "f.write(\"integer i;\\n\")\n",
    "f.write(\"always@(posedge clk )\\n\\\n",
    "    begin\\n\\\n",
    "        if(rst)\\n\\\n",
    "            begin\\n\\\n",
    "                for(i=0;i<IMG_SZ;i=i+1)\\n\\\n",
    "                    begin\\n\\\n",
    "                        in_buffer[i]<=0;\\n\\\n",
    "                    end\\n\\\n",
    "            end\\n\\\n",
    "        else\\n\\\n",
    "        begin\\n\")\n",
    "\n",
    "for i in range(img_size):\n",
    "    f.write(\"       in_buffer[\"+str(i)+\"]<=img[\"+str(7+i*8)+\":\"+str(0+i*8)+\"];\\n\")           \n",
    "f.write(\"        end\\n   end\\n\")\n",
    "for naming_idx in range(wire_cnt): \n",
    "    f.write(\"wire signed  [DATA_WIDTH-1:0]   \")   \n",
    "    f.write(in_buffer_weight_name+str(naming_idx)+\";\\n\")\n",
    "    f.write(\"assign \"+in_buffer_weight_name+str(naming_idx)+\"=0\")\n",
    "    #insert tcb\n",
    "    for in_buf_idx in range(img_size):\n",
    "        name=\"in_buffer[\" +str(in_buf_idx)+\"]\"\n",
    "        num=int(in_buffer_weight_parameter[naming_idx][in_buf_idx])\n",
    "        try:\n",
    "            f.write(D2reg(num,name))\n",
    "        except:\n",
    "            pass\n",
    "    f.write(\";\\n\")\n",
    "\n",
    "#weight0 to bias0\n",
    "previous_layer_name=in_buffer_weight_name\n",
    "#naming wire\n",
    "print(\"wire_cnt\",wire_cnt)\n",
    "for naming_idx in range(wire_cnt): \n",
    "    f.write(\"wire signed [DATA_WIDTH-1:0]   \")   \n",
    "    f.write(weight_to_bias_name+str(naming_idx)+\";\\n\")\n",
    "for naming_idx in range(wire_cnt):\n",
    "    f.write(\"assign \"+weight_to_bias_name+str(naming_idx)+\"=\")\n",
    "    f.write(previous_layer_name+str(naming_idx))\n",
    "    f.write(\"+(\")\n",
    "    f.write(str(int(weight_bias_parameter[naming_idx])))\n",
    "\n",
    "    f.write(\");\\n\")\n",
    "#bias0 to relu0\n",
    "previous_layer_name=weight_to_bias_name\n",
    "#naming wire\n",
    "print(\"wire_cnt\",wire_cnt)\n",
    "for naming_idx in range(wire_cnt): \n",
    "    f.write(\"wire signed [DATA_WIDTH-1:0]   \")   \n",
    "    f.write(bias_relu_name+str(naming_idx)+\";\\n\")\n",
    "for naming_idx in range(wire_cnt):\n",
    "    f.write(\"assign \"+bias_relu_name+str(naming_idx)+\"=(\")\n",
    "    f.write(previous_layer_name+str(naming_idx))\n",
    "    f.write(\"[DATA_WIDTH-1]==1'b1)   ?   \")\n",
    "    f.write(\"{DATA_WIDTH{1'b0}}:\")\n",
    "    f.write(previous_layer_name+str(naming_idx))\n",
    "    f.write(\";\\n\")\n",
    "\n",
    "\n",
    "f.write(\"assign layer_out={\")\n",
    "for naming_idx in range(wire_cnt-1,-1,-1):\n",
    "    if(naming_idx==0):\n",
    "        f.write(bias_relu_name+str(naming_idx))\n",
    "    else:\n",
    "        f.write(bias_relu_name+str(naming_idx)+\",\")\n",
    "f.write(\"};\\n\")\n",
    "f.write(\"always@(posedge clk)\\n\\\n",
    "    begin\\n\\\n",
    "        if(rst)\\n\\\n",
    "            begin\\n\\\n",
    "                ready<=1'b0;\\n\\\n",
    "            end\\n\\\n",
    "        else\\n\\\n",
    "            begin\\n\\\n",
    "                ready<=valid;\\n\\\n",
    "            end\\n\\\n",
    "    end\\n\")\n",
    "f.write(\"endmodule\")\n",
    "f.close()\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "last_output_sz=layer0_output_size\n",
    "last_layer_data_sz=layer0_bit\n",
    "\n",
    "wire_cnt=10\n",
    "in_buffer_weight_name=\"in_buffer_weight\"\n",
    "weight_to_bias_name=\"weight_bias\"\n",
    "bias_relu_name=\"bias_relu\"\n",
    "in_buffer_weight_parameter=model.state_dict()[\"liner1.weight\"]\n",
    "weight_bias_parameter=model.state_dict()[\"liner1.bias\"]\n",
    "\n",
    "layer2_verilog_file_name=\"layer2_tcb_\"+str(img_size)+\"x\"+str(layer0_output_size)+\"x10\"\n",
    "f=open(\"./\"+file_destination+\"/\"+layer2_verilog_file_name+\".v\",\"w\")\n",
    "f.write(\"module \"+layer2_verilog_file_name+\"\\n\")\n",
    "f.write(\"(\\n\")\n",
    "\n",
    "f.write(\"\\\n",
    "    input clk,\\n\\\n",
    "    input rst,\\n\")\n",
    "f.write(\"   input valid,\\n\")\n",
    "f.write(\"   output  reg ready,\\n\")\n",
    "f.write(\"    input [\"+str(last_layer_data_sz)+\"*\"+str(last_output_sz)+\"-1:0]  layer_in,\\n\")\n",
    "f.write(\"    output [\"+str(layer2_bit)+\"*10-1:0]   layer_out\\n\\\n",
    ");\\n\")\n",
    "f.write(\"parameter DATA_WIDTH   =   \"+str(layer2_bit)+\";\\n\")\n",
    "f.write(\"reg [DATA_WIDTH-1:0]    layer_in_buffer    [0:\"+str(last_output_sz)+\"-1];\\n\")\n",
    "f.write(\"integer i;\\n\")\n",
    "f.write(\"always@(posedge clk )\\n\\\n",
    "    begin\\n\\\n",
    "        if(rst)\\n\\\n",
    "            begin\\n\")\n",
    "f.write(\"                for(i=0;i<\"+str(last_output_sz)+\";i=i+1)\\n\\\n",
    "                    begin\\n\\\n",
    "                        layer_in_buffer[i]<=0;\\n\\\n",
    "                    end\\n\\\n",
    "            end\\n\\\n",
    "        else\\n\\\n",
    "        begin\\n\")\n",
    "for i in range(last_output_sz):\n",
    "    f.write(\"       layer_in_buffer[\"+str(i)+\"]<=layer_in[\"+str(last_layer_data_sz-1+i*last_layer_data_sz)+\":\"+str(0+i*last_layer_data_sz)+\"];\\n\")           \n",
    "f.write(\"        end\\n   end\\n\")\n",
    "\n",
    "\n",
    "f.write(\"\\n\")\n",
    "previous_layer_name=\"layer_in_buffer\"\n",
    "#naming wire\n",
    "for naming_idx in range(wire_cnt): \n",
    "    f.write(\"wire [DATA_WIDTH-1:0]   \")   \n",
    "    f.write(in_buffer_weight_name+str(naming_idx)+\";\\n\")\n",
    "    f.write(\"assign \"+in_buffer_weight_name+str(naming_idx)+\"=0\")\n",
    "    for previoud_layer_idx in range(last_output_sz):\n",
    "        name=previous_layer_name+\"[\"+str(previoud_layer_idx)+\"]\"\n",
    "        num=int(in_buffer_weight_parameter[naming_idx][previoud_layer_idx])\n",
    "        try:\n",
    "            f.write(D2reg(num,name))\n",
    "        except:\n",
    "            pass\n",
    "    f.write(\";\\n\")\n",
    "# weight4 to bias4 \n",
    "\n",
    "previous_layer_name=in_buffer_weight_name\n",
    "#naming wire\n",
    "for naming_idx in range(wire_cnt): \n",
    "    f.write(\"wire [DATA_WIDTH-1:0]   \")   \n",
    "    f.write(weight_to_bias_name+str(naming_idx)+\";\\n\")\n",
    "    f.write(\"assign \"+weight_to_bias_name+str(naming_idx)+\"=\")\n",
    "    f.write(previous_layer_name+str(naming_idx))\n",
    "    f.write(\"+(\")\n",
    "    f.write(str(int(weight_bias_parameter[naming_idx])))\n",
    "    f.write(\");\\n\")\n",
    "f.write(\"assign layer_out={\\n\")\n",
    "for naming_idx in range(wire_cnt-1,-1,-1): \n",
    "    if(naming_idx==0):\n",
    "        f.write(\"            \"+weight_to_bias_name+str(naming_idx))\n",
    "    else:\n",
    "        f.write(\"            \"+weight_to_bias_name+str(naming_idx)+\",\\n\")\n",
    "f.write(\"};\\n\")\n",
    "f.write(\"always@(posedge clk)\\n\\\n",
    "    begin\\n\\\n",
    "        if(rst)\\n\\\n",
    "            begin\\n\\\n",
    "                ready<=1'b0;\\n\\\n",
    "            end\\n\\\n",
    "        else\\n\\\n",
    "            begin\\n\\\n",
    "                ready<=valid;\\n\\\n",
    "            end\\n\\\n",
    "    end\\n\")\n",
    "f.write(\"endmodule\\n\")\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_sz=layer2_bit\n",
    "f=open(\"./\"+file_destination+\"/comparator_30bit.v\",\"w\")\n",
    "f.write(\"module comparator\\n\")\n",
    "f.write(\"(\\n\")\n",
    "f.write(\"input [\"+str(data_sz)+\"*10-1:0] layer_out,\\n\")\n",
    "f.write(\"input rst,\\n\")\n",
    "f.write(\"input clk,\\n\")\n",
    "f.write(\"input valid,\\n\")\n",
    "f.write(\"output  reg ready,\\n\")\n",
    "f.write(\"output reg [7:0] predict\\n\")\n",
    "f.write(\");\\n\")\n",
    "f.write(\"parameter DATA_WIDTH=\"+str(data_sz)+\";\\n\")\n",
    "f.write(\"reg [DATA_WIDTH-1: 0] result [0:9];\\n\")\n",
    "f.write(\"wire [4+DATA_WIDTH-1:0] com_re01,com_re23,com_re45,com_re67,com_re89;\\n\")\n",
    "f.write(\"reg ready_temp;\\n\")\n",
    "f.write(\"always@(posedge clk)\\n\\\n",
    "    begin\\n\\\n",
    "        if(rst)\\n\\\n",
    "            begin\\n\\\n",
    "                ready<=1'b0;\\n\\\n",
    "                ready_temp<=1'b0;\\n\\\n",
    "            end\\n\\\n",
    "        else\\n\\\n",
    "            begin\\n\\\n",
    "                ready_temp<=valid;\\n\\\n",
    "                ready<=ready_temp;\\n\\\n",
    "            end\\n\\\n",
    "    end\\n\")\n",
    "\n",
    "f.write(\" \\n\\\n",
    "assign com_re01=(result[0][DATA_WIDTH-1]^result[1][DATA_WIDTH-1]) ? \\n\\\n",
    "                                                        ((result[0][DATA_WIDTH-1]==1'b0)   ?   {4'd0,result[0]}:{4'd1,result[1]}):\\n\\\n",
    "                                                        ((result[0]>result[1]) ? {4'd0,result[0]}:{4'd1,result[1]});\\n\\\n",
    "assign com_re23=(result[2][DATA_WIDTH-1]^result[3][DATA_WIDTH-1]) ? \\n\\\n",
    "                                                        ((result[2][DATA_WIDTH-1]==1'b0)   ?   {4'd2,result[2]}:{4'd3,result[3]}):\\n\\\n",
    "                                                        ((result[2]>result[3]) ? {4'd2,result[2]}:{4'd3,result[3]});\\n\\\n",
    "assign com_re45=(result[4][DATA_WIDTH-1]^result[5][DATA_WIDTH-1]) ? \\n\\\n",
    "                                                        ((result[4][DATA_WIDTH-1]==1'b0)   ?   {4'd4,result[4]}:{4'd5,result[5]}):\\n\\\n",
    "                                                        ((result[4]>result[5]) ? {4'd4,result[4]}:{4'd5,result[5]});\\n\")  \n",
    "f.write(\"\\n\\\n",
    "assign com_re67=(result[6][DATA_WIDTH-1]^result[7][DATA_WIDTH-1]) ? \\n\\\n",
    "                                                        ((result[6][DATA_WIDTH-1]==1'b0)   ?   {4'd6,result[6]}:{4'd7,result[7]}):\\n\\\n",
    "                                                        ((result[6]>result[7]) ? {4'd6,result[6]}:{4'd7,result[7]});\\n\\\n",
    "assign com_re89=(result[8][DATA_WIDTH-1]^result[9][DATA_WIDTH-1]) ? \\n\\\n",
    "                                                        ((result[8][DATA_WIDTH-1]==1'b0)   ?   {4'd8,result[8]}:{4'd9,result[9]}):\\n\\\n",
    "                                                        ((result[8]>result[9]) ? {4'd8,result[8]}:{4'd9,result[9]});\\n\\\n",
    "wire [4+DATA_WIDTH-1:0] com_re01_23,com_re45_67,com_re0123_4567,com_re01234567_89;\\n\\\n",
    "assign com_re01_23=(com_re01[DATA_WIDTH-1]^com_re23[DATA_WIDTH-1])   ?\\n\\\n",
    "                                                        ((com_re01[DATA_WIDTH-1]==1'b0)  ?   com_re01:com_re23):\\n\\\n",
    "                                                        ((com_re01[DATA_WIDTH-1:0]>com_re23[DATA_WIDTH-1:0]) ?   com_re01:com_re23);\\n\\\n",
    "assign com_re45_67=(com_re45[DATA_WIDTH-1]^com_re67[DATA_WIDTH-1])   ?\\n\\\n",
    "                                                        ((com_re45[DATA_WIDTH-1]==1'b0)  ?   com_re45:com_re67):\\n\\\n",
    "                                                        ((com_re45[DATA_WIDTH-1:0]>com_re67[DATA_WIDTH-1:0]) ?   com_re45:com_re67);\\n\\\n",
    "assign com_re0123_4567=(com_re01_23[DATA_WIDTH-1]^com_re45_67[DATA_WIDTH-1])   ?\\n\\\n",
    "                                                        ((com_re01_23[DATA_WIDTH-1]==1'b0)  ?   com_re01_23:com_re45_67):\\n\\\n",
    "                                                        ((com_re01_23[DATA_WIDTH-1:0]>com_re45_67[DATA_WIDTH-1:0]) ?   com_re01_23:com_re45_67);\\n\\\n",
    "assign com_re01234567_89=(com_re0123_4567[DATA_WIDTH-1]^com_re89[DATA_WIDTH-1])   ?\\n\\\n",
    "                                                        ((com_re0123_4567[DATA_WIDTH-1]==1'b0)  ?   com_re0123_4567:com_re89):\\n\\\n",
    "                                                        ((com_re0123_4567[DATA_WIDTH-1:0]>com_re89[DATA_WIDTH-1:0]) ?   com_re0123_4567:com_re89);\\n\")\n",
    "f.write(\"integer i;\\n\")\n",
    "f.write(\"always@(posedge clk )\\n\")\n",
    "f.write(\"begin\\n\\\n",
    "    if(rst)\\n\\\n",
    "            begin\\n\\\n",
    "                for(i=0;i<10;i=i+1)\\n\\\n",
    "                    begin\\n\\\n",
    "                        result[i]<={\"+str(data_sz)+\"'b0};\\n\\\n",
    "                    end\\n\\\n",
    "                predict<=0;\\n\\\n",
    "            end\\n\\\n",
    "    else\\n\\\n",
    "    begin \\n\")\n",
    "f.write(\"\\\n",
    "        predict <={4'b0,com_re01234567_89[4+DATA_WIDTH-1:4+DATA_WIDTH-1-3]};\\n\")\n",
    "for i in range(10):\n",
    "    f.write(\"       result[\"+str(i)+\"]<=layer_out[\"+str(data_sz-1+data_sz*i)+\":\"+str(data_sz*i)+\"];\\n\")\n",
    "f.write(\"\\\n",
    "    end\\n\\\n",
    "end\\n\")\n",
    "\n",
    "\n",
    "\n",
    "f.write(\"endmodule\\n\")\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "layer0_port=layer0_output_size\n",
    "layer2_port=10\n",
    "tb_name=\"top_tcb_\"+str(input_img_sz*input_img_sz)+\"_\"+str(layer0_output_size)+\"_10\"\n",
    "f=open(\"./\"+file_destination+\"/\"+tb_name+\".v\",\"w\")\n",
    "f.write(\"module \"+tb_name+\"(\\n\")\n",
    "f.write(\"input clk,\\n\\\n",
    "input rst,\\n\\\n",
    "input [\"+str(input_img_sz*input_img_sz)+\"*8-1:0] img_source,\\n\\\n",
    "output [31:0] number,\\n\")\n",
    "f.write(\"input valid_top,\\n\")\n",
    "f.write(\"output  ready_top\\n\")\n",
    "f.write(\");\\n\")\n",
    "f.write(\"wire layer0_ready,layer2_ready\\n;\")\n",
    "f.write(\"wire   [\"+str(layer0_bit)+\"*\"+str(layer0_port)+\"-1:0] layer0_out;\\n\")\n",
    "f.write(\"wire   [\"+str(layer2_bit)+\"*\"+str(layer2_port)+\"-1:0] layer2_out;\\n\")\n",
    "f.write(layer0_verilog_file_name+\" DUT_layer0   (.clk(clk),.rst(rst),.img(img_source),.layer_out(layer0_out),.ready(layer0_ready),.valid(valid_top));\\n\")\n",
    "f.write(layer2_verilog_file_name+\" DUT_layer2   (.clk(clk),.rst(rst),.layer_in(layer0_out),.layer_out(layer2_out),.ready(layer2_ready),.valid(layer0_ready));\\n\")\n",
    "f.write(\"comparator DUT_comparator (.clk(clk),.rst(rst),.layer_out(layer2_out),.predict(number),.ready(ready_top),.valid(layer2_ready));\\n\")\n",
    "\n",
    "f.write(\"endmodule\\n\")\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "f=open(\"./\"+file_destination+\"/tb.v\",\"w\")\n",
    "f.write(\"`timescale 1ns/1ps\\n\")\n",
    "f.write(\"module tb;\\n\")\n",
    "\n",
    "f.write(\"reg clk,rst,valid;\\n\")\n",
    "f.write(\"reg [\"+str(input_img_sz*input_img_sz*8)+\"-1:0] img;\\n\")\n",
    "f.write(\"wire [7:0] number;\\n\")\n",
    "f.write(tb_name+\" top_DUT(\\n\\\n",
    "    .clk(clk),\\n\\\n",
    "    .rst(rst),\\n\\\n",
    "    .img_source(img),\\n\\\n",
    "    .valid_top(valid),\\n\\\n",
    "    .ready_top(ready_top),\\n\\\n",
    "    .number(number)\\n\\\n",
    ");\\n\")\n",
    "f.write(\"always #5 clk=~clk;\\n\")\n",
    "f.write(\"initial \\nbegin\\n\")\n",
    "f.write(\"$monitor(\\\"number is %d\\\",number);\\n\")\n",
    "f.write(\"clk=0;rst=1'b1;valid=1'b1;\\n\")\n",
    "f.write(\"img=\"+str(input_img_sz*input_img_sz)+\"'b0;\\n\")\n",
    "f.write(\"#10 rst=1'b0;\\n\")\n",
    "for i in range(10):\n",
    "    f.write(\"@(negedge clk) #(10/4) img=\"+str(input_img_sz*input_img_sz*8)+\"'b\")\n",
    "    img,idx=test_data[i]\n",
    "    img=img.reshape(-1)\n",
    "    img=np.asarray(img)\n",
    "    img=int_conver(img)\n",
    "    for ele in reversed(img):\n",
    "        eight_bit=\"{:08b}\".format(int(ele))\n",
    "        f.write(eight_bit)\n",
    "        #print(ele)\n",
    "    f.write(\";\\n\")\n",
    "\n",
    "\n",
    "\n",
    "f.write(\"#100 $finish;\\n\")\n",
    "\n",
    "\n",
    "f.write(\"end\\n\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "f.write(\"endmodule\\n\")\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "f=open(\"./\"+file_destination+\"/label.txt\",\"w\")\n",
    "for i in range(10):\n",
    "    img,idx=test_data[i]\n",
    "    f.write(str(idx))\n",
    "    f.write(\"\\n\")\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
